import unittest
from typing import Union
import yaml
import jk_commentjson as jsonc
import matplotlib.pyplot as plt
import pandas as pd
import os
import webbrowser
import requests
import io
import os
import glob
import re
import getopt
import sys
import base64
import unidecode
from termcolor     import colored
from mako.template import Template
import mako.runtime
import warnings
import zipfile
import shutil
import matplotlib
from importlib import reload


reload(matplotlib)
matplotlib.use('Agg')

warnings.filterwarnings("ignore")
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)


# Working Directories
output_dir = "output" + os.sep
data_dir   = "data"   + os.sep
input_dir  = "input"  + os.sep

configurationFile    = input_dir  + "Configuration.xlsx"
html_report_template = input_dir  + "report_template.html"
html_index_template  = input_dir  + "index_template.html"
context_file         = output_dir + "context.yaml"
regions_file         = output_dir + "france.json"

global_context     = {}

# DataFile and Data Frames

##########################
### Sitadel Logements
##########################

sitadelSourcePage     = "https://www.data.gouv.fr/es/datasets/base-des-permis-de-construire-et-autres-autorisations-durbanisme-sitadel"
global_context["URL_SOURCE_SITADEL"] = sitadelSourcePage

sitadelSource1316File = "https://www.data.gouv.fr/es/datasets/r/67dd4ee1-0d73-4676-a90f-854fe9012f5d"
sitadelSource1721File = "https://www.data.gouv.fr/es/datasets/r/1fa467ef-5e3a-456f-b961-be9032cfa3df"
sitadelSourceMetaFile = "https://www.data.gouv.fr/es/datasets/r/9d7d6728-c3bc-44e4-8105-7335ad70d52e"
sitadel1316File       = data_dir + "PC_DP_creant_logements_2013_2016.csv"
sitadel1721File       = data_dir + "PC_DP_creant_logements_2017_2021.csv"
sitadelMetaFile       = data_dir + "dictionnaire_variables_logements_permis_construire.xls"

sitadel1316 = None
sitadel1721 = None
sitadelMeta = None

# Logements
# "REG";"DEP";"COMM";"Type_DAU";"Num_DAU";"Etat_DAU";"DATE_REELLE_AUTORISATION";"DATE_REELLE_DOC";"DATE_REELLE_DAACT";"DPC_AUT";"DPC_DOC";"DPC_DERN";"APE_DEM";"CJ_DEM";"DENOM_DEM";"SIREN_DEM";"SIRET_DEM";"CODPOST_DEM";"LOCALITE_DEM";"REC_ARCHI";"ADR_NUM_TER";"ADR_TYPEVOIE_TER";"ADR_LIBVOIE_TER";"ADR_LIEUDIT_TER";"ADR_LOCALITE_TER";"ADR_CODPOST_TER";"sec_cadastre1";"num_cadastre1";"sec_cadastre2";"num_cadastre2";"sec_cadastre3";"num_cadastre3";"SUPERFICIE_TERRAIN";"ZONE_OP";"NATURE_PROJET";"I_EXTENSION";"I_SURELEVATION";"I_NIVSUPP";"NB_NIV_MAX";"NB_CHAMBRES";"SURF_HAB_AVANT";"SURF_HAB_CREEE";"SURF_HAB_ISSUE_TRANSFO";"SURF_HAB_DEMOLIE";"SURF_HAB_TRANSFORMEE";"SURF_LOC_AVANT";"SURF_LOC_CREEE";"SURF_LOC_ISSUE_TRANSFO";"SURF_LOC_DEMOLIE";"SURF_LOC_TRANSFORMEE";"SURF_HEB_AVANT";"SURF_HEB_CREEE";"SURF_HEB_ISSUE_TRANSFO";"SURF_HEB_DEMOLIE";"SURF_HEB_TRANSFORMEE";"SURF_BUR_AVANT";"SURF_BUR_CREEE";"SURF_BUR_ISSUE_TRANSFO";"SURF_BUR_DEMOLIE";"SURF_BUR_TRANSFORMEE";"SURF_COM_AVANT";"SURF_COM_CREEE";"SURF_COM_ISSUE_TRANSFO";"SURF_COM_DEMOLIE";"SURF_COM_TRANSFORMEE";"SURF_ART_AVANT";"SURF_ART_CREEE";"SURF_ART_ISSUE_TRANSFO";"SURF_ART_DEMOLIE";"SURF_ART_TRANSFORMEE";"SURF_IND_AVANT";"SURF_IND_CREEE";"SURF_IND_ISSUE_TRANSFO";"SURF_IND_DEMOLIE";"SURF_IND_TRANSFORMEE";"SURF_AGR_AVANT";"SURF_AGR_CREEE";"SURF_AGR_ISSUE_TRANSFO";"SURF_AGR_DEMOLIE";"SURF_AGR_TRANSFORMEE";"SURF_ENT_AVANT";"SURF_ENT_CREEE";"SURF_ENT_ISSUE_TRANSFO";"SURF_ENT_DEMOLIE";"SURF_ENT_TRANSFORMEE";"SURF_PUB_AVANT";"SURF_PUB_CREEE";"SURF_PUB_ISSUE_TRANSFO";"SURF_PUB_DEMOLIE";"SURF_PUB_TRANSFORMEE";"TYPE_SERVICE_PUBLIC"


def load_sitadel(sitadel1316_file:  str = sitadel1316File,
                 sitadel1721_file:  str = sitadel1721File,
                 sitadel_meta_file: str = sitadelMetaFile):
    global sitadel1316, sitadel1721, sitadelMeta
    if (sitadel1316 is None) or (sitadel1721 is None)  or (sitadelMeta is None):
        downloadFile(sitadelSource1316File, sitadel1316File, zip=True, zipped_file="PC_DP_créant_logements_2013_2016.csv")
        downloadFile(sitadelSource1721File, sitadel1721File, zip=True, zipped_file="PC_DP_créant_logements_2017_2021.csv")
        downloadFile(sitadelSourceMetaFile, sitadelMetaFile)
        print_blue("Lecture Sitadel Logements 2013-2016 : " + sitadel1316_file + " ...")
        sitadel1316 = pd.read_csv(sitadel1316_file, delimiter=';', index_col=4, encoding='latin-1', dtype={"DEP": str, "COMM": str, "DPC_AUT": str, "NATURE_PROJET" : str, "I_EXTENSION": str, "I_SURELEVATION": str, "I_NIVSUPP": str})
        print_blue("Lecture Sitadel Logements 2017-2021 : " + sitadel1721_file + " ...")
        sitadel1721 = pd.read_csv(sitadel1721_file, delimiter=';', index_col=4, encoding='latin-1', dtype={"DEP": str, "COMM": str, "DPC_AUT": str, "ADR_LOCALITE_TER" : str, "ADR_CODPOST_TER" : str})
        print_blue("Lecture Meta Logements Sitadel : " + sitadel_meta_file + " ...")
        xls = pd.ExcelFile(sitadel_meta_file)
        sitadelMeta = pd.read_excel(xls, 'Variables_Logements', index_col=0)
    return sitadel1316, sitadel1721, sitadelMeta


##########################
### Sitadel Locaux
##########################

sitadelLocauxSource1316File = "https://www.data.gouv.fr/es/datasets/r/3b987380-d1cf-4047-8dc5-1a19a3ecf812"
sitadelLocauxSource1721File = "https://www.data.gouv.fr/es/datasets/r/98ff9fd3-a14e-474d-bb8f-12bde12d9f70"
sitadelLocauxSourceMetaFile = "https://www.data.gouv.fr/es/datasets/r/b3ffee5b-fd75-4345-a086-02ded2018705"
sitadelLocaux1316File = data_dir + "PC_DP_creant_locaux_2013_2016.csv"
sitadelLocaux1721File = data_dir + "PC_DP_creant_locaux_2017_2021.csv"
sitadelLocauxMetaFile = data_dir + "dictionnaire_variables_locaux_permis_construire.xls"

sitadel_locaux_1316 = None
sitadel_locaux_1721 = None
sitadel_locaux_Meta = None

# Locaux
# "REG";"DEP";"COMM";"Type_DAU";"Num_DAU";"Etat_DAU";"DATE_REELLE_AUTORISATION";"DATE_REELLE_DOC";"DATE_REELLE_DAACT";"DPC_AUT";"DPC_DOC";"DPC_DERN";"APE_DEM";"CJ_DEM";"DENOM_DEM";"SIREN_DEM";"SIRET_DEM";"CODPOST_DEM";"LOCALITE_DEM";"REC_ARCHI";"ADR_NUM_TER";"ADR_TYPEVOIE_TER";"ADR_LIBVOIE_TER";"ADR_LIEUDIT_TER";"ADR_LOCALITE_TER";"ADR_CODPOST_TER";"sec_cadastre1";"num_cadastre1";"sec_cadastre2";"num_cadastre2";"sec_cadastre3";"num_cadastre3";"SUPERFICIE_TERRAIN";"ZONE_OP";"NATURE_PROJET";"I_EXTENSION";"I_SURELEVATION";"I_NIVSUPP";"NB_NIV_MAX";"NB_CHAMBRES";"SURF_HAB_AVANT";"SURF_HAB_CREEE";"SURF_HAB_ISSUE_TRANSFO";"SURF_HAB_DEMOLIE";"SURF_HAB_TRANSFORMEE";"SURF_LOC_AVANT";"SURF_LOC_CREEE";"SURF_LOC_ISSUE_TRANSFO";"SURF_LOC_DEMOLIE";"SURF_LOC_TRANSFORMEE";"SURF_HEB_AVANT";"SURF_HEB_CREEE";"SURF_HEB_ISSUE_TRANSFO";"SURF_HEB_DEMOLIE";"SURF_HEB_TRANSFORMEE";"SURF_BUR_AVANT";"SURF_BUR_CREEE";"SURF_BUR_ISSUE_TRANSFO";"SURF_BUR_DEMOLIE";"SURF_BUR_TRANSFORMEE";"SURF_COM_AVANT";"SURF_COM_CREEE";"SURF_COM_ISSUE_TRANSFO";"SURF_COM_DEMOLIE";"SURF_COM_TRANSFORMEE";"SURF_ART_AVANT";"SURF_ART_CREEE";"SURF_ART_ISSUE_TRANSFO";"SURF_ART_DEMOLIE";"SURF_ART_TRANSFORMEE";"SURF_IND_AVANT";"SURF_IND_CREEE";"SURF_IND_ISSUE_TRANSFO";"SURF_IND_DEMOLIE";"SURF_IND_TRANSFORMEE";"SURF_AGR_AVANT";"SURF_AGR_CREEE";"SURF_AGR_ISSUE_TRANSFO";"SURF_AGR_DEMOLIE";"SURF_AGR_TRANSFORMEE";"SURF_ENT_AVANT";"SURF_ENT_CREEE";"SURF_ENT_ISSUE_TRANSFO";"SURF_ENT_DEMOLIE";"SURF_ENT_TRANSFORMEE";"SURF_PUB_AVANT";"SURF_PUB_CREEE";"SURF_PUB_ISSUE_TRANSFO";"SURF_PUB_DEMOLIE";"SURF_PUB_TRANSFORMEE";"TYPE_SERVICE_PUBLIC"


def load_sitadel_locaux(sitadelLocaux1316_file:  str = sitadelLocaux1316File,
                        sitadelLocaux1721_file:  str = sitadelLocaux1721File,
                        sitadelLocaux_meta_file: str = sitadelLocauxMetaFile):
    global sitadel_locaux_1316, sitadel_locaux_1721, sitadel_locaux_Meta
    if (sitadel_locaux_1316 is None) or (sitadel_locaux_1721 is None)  or (sitadel_locaux_Meta is None):
        downloadFile(sitadelLocauxSource1316File, sitadelLocaux1316File, zip=True, zipped_file="PC_DP_créant_locaux_2013_2016.csv")
        downloadFile(sitadelLocauxSource1721File, sitadelLocaux1721File, zip=True, zipped_file="PC_DP_créant_locaux_2017_2021.csv")
        downloadFile(sitadelLocauxSourceMetaFile, sitadelLocauxMetaFile)
        print_blue("Lecture Sitadel Locaux 2013-2016 : " + sitadelLocaux1316_file + " ...")
        sitadel_locaux_1316 = pd.read_csv(sitadelLocaux1316_file, delimiter=';', index_col=4, encoding='latin-1', dtype={"DEP": str, "COMM": str, "DPC_AUT": str, "NATURE_PROJET" : str, "I_EXTENSION": str, "I_SURELEVATION": str, "I_NIVSUPP": str, "ZONE_OP": str, "NATURE_PROJET": str, "I_EXTENSION": str, "I_SURELEVATION": str, "I_NIVSUPP": str, "SUPERFICIE_TERRAIN": float, "SURF_HAB_AVANT": float})
        print_blue("Lecture Sitadel Locaux 2017-2021 : " + sitadelLocaux1721_file + " ...")
        sitadel_locaux_1721 = pd.read_csv(sitadelLocaux1721_file, delimiter=';', index_col=4, encoding='latin-1', dtype={"DEP": str, "COMM": str, "DPC_AUT": str, "ADR_LOCALITE_TER" : str, "ADR_CODPOST_TER" : str, "NATURE_PROJET" : str, "I_EXTENSION": str, "I_SURELEVATION": str, "I_NIVSUPP": str, "ZONE_OP": str, "NATURE_PROJET": str, "I_EXTENSION": str, "I_SURELEVATION": str, "I_NIVSUPP": str, "SUPERFICIE_TERRAIN": float, "SURF_HAB_AVANT": float})
        print_blue("Lecture Meta Locaux Sitadel : " + sitadelLocaux_meta_file + " ...")
        xls = pd.ExcelFile(sitadelLocaux_meta_file)
        sitadel_locaux_Meta = pd.read_excel(xls, 'Variables_Locaux', index_col=0)
    return sitadel1316, sitadel1721, sitadelMeta

##########################
### Evolution 2008-2021
##########################

evolutionSourcePage = "https://www.insee.fr/fr/statistiques/1893198"
evolutionSourceFile = "https://www.insee.fr/fr/statistiques/fichier/1893198/evolution-population-reg-2008-2021.xlsx"
evolutionFile = data_dir + "evolution-population-dep-2008-2021.xlsx"
evolution0813 = None
evolution1318 = None
evolution1821 = None
global_context["URL_SOURCE_EVOLUTION"] = evolutionSourcePage

# Variation relative annuelle 2018-2021 (en %)
# Département, Estimations de population au 1er janvier 2021, Totale Due au solde naturel, Due au solde apparent des entrées et des sorties
# Ain	662,244	    0.7%	0.3%	0.4%


def load_evolution(evolution_file: str = evolutionFile):
    global evolution0813, evolution1318, evolution1821
    if (evolution0813 is None) or (evolution1318 is None)  or (evolution1821 is None):
        print_blue("Lecture Evolution_file Dept : " + evolution_file + " ...")
        xls = pd.ExcelFile(evolution_file)
        evolution0813 = pd.read_excel(xls, '2008-2013', index_col=0, dtype={"Unnamed: 0": str})
        evolution1318 = pd.read_excel(xls, '2013-2018', index_col=0, dtype={"Unnamed: 0": str})
        xls = pd.ExcelFile(evolution_file)
        evolution1821 = pd.read_excel(xls, '2018-2021', index_col=0, dtype={"Unnamed: 0": str})
    return evolution0813, evolution1318, evolution1821

##########################
### Projections 2013-2050
##########################

projectionsSourcePage = "https://www.insee.fr/fr/statistiques/2859843"
projectionsSourceFile = "https://www.insee.fr/fr/statistiques/fichier/2859843/projections_scenario_central.xls"
projectionsFile = data_dir + "projections_scenario_central.xls"
projectionsDPT = None
projectionsREG = None
global_context["URL_SOURCE_PROJECTIONS_2050"] = projectionsSourcePage

### Population_DEP
# Département       Libellé du département	Population en 2013	Population en 2014	Population en 2015	Population en 2016	Population en 2017	Population en 2018	Population en 2019	Population en 2020	Population en 2021	Population en 2022	Population en 2023	Population en 2024	Population en 2025	Population en 2026	Population en 2027	Population en 2028	Population en 2029	Population en 2030	Population en 2031	Population en 2032	Population en 2033	Population en 2034	Population en 2035	Population en 2036	Population en 2037	Population en 2038	Population en 2039	Population en 2040	Population en 2041	Population en 2042	Population en 2043	Population en 2044	Population en 2045	Population en 2046	Population en 2047	Population en 2048	Population en 2049	Population en 2050
# code_Departements	libelle_Departements	pop_2013	pop_2014	pop_2015	pop_2016	pop_2017	pop_2018	pop_2019	pop_2020	pop_2021	pop_2022	pop_2023	pop_2024	pop_2025	pop_2026	pop_2027	pop_2028	pop_2029	pop_2030	pop_2031	pop_2032	pop_2033	pop_2034	pop_2035	pop_2036	pop_2037	pop_2038	pop_2039	pop_2040	pop_2041	pop_2042	pop_2043	pop_2044	pop_2045	pop_2046	pop_2047	pop_2048	pop_2049	pop_2050

### Population_REG
# Région	Libellé de la région	Population en 2013	Population en 2014	Population en 2015	Population en 2016	Population en 2017	Population en 2018	Population en 2019	Population en 2020	Population en 2021	Population en 2022	Population en 2023	Population en 2024	Population en 2025	Population en 2026	Population en 2027	Population en 2028	Population en 2029	Population en 2030	Population en 2031	Population en 2032	Population en 2033	Population en 2034	Population en 2035	Population en 2036	Population en 2037	Population en 2038	Population en 2039	Population en 2040	Population en 2041	Population en 2042	Population en 2043	Population en 2044	Population en 2045	Population en 2046	Population en 2047	Population en 2048	Population en 2049	Population en 2050
# code_Regions	libelle_Regions	pop_2013	pop_2014	pop_2015	pop_2016	pop_2017	pop_2018	pop_2019	pop_2020	pop_2021	pop_2022	pop_2023	pop_2024	pop_2025	pop_2026	pop_2027	pop_2028	pop_2029	pop_2030	pop_2031	pop_2032	pop_2033	pop_2034	pop_2035	pop_2036	pop_2037	pop_2038	pop_2039	pop_2040	pop_2041	pop_2042	pop_2043	pop_2044	pop_2045	pop_2046	pop_2047	pop_2048	pop_2049	pop_2050


def load_projections(projections_file: str = projectionsFile):
    global projectionsREG, projectionsDPT
    if (projectionsREG is None) or (projectionsREG is None):
        print_blue("Lecture Projections Dept/Reg : " + projections_file + " ...")
        xls = pd.ExcelFile(projections_file)
        projectionsDPT = pd.read_excel(xls, 'Population_DEP', index_col=0, dtype={"Unnamed: 0": str, "Unnamed: 1": str})
        projectionsREG = pd.read_excel(xls, 'Population_REG', index_col=0, dtype={"Unnamed: 0": str, "Unnamed: 1": str})
    return projectionsDPT, projectionsREG


##############################
### Projections PACA 2030-2050
##############################

projectionsPacaSourcePage = "https://www.insee.fr/fr/statistiques/3202958?sommaire=3203271"
projectionsPacaSourceFile = "https://www.insee.fr/fr/statistiques/fichier/3202958/1_Population_evolutions.xls"
projectionsPacaFile = data_dir + "1_Population_evolutions.xls"
projectionsPaca = None
global_context["URL_SOURCE_PROJECTIONS_PACA"] = projectionsPacaSourcePage

# Type de Zone  EPCI	Nom de zone		Population haute 2013	Central* 2013	Population basse 2013	Sans migrations 2013	Population haute 2030	Central* 2030	Population basse 2030	Sans migrations 2030 Population haute 2050	Central* 2050	Population basse 2050	Sans migrations 2050


def load_projections_paca(projections_paca_file: str = projectionsPacaFile):
    global projectionsPaca
    if (projectionsPaca is None) :
        print_blue("Lecture Projections Paca : " + projections_paca_file + " ...")
        xls = pd.ExcelFile(projections_paca_file)
        projectionsPaca = pd.read_excel(xls, 'Projection', dtype={'["Unnamed: 0"]': str, '["Unnamed: 1"]': str, '["Unnamed: 2"]': str})
    return projectionsPaca


################
### Departements
################

departementsSourcePage = "https://www.data.gouv.fr/en/datasets/departements-de-france/"
departementsSourceFile = "https://www.data.gouv.fr/en/datasets/r/70cef74f-70b1-495a-8500-c089229c0254"
departementsFile = data_dir + "departements-france.csv"
departements     = None
global_context["URL_SOURCE_DEPARTEMENTS"] = departementsSourcePage

# code_departement	nom_departement	code_region	nom_region


def load_departements(dpt_file: str = departementsFile):
    global departements
    if (departements is None):
        print_blue("Lecture Departements : " + dpt_file + " ...")
        departements = pd.read_csv(dpt_file, delimiter=',', index_col=0, dtype={'code_departement': str, 'nom_departement': str, 'code_region': str, 'nom_region': str})
    return departements

####################
### Intercommunalite
####################

interCoSourcePage = "https://www.insee.fr/fr/information/2510634"
interCoSourceFile = "https://www.insee.fr/fr/statistiques/fichier/2510634/Intercommunalite_Metropole_au_01-01-2021.zip"
intercoFile = data_dir + "Intercommunalite-Metropole_au_01-01-2021.xlsx"
intercoDossier = None
intercoEPCI    = None
global_context["URL_SOURCE_INTERCOMMUNALITES"] = interCoSourcePage

# CODGEO	LIBGEO	EPCI	LIBEPCI	DEP	REG


def load_interco(interco_file: str = intercoFile):
    # EPCI		    EPCI - Métropole		        Code géographique de l'établissement public à fiscalité propre ou métropole
    # LIBEPCI		Libellé de l'EPCI / Métropole	Libellé de l'EPCI ou métropole
    # NATURE_EPCI	Nature d'EPCI			        Nature d'établissement public
    # NB_COM		Nombre communes			        Nombre de communes contenues dans l'objet géographique
    # CODGEO		Code géographique		        Code géographique
    # LIBGEO		Libellé géographique	        Libellé géographique
    # DEP		    Département			            Code géographique du département
    # REG		    Région				            Code géographique de la région
    global intercoDossier, intercoEPCI
    if (intercoDossier is None) or (intercoEPCI is None):
        print_blue("Lecture Donnees Intercommunalite : " + interco_file + " ...")
        xls = pd.ExcelFile(interco_file)
        intercoDossier = pd.read_excel(xls, 'Composition_communale', index_col=0, dtype={"EPCI": str, "LIBEPCI": str,  "NATURE_EPCI": str, "NB_COM": int, "CODGEO": str, "LIBGEO": str, "DEP": str, "REG": str})
        intercoEPCI    = pd.read_excel(xls, 'EPCI', index_col=0)
    return intercoDossier, intercoEPCI

#################
### Codes Postaux
#################

codesPostauxSourcePage = "https://datanova.laposte.fr/explore/dataset/laposte_hexasmal/information/?disjunctive.code_commune_insee&disjunctive.nom_de_la_commune&disjunctive.code_postal&disjunctive.ligne_5"
codesPostauxSourceFile = "https://datanova.laposte.fr/explore/dataset/laposte_hexasmal/download/?format=csv&timezone=Europe/Berlin&lang=fr&use_labels_for_header=true&csv_separator=%3B"
codesPostauxFile = data_dir + "laposte_hexasmal.csv"
codesPostaux = None
global_context["URL_SOURCE_CODES_POSTAUX"] = codesPostauxSourcePage

# Code_commune_INSEE;Nom_commune;Code_postal;Ligne_5;LibellÃ©_d_acheminement;coordonnees_gps (lat,long)
# 02547;LA NEUVILLE HOUSSET;02250;;LA NEUVILLE HOUSSET;49.7881379377,3.731716273


def load_codes():
    global codesPostaux
    if (codesPostaux is None) :
        downloadFile(codesPostauxSourceFile, codesPostauxFile)
        print_blue("Lecture Codes Postaux Donnees Communes : " + metaDossierFile + " ...")
        codesPostaux = pd.read_csv(codesPostauxFile, delimiter=';', index_col=0, dtype=str)
    return codesPostaux

#################
### SRU
#################

sru2017SourcePage = "http://www.paca.developpement-durable.gouv.fr/periode-triennale-2017-2019-a10879.html"
sru2017SourceFile = "http://www.paca.developpement-durable.gouv.fr/IMG/pdf/2017-2019_communes_sru_en_paca.pdf"
sru2020SourcePage = "http://www.paca.developpement-durable.gouv.fr/periode-triennale-2020-2022-a13129.html"
sru2020SourceFile = "http://www.paca.developpement-durable.gouv.fr/IMG/pdf/inventaire_010120.pdf"
sruFile = data_dir + "communes_sru_en_paca.xlsx"
sru2017 = None
sru2020 = None
global_context["URL_SOURCE_SRU"] = sru2020SourcePage

# REG;"DEP";"COMM";"Type_DAU";"Num_DAU";"Etat_DAU";"DATE_REELLE_AUTORISATION";"DATE_REELLE_DOC";"DATE_REELLE_DAACT";"DPC_AUT";"DPC_DOC";"DPC_DERN";"CAT_DEM";"APE_DEM";"CJ_DEM";"DENOM_DEM";"SIREN_DEM";"SIRET_DEM";"CODPOST_DEM";"LOCALITE_DEM";"REC_ARCHI";"ADR_NUM_TER";"ADR_TYPEVOIE_TER";"ADR_LIBVOIE_TER";"ADR_LIEUDIT_TER";"ADR_LOCALITE_TER";"ADR_CODPOST_TER";"sec_cadastre1";"num_cadastre1";"sec_cadastre2";"num_cadastre2";"sec_cadastre3";"num_cadastre3";"SUPERFICIE_TERRAIN";"ZONE_OP";"NATURE_PROJET";"I_EXTENSION";"I_SURELEVATION";"I_NIVSUPP";"NB_NIV_MAX";"UTILISATION";"RES_PRINCIP_OU_SECOND";"TYP_ANNEXE";"RESIDENCE_SERVICE";"NB_LGT_TOT_CREES";"NB_LGT_IND_CREES";"NB_LGT_COL_CREES";"NB_LGT_DEMOLIS";"NB_LGT_1P";"NB_LGT_2P";"NB_LGT_3P";"NB_LGT_4P";"NB_LGT_5P";"NB_LGT_6P_PLUS";"NB_LGT_PRET_LOC_SOCIAL";"NB_LGT_ACC_SOC_HORS_PTZ";"NB_LGT_PTZ";"SURF_HAB_AVANT";"SURF_HAB_CREEE";"SURF_HAB_ISSUE_TRANSFO";"SURF_HAB_DEMOLIE";"SURF_HAB_TRANSFORMEE";"SURF_LOC_AVANT";"SURF_LOC_CREEE";"SURF_LOC_ISSUE_TRANSFO";"SURF_LOC_DEMOLIE";"SURF_LOC_TRANSFORMEE"


def load_sru(sru_file: str = sruFile):
    global sru2017, sru2020
    if (sru2017 is None) or (sru2020 is None):
        print_blue("Lecture Carences SRU PACA : " + sru_file + " ...")
        xls = pd.ExcelFile(sru_file)
        sru2017 = pd.read_excel(xls, '2017-2019_communes_sru_en_paca', index_col=2, dtype={"REG": str, "DEP": str, "REG": str})
        sru2020 = pd.read_excel(xls, '2020-2022_communes_sru_en_paca', index_col=2, dtype={"REG": str, "DEP": str, "REG": str})
    return sru2017, sru2020

#################
### Communes
#################

metaDossierSourcePage = "https://www.insee.fr/fr/statistiques/5359146"
metaDossierSourceFile = "https://www.insee.fr/fr/statistiques/fichier/5359146/dossier_complet.zip"
metaDossierFile = data_dir + "meta_dossier_complet.csv"
dossierCompletFile = data_dir + "dossier_complet.csv"
metaDossier    = None
dossierComplet = None
global_context["URL_SOURCE_COMMUNES"] = metaDossierSourcePage

# CODGEO;P18_POP;P18_POP0014;P18_POP1529;P18_POP3044;P18_POP4559;P18_POP6074;P18_POP7589;P18_POP90P;P18_POPH;P18_H0014;P18_H1529;P18_H3044;P18_H4559;P18_H6074;P18_H7589;P18_H90P;P18_H0019;P18_H2064;P18_H65P;P18_POPF;P18_F0014;P18_F1529;P18_F3044;P18_F4559;P18_F6074;P18_F7589;P18_F90P;P18_F0019;P18_F2064;P18_F65P;P18_POP01P;P18_POP01P_IRAN1;P18_POP01P_IRAN2;P18_POP01P_IRAN3;P18_POP01P_IRAN4;P18_POP01P_IRAN5;P18_POP01P_IRAN6;P18_POP01P_IRAN7;P18_POP0114_IRAN2P;P18_POP0114_IRAN2;P18_POP0114_IRAN3P;P18_POP1524_IRAN2P;P18_POP1524_IRAN2;P18_POP1524_IRAN3P;P18_POP2554_IRAN2P;P18_POP2554_IRAN2;P18_POP2554_IRAN3P;P18_POP55P_IRAN2P;P18_POP55P_IRAN2;P18_POP55P_IRAN3P;C18_POP15P;C18_POP15P_CS1;C18_POP15P_CS2;C18_POP15P_CS3;C18_POP15P_CS4;C18_POP15P_CS5;C18_POP15P_CS6;C18_POP15P_CS7;C18_POP15P_CS8;C18_H15P;C18_H15P_CS1;C18_H15P_CS2;C18_H15P_CS3;C18_H15P_CS4;C18_H15P_CS5;C18_H15P_CS6;C18_H15P_CS7;C18_H15P_CS8;C18_F15P;C18_F15P_CS1;C18_F15P_CS2;C18_F15P_CS3;C18_F15P_CS4;C18_F15P_CS5;C18_F15P_CS6;C18_F15P_CS7;C18_F15P_CS8;C18_POP1524;C18_POP1524_CS1;C18_POP1524_CS2;C18_POP1524_CS3;C18_POP1524_CS4;C18_POP1524_CS5;C18_POP1524_CS6;C18_POP1524_CS7;C18_POP1524_CS8;C18_POP2554;C18_POP2554_CS1;C18_POP2554_CS2;C18_POP2554_CS3;C18_POP2554_CS4;C18_POP2554_CS5;C18_POP2554_CS6;C18_POP2554_CS7;C18_POP2554_CS8;C18_POP55P;C18_POP55P_CS1;C18_POP55P_CS2;C18_POP55P_CS3;C18_POP55P_CS4;C18_POP55P_CS5;C18_POP55P_CS6;C18_POP55P_CS7;C18_POP55P_CS8;P13_POP;P13_POP0014;P13_POP1529;P13_POP3044;P13_POP4559;P13_POP6074;P13_POP7589;P13_POP90P;P13_POPH;P13_H0014;P13_H1529;P13_H3044;P13_H4559;P13_H6074;P13_H7589;P13_H90P;P13_H0019;P13_H2064;P13_H65P;P13_POPF;P13_F0014;P13_F1529;P13_F3044;P13_F4559;P13_F6074;P13_F7589;P13_F90P;P13_F0019;P13_F2064;P13_F65P;P13_POP01P;P13_POP01P_IRAN1;P13_POP01P_IRAN2;P13_POP01P_IRAN3;P13_POP01P_IRAN4;P13_POP01P_IRAN5;P13_POP01P_IRAN6;P13_POP01P_IRAN7;P13_POP0114_IRAN2P;P13_POP0114_IRAN2;P13_POP0114_IRAN3P;P13_POP1524_IRAN2P;P13_POP1524_IRAN2;P13_POP1524_IRAN3P;P13_POP2554_IRAN2P;P13_POP2554_IRAN2;P13_POP2554_IRAN3P;P13_POP55P_IRAN2P;P13_POP55P_IRAN2;P13_POP55P_IRAN3P;C13_POP15P;C13_POP15P_CS1;C13_POP15P_CS2;C13_POP15P_CS3;C13_POP15P_CS4;C13_POP15P_CS5;C13_POP15P_CS6;C13_POP15P_CS7;C13_POP15P_CS8;C13_H15P;C13_H15P_CS1;C13_H15P_CS2;C13_H15P_CS3;C13_H15P_CS4;C13_H15P_CS5;C13_H15P_CS6;C13_H15P_CS7;C13_H15P_CS8;C13_F15P;C13_F15P_CS1;C13_F15P_CS2;C13_F15P_CS3;C13_F15P_CS4;C13_F15P_CS5;C13_F15P_CS6;C13_F15P_CS7;C13_F15P_CS8;C13_POP1524;C13_POP1524_CS1;C13_POP1524_CS2;C13_POP1524_CS3;C13_POP1524_CS4;C13_POP1524_CS5;C13_POP1524_CS6;C13_POP1524_CS7;C13_POP1524_CS8;C13_POP2554;C13_POP2554_CS1;C13_POP2554_CS2;C13_POP2554_CS3;C13_POP2554_CS4;C13_POP2554_CS5;C13_POP2554_CS6;C13_POP2554_CS7;C13_POP2554_CS8;C13_POP55P;C13_POP55P_CS1;C13_POP55P_CS2;C13_POP55P_CS3;C13_POP55P_CS4;C13_POP55P_CS5;C13_POP55P_CS6;C13_POP55P_CS7;C13_POP55P_CS8;P08_POP;P08_POP0014;P08_POP1529;P08_POP3044;P08_POP4559;P08_POP6074;P08_POP75P;P08_POPH;P08_H0014;P08_H1529;P08_H3044;P08_H4559;P08_H6074;P08_H7589;P08_H90P;P08_H0019;P08_H2064;P08_H65P;P08_POPF;P08_F0014;P08_F1529;P08_F3044;P08_F4559;P08_F6074;P08_F7589;P08_F90P;P08_F0019;P08_F2064;P08_F65P;P08_POP05P;P08_POP05P_IRAN1;P08_POP05P_IRAN2;P08_POP05P_IRAN3;P08_POP05P_IRAN4;P08_POP05P_IRAN5;P08_POP05P_IRAN6;P08_POP05P_IRAN7;P08_POP0514;P08_POP0514_IRAN2;P08_POP0514_IRAN3P;P08_POP1524;P08_POP1524_IRAN2;P08_POP1524_IRAN3P;P08_POP2554;P08_POP2554_IRAN2;P08_POP2554_IRAN3P;P08_POP55P;P08_POP55P_IRAN2;P08_POP55P_IRAN3P;C08_POP15P;C08_POP15P_CS1;C08_POP15P_CS2;C08_POP15P_CS3;C08_POP15P_CS4;C08_POP15P_CS5;C08_POP15P_CS6;C08_POP15P_CS7;C08_POP15P_CS8;C08_H15P;C08_H15P_CS1;C08_H15P_CS2;C08_H15P_CS3;C08_H15P_CS4;C08_H15P_CS5;C08_H15P_CS6;C08_H15P_CS7;C08_H15P_CS8;C08_F15P;C08_F15P_CS1;C08_F15P_CS2;C08_F15P_CS3;C08_F15P_CS4;C08_F15P_CS5;C08_F15P_CS6;C08_F15P_CS7;C08_F15P_CS8;C08_POP1524;C08_POP1524_CS1;C08_POP1524_CS2;C08_POP1524_CS3;C08_POP1524_CS4;C08_POP1524_CS5;C08_POP1524_CS6;C08_POP1524_CS7;C08_POP1524_CS8;C08_POP2554;C08_POP2554_CS1;C08_POP2554_CS2;C08_POP2554_CS3;C08_POP2554_CS4;C08_POP2554_CS5;C08_POP2554_CS6;C08_POP2554_CS7;C08_POP2554_CS8;C08_POP55P;C08_POP55P_CS1;C08_POP55P_CS2;C08_POP55P_CS3;C08_POP55P_CS4;C08_POP55P_CS5;C08_POP55P_CS6;C08_POP55P_CS7;C08_POP55P_CS8;C18_MEN;C18_MENPSEUL;C18_MENHSEUL;C18_MENFSEUL;C18_MENSFAM;C18_MENFAM;C18_MENCOUPSENF;C18_MENCOUPAENF;C18_MENFAMMONO;C18_PMEN;C18_PMEN_MENPSEUL;C18_PMEN_MENHSEUL;C18_PMEN_MENFSEUL;C18_PMEN_MENSFAM;C18_PMEN_MENFAM;C18_PMEN_MENCOUPSENF;C18_PMEN_MENCOUPAENF;C18_PMEN_MENFAMMONO;P18_POP15P;P18_POP1519;P18_POP2024;P18_POP2539;P18_POP4054;P18_POP5564;P18_POP6579;P18_POP80P;P18_POPMEN1519;P18_POPMEN2024;P18_POPMEN2539;P18_POPMEN4054;P18_POPMEN5564;P18_POPMEN6579;P18_POPMEN80P;P18_POP1519_PSEUL;P18_POP2024_PSEUL;P18_POP2539_PSEUL;P18_POP4054_PSEUL;P18_POP5564_PSEUL;P18_POP6579_PSEUL;P18_POP80P_PSEUL;P18_POP1519_COUPLE;P18_POP2024_COUPLE;P18_POP2539_COUPLE;P18_POP4054_COUPLE;P18_POP5564_COUPLE;P18_POP6579_COUPLE;P18_POP80P_COUPLE;P18_POP15P_MARIEE;P18_POP15P_PACSEE;P18_POP15P_CONCUB_UNION_LIBRE;P18_POP15P_VEUFS;P18_POP15P_DIVORCEE;P18_POP15P_CELIBATAIRE;C18_MEN_CS1;C18_MEN_CS2;C18_MEN_CS3;C18_MEN_CS4;C18_MEN_CS5;C18_MEN_CS6;C18_MEN_CS7;C18_MEN_CS8;C18_PMEN_CS1;C18_PMEN_CS2;C18_PMEN_CS3;C18_PMEN_CS4;C18_PMEN_CS5;C18_PMEN_CS6;C18_PMEN_CS7;C18_PMEN_CS8;C18_FAM;C18_COUPAENF;C18_FAMMONO;C18_HMONO;C18_FMONO;C18_COUPSENF;C18_NE24F0;C18_NE24F1;C18_NE24F2;C18_NE24F3;C18_NE24F4P;C13_MEN;C13_MENPSEUL;C13_MENHSEUL;C13_MENFSEUL;C13_MENSFAM;C13_MENFAM;C13_MENCOUPSENF;C13_MENCOUPAENF;C13_MENFAMMONO;C13_PMEN;C13_PMEN_MENPSEUL;C13_PMEN_MENHSEUL;C13_PMEN_MENFSEUL;C13_PMEN_MENSFAM;C13_PMEN_MENFAM;C13_PMEN_MENCOUPSENF;C13_PMEN_MENCOUPAENF;C13_PMEN_MENFAMMONO;P13_POP15P;P13_POP1519;P13_POP2024;P13_POP2539;P13_POP4054;P13_POP5564;P13_POP6579;P13_POP80P;P13_POPMEN1519;P13_POPMEN2024;P13_POPMEN2539;P13_POPMEN4054;P13_POPMEN5564;P13_POPMEN6579;P13_POPMEN80P;P13_POP1519_PSEUL;P13_POP2024_PSEUL;P13_POP2539_PSEUL;P13_POP4054_PSEUL;P13_POP5564_PSEUL;P13_POP6579_PSEUL;P13_POP80P_PSEUL;P13_POP1519_COUPLE;P13_POP2024_COUPLE;P13_POP2539_COUPLE;P13_POP4054_COUPLE;P13_POP5564_COUPLE;P13_POP6579_COUPLE;P13_POP80P_COUPLE;P13_POP15P_MARIEE;P13_POP15P_NONMARIEE;C13_MEN_CS1;C13_MEN_CS2;C13_MEN_CS3;C13_MEN_CS4;C13_MEN_CS5;C13_MEN_CS6;C13_MEN_CS7;C13_MEN_CS8;C13_PMEN_CS1;C13_PMEN_CS2;C13_PMEN_CS3;C13_PMEN_CS4;C13_PMEN_CS5;C13_PMEN_CS6;C13_PMEN_CS7;C13_PMEN_CS8;C13_FAM;C13_COUPAENF;C13_FAMMONO;C13_HMONO;C13_FMONO;C13_COUPSENF;C13_NE24F0;C13_NE24F1;C13_NE24F2;C13_NE24F3;C13_NE24F4P;C08_MEN;C08_MENPSEUL;C08_MENHSEUL;C08_MENFSEUL;C08_MENSFAM;C08_MENFAM;C08_MENCOUPSENF;C08_MENCOUPAENF;C08_MENFAMMONO;C08_PMEN;C08_PMEN_MENPSEUL;C08_PMEN_MENHSEUL;C08_PMEN_MENFSEUL;C08_PMEN_MENSFAM;C08_PMEN_MENFAM;C08_PMEN_MENCOUPSENF;C08_PMEN_MENCOUPAENF;C08_PMEN_MENFAMMONO;P08_POP15P;P08_POP1519;P08_POP2024;P08_POP2539;P08_POP4054;P08_POP5564;P08_POP6579;P08_POP80P;P08_POPMEN1519;P08_POPMEN2024;P08_POPMEN2539;P08_POPMEN4054;P08_POPMEN5564;P08_POPMEN6579;P08_POPMEN80P;P08_POP1519_PSEUL;P08_POP2024_PSEUL;P08_POP2539_PSEUL;P08_POP4054_PSEUL;P08_POP5564_PSEUL;P08_POP6579_PSEUL;P08_POP80P_PSEUL;P08_POP1519_COUPLE;P08_POP2024_COUPLE;P08_POP2539_COUPLE;P08_POP4054_COUPLE;P08_POP5564_COUPLE;P08_POP6579_COUPLE;P08_POP80P_COUPLE;P08_POP15P_MARIE;P08_POP15P_CELIB;P08_POP15P_VEUF;P08_POP15P_DIVOR;C08_MEN_CS1;C08_MEN_CS2;C08_MEN_CS3;C08_MEN_CS4;C08_MEN_CS5;C08_MEN_CS6;C08_MEN_CS7;C08_MEN_CS8;C08_PMEN_CS1;C08_PMEN_CS2;C08_PMEN_CS3;C08_PMEN_CS4;C08_PMEN_CS5;C08_PMEN_CS6;C08_PMEN_CS7;C08_PMEN_CS8;C08_FAM;C08_COUPAENF;C08_FAMMONO;C08_HMONO;C08_FMONO;C08_COUPSENF;C08_NE24F0;C08_NE24F1;C08_NE24F2;C08_NE24F3;C08_NE24F4P;P18_LOG;P18_RP;P18_RSECOCC;P18_LOGVAC;P18_MAISON;P18_APPART;P18_RP_1P;P18_RP_2P;P18_RP_3P;P18_RP_4P;P18_RP_5PP;P18_NBPI_RP;P18_RPMAISON;P18_NBPI_RPMAISON;P18_RPAPPART;P18_NBPI_RPAPPART;C18_RP_HSTU1P;C18_RP_HSTU1P_SUROCC;P18_RP_ACHTOT;P18_RP_ACH19;P18_RP_ACH45;P18_RP_ACH70;P18_RP_ACH90;P18_RP_ACH05;P18_RP_ACH15;P18_RPMAISON_ACH19;P18_RPMAISON_ACH45;P18_RPMAISON_ACH70;P18_RPMAISON_ACH90;P18_RPMAISON_ACH05;P18_RPMAISON_ACH15;P18_RPAPPART_ACH19;P18_RPAPPART_ACH45;P18_RPAPPART_ACH70;P18_RPAPPART_ACH90;P18_RPAPPART_ACH05;P18_RPAPPART_ACH15;P18_MEN;P18_MEN_ANEM0002;P18_MEN_ANEM0204;P18_MEN_ANEM0509;P18_MEN_ANEM10P;P18_MEN_ANEM1019;P18_MEN_ANEM2029;P18_MEN_ANEM30P;P18_PMEN;P18_PMEN_ANEM0002;P18_PMEN_ANEM0204;P18_PMEN_ANEM0509;P18_PMEN_ANEM10P;P18_NBPI_RP_ANEM0002;P18_NBPI_RP_ANEM0204;P18_NBPI_RP_ANEM0509;P18_NBPI_RP_ANEM10P;P18_RP_PROP;P18_RP_LOC;P18_RP_LOCHLMV;P18_RP_GRAT;P18_NPER_RP;P18_NPER_RP_PROP;P18_NPER_RP_LOC;P18_NPER_RP_LOCHLMV;P18_NPER_RP_GRAT;P18_ANEM_RP;P18_ANEM_RP_PROP;P18_ANEM_RP_LOC;P18_ANEM_RP_LOCHLMV;P18_ANEM_RP_GRAT;P18_RP_SDB;P18_RP_CCCOLL;P18_RP_CCIND;P18_RP_CINDELEC;P18_RP_ELEC;P18_RP_EAUCH;P18_RP_BDWC;P18_RP_CHOS;P18_RP_CLIM;P18_RP_TTEGOU;P18_RP_GARL;P18_RP_VOIT1P;P18_RP_VOIT1;P18_RP_VOIT2P;P18_RP_HABFOR;P18_RP_CASE;P18_RP_MIBOIS;P18_RP_MIDUR;P13_LOG;P13_RP;P13_RSECOCC;P13_LOGVAC;P13_MAISON;P13_APPART;P13_RP_1P;P13_RP_2P;P13_RP_3P;P13_RP_4P;P13_RP_5PP;P13_NBPI_RP;P13_RPMAISON;P13_NBPI_RPMAISON;P13_RPAPPART;P13_NBPI_RPAPPART;P13_RP_ACHTOT;P13_RP_ACH19;P13_RP_ACH45;P13_RP_ACH70;P13_RP_ACH90;P13_RP_ACH05;P13_RP_ACH10;P13_RPMAISON_ACH19;P13_RPMAISON_ACH45;P13_RPMAISON_ACH70;P13_RPMAISON_ACH90;P13_RPMAISON_ACH05;P13_RPMAISON_ACH10;P13_RPAPPART_ACH19;P13_RPAPPART_ACH45;P13_RPAPPART_ACH70;P13_RPAPPART_ACH90;P13_RPAPPART_ACH05;P13_RPAPPART_ACH10;P13_MEN;P13_MEN_ANEM0002;P13_MEN_ANEM0204;P13_MEN_ANEM0509;P13_MEN_ANEM10P;P13_MEN_ANEM1019;P13_MEN_ANEM2029;P13_MEN_ANEM30P;P13_PMEN;P13_PMEN_ANEM0002;P13_PMEN_ANEM0204;P13_PMEN_ANEM0509;P13_PMEN_ANEM10P;P13_NBPI_RP_ANEM0002;P13_NBPI_RP_ANEM0204;P13_NBPI_RP_ANEM0509;P13_NBPI_RP_ANEM10P;P13_RP_PROP;P13_RP_LOC;P13_RP_LOCHLMV;P13_RP_GRAT;P13_NPER_RP;P13_NPER_RP_PROP;P13_NPER_RP_LOC;P13_NPER_RP_LOCHLMV;P13_NPER_RP_GRAT;P13_ANEM_RP;P13_ANEM_RP_PROP;P13_ANEM_RP_LOC;P13_ANEM_RP_LOCHLMV;P13_ANEM_RP_GRAT;P13_RP_SDB;P13_RP_CCCOLL;P13_RP_CCIND;P13_RP_CINDELEC;P13_RP_ELEC;P13_RP_EAUCH;P13_RP_BDWC;P13_RP_CHOS;P13_RP_CLIM;P13_RP_TTEGOU;P13_RP_GARL;P13_RP_VOIT1P;P13_RP_VOIT1;P13_RP_VOIT2P;P13_RP_HABFOR;P13_RP_CASE;P13_RP_MIBOIS;P13_RP_MIDUR;P08_LOG;P08_RP;P08_RSECOCC;P08_LOGVAC;P08_MAISON;P08_APPART;P08_RP_1P;P08_RP_2P;P08_RP_3P;P08_RP_4P;P08_RP_5PP;P08_NBPI_RP;P08_RPMAISON;P08_NBPI_RPMAISON;P08_RPAPPART;P08_NBPI_RPAPPART;P08_RP_ACHTT;P08_RP_ACHT1;P08_RP_ACHT2;P08_RP_ACHT3;P08_RP_ACHT4;P08_RPMAISON_ACHT1;P08_RPMAISON_ACHT2;P08_RPMAISON_ACHT3;P08_RPMAISON_ACHT4;P08_RPAPPART_ACHT1;P08_RPAPPART_ACHT2;P08_RPAPPART_ACHT3;P08_RPAPPART_ACHT4;P08_MEN;P08_MEN_ANEM0002;P08_MEN_ANEM0204;P08_MEN_ANEM0509;P08_MEN_ANEM10P;P08_MEN_ANEM1019;P08_MEN_ANEM2029;P08_MEN_ANEM30P;P08_PMEN;P08_PMEN_ANEM0002;P08_PMEN_ANEM0204;P08_PMEN_ANEM0509;P08_PMEN_ANEM10P;P08_NBPI_RP_ANEM0002;P08_NBPI_RP_ANEM0204;P08_NBPI_RP_ANEM0509;P08_NBPI_RP_ANEM10P;P08_RP_PROP;P08_RP_LOC;P08_RP_LOCHLMV;P08_RP_GRAT;P08_NPER_RP;P08_NPER_RP_PROP;P08_NPER_RP_LOC;P08_NPER_RP_LOCHLMV;P08_NPER_RP_GRAT;P08_ANEM_RP;P08_ANEM_RP_PROP;P08_ANEM_RP_LOC;P08_ANEM_RP_LOCHLMV;P08_ANEM_RP_GRAT;P08_RP_SDB;P08_RP_CCCOLL;P08_RP_CCIND;P08_RP_CINDELEC;P08_RP_ELEC;P08_RP_EAUCH;P08_RP_BDWC;P08_RP_CHOS;P08_RP_CLIM;P08_RP_TTEGOU;P08_RP_GARL;P08_RP_VOIT1P;P08_RP_VOIT1;P08_RP_VOIT2P;P08_RP_HABFOR;P08_RP_CASE;P08_RP_MIBOIS;P08_RP_MIDUR;P18_POP0205;P18_POP0610;P18_POP1114;P18_POP1517;P18_POP1824;P18_POP2529;P18_POP30P;P18_SCOL0205;P18_SCOL0610;P18_SCOL1114;P18_SCOL1517;P18_SCOL1824;P18_SCOL2529;P18_SCOL30P;P18_H0205;P18_H0610;P18_H1114;P18_H1517;P18_H1824;P18_H2529;P18_H30P;P18_HSCOL0205;P18_HSCOL0610;P18_HSCOL1114;P18_HSCOL1517;P18_HSCOL1824;P18_HSCOL2529;P18_HSCOL30P;P18_F0205;P18_F0610;P18_F1114;P18_F1517;P18_F1824;P18_F2529;P18_F30P;P18_FSCOL0205;P18_FSCOL0610;P18_FSCOL1114;P18_FSCOL1517;P18_FSCOL1824;P18_FSCOL2529;P18_FSCOL30P;P18_NSCOL15P;P18_NSCOL15P_DIPLMIN;P18_NSCOL15P_BEPC;P18_NSCOL15P_CAPBEP;P18_NSCOL15P_BAC;P18_NSCOL15P_SUP2;P18_NSCOL15P_SUP34;P18_NSCOL15P_SUP5;P18_HNSCOL15P;P18_HNSCOL15P_DIPLMIN;P18_HNSCOL15P_BEPC;P18_HNSCOL15P_CAPBEP;P18_HNSCOL15P_BAC;P18_HNSCOL15P_SUP2;P18_HNSCOL15P_SUP34;P18_HNSCOL15P_SUP5;P18_FNSCOL15P;P18_FNSCOL15P_DIPLMIN;P18_FNSCOL15P_BEPC;P18_FNSCOL15P_CAPBEP;P18_FNSCOL15P_BAC;P18_FNSCOL15P_SUP2;P18_FNSCOL15P_SUP34;P18_FNSCOL15P_SUP5;P13_POP0205;P13_POP0610;P13_POP1114;P13_POP1517;P13_POP1824;P13_POP2529;P13_POP30P;P13_SCOL0205;P13_SCOL0610;P13_SCOL1114;P13_SCOL1517;P13_SCOL1824;P13_SCOL2529;P13_SCOL30P;P13_H0205;P13_H0610;P13_H1114;P13_H1517;P13_H1824;P13_H2529;P13_H30P;P13_HSCOL0205;P13_HSCOL0610;P13_HSCOL1114;P13_HSCOL1517;P13_HSCOL1824;P13_HSCOL2529;P13_HSCOL30P;P13_F0205;P13_F0610;P13_F1114;P13_F1517;P13_F1824;P13_F2529;P13_F30P;P13_FSCOL0205;P13_FSCOL0610;P13_FSCOL1114;P13_FSCOL1517;P13_FSCOL1824;P13_FSCOL2529;P13_FSCOL30P;P13_NSCOL15P;P13_NSCOL15P_DIPLMIN;P13_NSCOL15P_CAPBEP;P13_NSCOL15P_BAC;P13_NSCOL15P_SUP;P13_HNSCOL15P;P13_HNSCOL15P_DIPLMIN;P13_HNSCOL15P_CAPBEP;P13_HNSCOL15P_BAC;P13_HNSCOL15P_SUP;P13_FNSCOL15P;P13_FNSCOL15P_DIPLMIN;P13_FNSCOL15P_CAPBEP;P13_FNSCOL15P_BAC;P13_FNSCOL15P_SUP;P08_POP0205;P08_POP0610;P08_POP1114;P08_POP1517;P08_POP1824;P08_POP2529;P08_POP30P;P08_SCOL0205;P08_SCOL0610;P08_SCOL1114;P08_SCOL1517;P08_SCOL1824;P08_SCOL2529;P08_SCOL30P;P08_H0205;P08_H0610;P08_H1114;P08_H1517;P08_H1824;P08_H2529;P08_H30P;P08_HSCOL0205;P08_HSCOL0610;P08_HSCOL1114;P08_HSCOL1517;P08_HSCOL1824;P08_HSCOL2529;P08_HSCOL30P;P08_F0205;P08_F0610;P08_F1114;P08_F1517;P08_F1824;P08_F2529;P08_F30P;P08_FSCOL0205;P08_FSCOL0610;P08_FSCOL1114;P08_FSCOL1517;P08_FSCOL1824;P08_FSCOL2529;P08_FSCOL30P;P08_NSCOL15P;P08_NSCOL15P_DIPL0;P08_NSCOL15P_CEP;P08_NSCOL15P_BEPC;P08_NSCOL15P_CAPBEP;P08_NSCOL15P_BAC;P08_NSCOL15P_BACP2;P08_NSCOL15P_SUP;P08_HNSCOL15P;P08_HNSCOL15P_DIPL0;P08_HNSCOL15P_CEP;P08_HNSCOL15P_BEPC;P08_HNSCOL15P_CAPBEP;P08_HNSCOL15P_BAC;P08_HNSCOL15P_BACP2;P08_HNSCOL15P_SUP;P08_FNSCOL15P;P08_FNSCOL15P_DIPL0;P08_FNSCOL15P_CEP;P08_FNSCOL15P_BEPC;P08_FNSCOL15P_CAPBEP;P08_FNSCOL15P_BAC;P08_FNSCOL15P_BACP2;P08_FNSCOL15P_SUP;P18_POP1564;P18_POP1524;P18_POP2554;P18_H1564;P18_H1524;P18_H2554;P18_H5564;P18_F1564;P18_F1524;P18_F2554;P18_F5564;P18_ACT1564;P18_ACT1524;P18_ACT2554;P18_ACT5564;P18_HACT1564;P18_HACT1524;P18_HACT2554;P18_HACT5564;P18_FACT1564;P18_FACT1524;P18_FACT2554;P18_FACT5564;P18_ACTOCC1564;P18_ACTOCC1524;P18_ACTOCC2554;P18_ACTOCC5564;P18_HACTOCC1564;P18_HACTOCC1524;P18_HACTOCC2554;P18_HACTOCC5564;P18_FACTOCC1564;P18_FACTOCC1524;P18_FACTOCC2554;P18_FACTOCC5564;P18_CHOM1564;P18_HCHOM1564;P18_HCHOM1524;P18_HCHOM2554;P18_HCHOM5564;P18_FCHOM1564;P18_FCHOM1524;P18_FCHOM2554;P18_FCHOM5564;P18_INACT1564;P18_ETUD1564;P18_RETR1564;P18_AINACT1564;C18_ACT1564;C18_ACT1564_CS1;C18_ACT1564_CS2;C18_ACT1564_CS3;C18_ACT1564_CS4;C18_ACT1564_CS5;C18_ACT1564_CS6;C18_ACTOCC1564;C18_ACTOCC1564_CS1;C18_ACTOCC1564_CS2;C18_ACTOCC1564_CS3;C18_ACTOCC1564_CS4;C18_ACTOCC1564_CS5;C18_ACTOCC1564_CS6;P18_EMPLT;P18_ACTOCC;P18_ACT15P;P18_EMPLT_SAL;P18_EMPLT_FSAL;P18_EMPLT_SALTP;P18_EMPLT_NSAL;P18_EMPLT_FNSAL;P18_EMPLT_NSALTP;C18_EMPLT;C18_EMPLT_CS1;C18_EMPLT_CS2;C18_EMPLT_CS3;C18_EMPLT_CS4;C18_EMPLT_CS5;C18_EMPLT_CS6;C18_EMPLT_AGRI;C18_EMPLT_INDUS;C18_EMPLT_CONST;C18_EMPLT_CTS;C18_EMPLT_APESAS;C18_EMPLT_F;C18_AGRILT_F;C18_INDUSLT_F;C18_CONSTLT_F;C18_CTSLT_F;C18_APESASLT_F;C18_EMPLT_SAL;C18_AGRILT_SAL;C18_INDUSLT_SAL;C18_CONSTLT_SAL;C18_CTSLT_SAL;C18_APESASLT_SAL;C18_AGRILT_FSAL;C18_INDUSLT_FSAL;C18_CONSTLT_FSAL;C18_CTSLT_FSAL;C18_APESASLT_FSAL;C18_AGRILT_NSAL;C18_INDUSLT_NSAL;C18_CONSTLT_NSAL;C18_CTSLT_NSAL;C18_APESASLT_NSAL;C18_AGRILT_FNSAL;C18_INDUSLT_FNSAL;C18_CONSTLT_FNSAL;C18_CTSLT_FNSAL;C18_APESASLT_FNSAL;P13_POP1564;P13_POP1524;P13_POP2554;P13_H1564;P13_H1524;P13_H2554;P13_H5564;P13_F1564;P13_F1524;P13_F2554;P13_F5564;P13_ACT1564;P13_ACT1524;P13_ACT2554;P13_ACT5564;P13_HACT1564;P13_HACT1524;P13_HACT2554;P13_HACT5564;P13_FACT1564;P13_FACT1524;P13_FACT2554;P13_FACT5564;P13_ACTOCC1564;P13_ACTOCC1524;P13_ACTOCC2554;P13_ACTOCC5564;P13_HACTOCC1564;P13_HACTOCC1524;P13_HACTOCC2554;P13_HACTOCC5564;P13_FACTOCC1564;P13_FACTOCC1524;P13_FACTOCC2554;P13_FACTOCC5564;P13_CHOM1564;P13_HCHOM1564;P13_HCHOM1524;P13_HCHOM2554;P13_HCHOM5564;P13_FCHOM1564;P13_FCHOM1524;P13_FCHOM2554;P13_FCHOM5564;P13_INACT1564;P13_ETUD1564;P13_RETR1564;P13_AINACT1564;C13_ACT1564;C13_ACT1564_CS1;C13_ACT1564_CS2;C13_ACT1564_CS3;C13_ACT1564_CS4;C13_ACT1564_CS5;C13_ACT1564_CS6;C13_ACTOCC1564;C13_ACTOCC1564_CS1;C13_ACTOCC1564_CS2;C13_ACTOCC1564_CS3;C13_ACTOCC1564_CS4;C13_ACTOCC1564_CS5;C13_ACTOCC1564_CS6;P13_EMPLT;P13_ACTOCC;P13_ACT15P;P13_EMPLT_SAL;P13_EMPLT_FSAL;P13_EMPLT_SALTP;P13_EMPLT_NSAL;P13_EMPLT_FNSAL;P13_EMPLT_NSALTP;C13_EMPLT;C13_EMPLT_CS1;C13_EMPLT_CS2;C13_EMPLT_CS3;C13_EMPLT_CS4;C13_EMPLT_CS5;C13_EMPLT_CS6;C13_EMPLT_AGRI;C13_EMPLT_INDUS;C13_EMPLT_CONST;C13_EMPLT_CTS;C13_EMPLT_APESAS;C13_EMPLT_F;C13_AGRILT_F;C13_INDUSLT_F;C13_CONSTLT_F;C13_CTSLT_F;C13_APESASLT_F;C13_EMPLT_SAL;C13_AGRILT_SAL;C13_INDUSLT_SAL;C13_CONSTLT_SAL;C13_CTSLT_SAL;C13_APESASLT_SAL;C13_AGRILT_FSAL;C13_INDUSLT_FSAL;C13_CONSTLT_FSAL;C13_CTSLT_FSAL;C13_APESASLT_FSAL;C13_AGRILT_NSAL;C13_INDUSLT_NSAL;C13_CONSTLT_NSAL;C13_CTSLT_NSAL;C13_APESASLT_NSAL;C13_AGRILT_FNSAL;C13_INDUSLT_FNSAL;C13_CONSTLT_FNSAL;C13_CTSLT_FNSAL;C13_APESASLT_FNSAL;P08_POP1564;P08_H1564;P08_H1524;P08_H2554;P08_H5564;P08_F1564;P08_F1524;P08_F2554;P08_F5564;P08_ACT1564;P08_ACT1524;P08_ACT2554;P08_ACT5564;P08_HACT1564;P08_HACT1524;P08_HACT2554;P08_HACT5564;P08_FACT1564;P08_FACT1524;P08_FACT2554;P08_FACT5564;P08_ACTOCC1564;P08_ACTOCC1524;P08_ACTOCC2554;P08_ACTOCC5564;P08_HACTOCC1564;P08_HACTOCC1524;P08_HACTOCC2554;P08_HACTOCC5564;P08_FACTOCC1564;P08_FACTOCC1524;P08_FACTOCC2554;P08_FACTOCC5564;P08_CHOM1564;P08_HCHOM1564;P08_HCHOM1524;P08_HCHOM2554;P08_HCHOM5564;P08_FCHOM1564;P08_FCHOM1524;P08_FCHOM2554;P08_FCHOM5564;P08_INACT1564;P08_ETUD1564;P08_RETR1564;P08_AINACT1564;C08_ACT1564;C08_ACT1564_CS1;C08_ACT1564_CS2;C08_ACT1564_CS3;C08_ACT1564_CS4;C08_ACT1564_CS5;C08_ACT1564_CS6;C08_ACTOCC1564;C08_ACTOCC1564_CS1;C08_ACTOCC1564_CS2;C08_ACTOCC1564_CS3;C08_ACTOCC1564_CS4;C08_ACTOCC1564_CS5;C08_ACTOCC1564_CS6;P08_EMPLT;P08_ACTOCC;P08_ACT15P;P08_EMPLT_SAL;P08_EMPLT_FSAL;P08_EMPLT_SALTP;P08_EMPLT_NSAL;P08_EMPLT_FNSAL;P08_EMPLT_NSALTP;C08_EMPLT;C08_EMPLT_CS1;C08_EMPLT_CS2;C08_EMPLT_CS3;C08_EMPLT_CS4;C08_EMPLT_CS5;C08_EMPLT_CS6;C08_EMPLT_AGRI;C08_EMPLT_INDUS;C08_EMPLT_CONST;C08_EMPLT_CTS;C08_EMPLT_APESAS;C08_EMPLT_F;C08_AGRILT_F;C08_INDUSLT_F;C08_CONSTLT_F;C08_CTSLT_F;C08_APESASLT_F;C08_EMPLT_SAL;C08_AGRILT_SAL;C08_INDUSLT_SAL;C08_CONSTLT_SAL;C08_CTSLT_SAL;C08_APESASLT_SAL;C08_AGRILT_FSAL;C08_INDUSLT_FSAL;C08_CONSTLT_FSAL;C08_CTSLT_FSAL;C08_APESASLT_FSAL;C08_AGRILT_NSAL;C08_INDUSLT_NSAL;C08_CONSTLT_NSAL;C08_CTSLT_NSAL;C08_APESASLT_NSAL;C08_AGRILT_FNSAL;C08_INDUSLT_FNSAL;C08_CONSTLT_FNSAL;C08_CTSLT_FNSAL;C08_APESASLT_FNSAL;P18_ACTOCC15P;P18_SAL15P;P18_NSAL15P;P18_ACTOCC15P_TP;P18_SAL15P_TP;P18_HSAL15P_TP;P18_FSAL15P_TP;P18_NSAL15P_TP;P18_HACTOCC15P;P18_HSAL15P;P18_HSAL15P_CDI;P18_HSAL15P_CDD;P18_HSAL15P_INTERIM;P18_HSAL15P_EMPAID;P18_HSAL15P_APPR;P18_HNSAL15P;P18_HNSAL15P_INDEP;P18_HNSAL15P_EMPLOY;P18_HNSAL15P_AIDFAM;P18_FACTOCC15P;P18_FSAL15P;P18_FSAL15P_CDI;P18_FSAL15P_CDD;P18_FSAL15P_INTERIM;P18_FSAL15P_EMPAID;P18_FSAL15P_APPR;P18_FNSAL15P;P18_FNSAL15P_INDEP;P18_FNSAL15P_EMPLOY;P18_FNSAL15P_AIDFAM;P18_HSAL1564;P18_HSAL1524;P18_HSAL2554;P18_HSAL5564;P18_HSAL1564_TP;P18_HSAL1524_TP;P18_HSAL2554_TP;P18_HSAL5564_TP;P18_FSAL1564;P18_FSAL1524;P18_FSAL2554;P18_FSAL5564;P18_FSAL1564_TP;P18_FSAL1524_TP;P18_FSAL2554_TP;P18_FSAL5564_TP;P18_ACTOCC15P_ILT1;P18_ACTOCC15P_ILT2P;P18_ACTOCC15P_ILT2;P18_ACTOCC15P_ILT3;P18_ACTOCC15P_ILT4;P18_ACTOCC15P_ILT5;P18_ACTOCC15P_PASTRANS;P18_ACTOCC15P_MARCHE;P18_ACTOCC15P_VELO;P18_ACTOCC15P_2ROUESMOT;P18_ACTOCC15P_VOITURE;P18_ACTOCC15P_COMMUN;P13_ACTOCC15P;P13_SAL15P;P13_NSAL15P;P13_ACTOCC15P_TP;P13_SAL15P_TP;P13_HSAL15P_TP;P13_FSAL15P_TP;P13_NSAL15P_TP;P13_HACTOCC15P;P13_HSAL15P;P13_HSAL15P_CDI;P13_HSAL15P_CDD;P13_HSAL15P_INTERIM;P13_HSAL15P_EMPAID;P13_HSAL15P_APPR;P13_HNSAL15P;P13_HNSAL15P_INDEP;P13_HNSAL15P_EMPLOY;P13_HNSAL15P_AIDFAM;P13_FACTOCC15P;P13_FSAL15P;P13_FSAL15P_CDI;P13_FSAL15P_CDD;P13_FSAL15P_INTERIM;P13_FSAL15P_EMPAID;P13_FSAL15P_APPR;P13_FNSAL15P;P13_FNSAL15P_INDEP;P13_FNSAL15P_EMPLOY;P13_FNSAL15P_AIDFAM;P13_HSAL1564;P13_HSAL1524;P13_HSAL2554;P13_HSAL5564;P13_HSAL1564_TP;P13_HSAL1524_TP;P13_HSAL2554_TP;P13_HSAL5564_TP;P13_FSAL1564;P13_FSAL1524;P13_FSAL2554;P13_FSAL5564;P13_FSAL1564_TP;P13_FSAL1524_TP;P13_FSAL2554_TP;P13_FSAL5564_TP;P13_ACTOCC15P_ILT1;P13_ACTOCC15P_ILT2P;P13_ACTOCC15P_ILT2;P13_ACTOCC15P_ILT3;P13_ACTOCC15P_ILT4;P13_ACTOCC15P_ILT5;P13_ACTOCC15P_PASTRANS;P13_ACTOCC15P_MARCHE;P13_ACTOCC15P_2ROUES;P13_ACTOCC15P_VOITURE;P13_ACTOCC15P_COMMUN;P08_ACTOCC15P;P08_SAL15P;P08_NSAL15P;P08_ACTOCC15P_TP;P08_SAL15P_TP;P08_HSAL15P_TP;P08_FSAL15P_TP;P08_NSAL15P_TP;P08_HACTOCC15P;P08_HSAL15P;P08_HSAL15P_CDI;P08_HSAL15P_CDD;P08_HSAL15P_INTERIM;P08_HSAL15P_EMPAID;P08_HSAL15P_APPR;P08_HNSAL15P;P08_HNSAL15P_INDEP;P08_HNSAL15P_EMPLOY;P08_HNSAL15P_AIDFAM;P08_FACTOCC15P;P08_FSAL15P;P08_FSAL15P_CDI;P08_FSAL15P_CDD;P08_FSAL15P_INTERIM;P08_FSAL15P_EMPAID;P08_FSAL15P_APPR;P08_FNSAL15P;P08_FNSAL15P_INDEP;P08_FNSAL15P_EMPLOY;P08_FNSAL15P_AIDFAM;P08_HSAL1564;P08_HSAL1524;P08_HSAL2554;P08_HSAL5564;P08_HSAL1564_TP;P08_HSAL1524_TP;P08_HSAL2554_TP;P08_HSAL5564_TP;P08_FSAL1564;P08_FSAL1524;P08_FSAL2554;P08_FSAL5564;P08_FSAL1564_TP;P08_FSAL1524_TP;P08_FSAL2554_TP;P08_FSAL5564_TP;P08_ACTOCC15P_ILT1;P08_ACTOCC15P_ILT2P;P08_ACTOCC15P_ILT2;P08_ACTOCC15P_ILT3;P08_ACTOCC15P_ILT4;P08_ACTOCC15P_ILT5;D99_POP;D90_POP;D82_POP;D75_POP;D68_POP;SUPERF;NAIS1318;NAIS0813;NAIS9908;NAIS9099;NAIS8290;NAIS7582;NAIS6875;DECE1318;DECE0813;DECE9908;DECE9099;DECE8290;DECE7582;DECE6875;D99_LOG;D90_LOG;D82_LOG;D75_LOG;D68_LOG;D99_RP;D90_RP;D82_RP;D75_RP;D68_RP;D99_RSECOCC;D90_RSECOCC;D82_RSECOCC;D75_RSECOCC;D68_RSECOCC;D99_LOGVAC;D90_LOGVAC;D82_LOGVAC;D75_LOGVAC;D68_LOGVAC;D99_PMEN;D90_NPER_RP;D82_NPER_RP;D75_NPER_RP;D68_NPER_RP;NAISD14;NAISD15;NAISD16;NAISD17;NAISD18;NAISD19;NAISD20;DECESD14;DECESD15;DECESD16;DECESD17;DECESD18;DECESD19;DECESD20;NBMENFISC18;NBPERSMENFISC18;MED18;PIMP18;TP6018;TP60AGE118;TP60AGE218;TP60AGE318;TP60AGE418;TP60AGE518;TP60AGE618;TP60TOL118;TP60TOL218;PACT18;PTSA18;PCHO18;PBEN18;PPEN18;PPAT18;PPSOC18;PPFAM18;PPMINI18;PPLOGT18;PIMPOT18;D118;D918;RD18;SNHM19;SNHMC19;SNHMP19;SNHME19;SNHMO19;SNHMF19;SNHMFC19;SNHMFP19;SNHMFE19;SNHMFO19;SNHMH19;SNHMHC19;SNHMHP19;SNHMHE19;SNHMHO19;SNHM1819;SNHM2619;SNHM5019;SNHMF1819;SNHMF2619;SNHMF5019;SNHMH1819;SNHMH2619;SNHMH5019;ETTOT18;ETAZ18;ETBE18;ETFZ18;ETGU18;ETGZ18;ETOQ18;ETTEF018;ETAZ018;ETBE018;ETFZ018;ETGU018;ETGZ018;ETOQ018;ETTEF118;ETAZ118;ETBE118;ETFZ118;ETGU118;ETGZ118;ETOQ118;ETTEF1018;ETAZ1018;ETBE1018;ETFZ1018;ETGU1018;ETGZ1018;ETOQ1018;ETTEF2018;ETAZ2018;ETBE2018;ETFZ2018;ETGU2018;ETGZ2018;ETOQ2018;ETTEF5018;ETAZ5018;ETBE5018;ETFZ5018;ETGU5018;ETGZ5018;ETOQ5018;ETPTOT18;ETPAZ18;ETPBE18;ETPFZ18;ETPGU18;ETPGZ18;ETPOQ18;ETPTEF118;ETPAZ118;ETPBE118;ETPFZ118;ETPGU118;ETPGZ118;ETPOQ118;ETPTEF1018;ETPAZ1018;ETPBE1018;ETPFZ1018;ETPGU1018;ETPGZ1018;ETPOQ1018;ETPTEF2018;ETPAZ2018;ETPBE2018;ETPFZ2018;ETPGU2018;ETPGZ2018;ETPOQ2018;ETPTEF5018;ETPAZ5018;ETPBE5018;ETPFZ5018;ETPGU5018;ETPGZ5018;ETPOQ5018;ETPTEFCP18;ETPAZCP18;ETPBECP18;ETPFZCP18;ETPGUCP18;ETPGZCP18;ETPOQCP18;ETPRES18;ETNPRES18;ETPRESPUB18;ETNPRESPUB18;ETPPRES18;ETPNPRES18;ETPPRESPUB18;ETPNPRESPUB18;ETASSMAT18;ETAUTRES18;ENNTOT20;ENNBE20;ENNFZ20;ENNGI20;ENNJZ20;ENNKZ20;ENNLZ20;ENNMN20;ENNOQ20;ENNRU20;ENCTOT20;ENCBE20;ENCFZ20;ENCGI20;ENCJZ20;ENCKZ20;ENCLZ20;ENCMN20;ENCOQ20;ENCRU20;ENCTOT19;ENCTOT18;ENCTOT17;ENCTOT16;ENCTOT15;ENCTOT14;ENCTOT13;ENCTOT12;ENCTOT11;ENCITOT20;ENCIBE20;ENCIFZ20;ENCIGI20;ENCIJZ20;ENCIKZ20;ENCILZ20;ENCIMN20;ENCIOQ20;ENCIRU20;ENCITOT19;ENCITOT18;ENCITOT17;ENCITOT16;ENCITOT15;ENCITOT14;ENCITOT13;ENCITOT12;ENCITOT11;ETNTOT20;ETNBE20;ETNFZ20;ETNGI20;ETNJZ20;ETNKZ20;ETNLZ20;ETNMN20;ETNOQ20;ETNRU20;ETCTOT20;ETCBE20;ETCFZ20;ETCGI20;ETCJZ20;ETCKZ20;ETCLZ20;ETCMN20;ETCOQ20;ETCRU20;ETCTOT19;ETCBE19;ETCFZ19;ETCGI19;ETCJZ19;ETCKZ19;ETCLZ19;ETCMN19;ETCOQ19;ETCRU19;ETCTOT18;ETCBE18;ETCFZ18;ETCGI18;ETCJZ18;ETCKZ18;ETCLZ18;ETCMN18;ETCOQ18;ETCRU18;ETCTOT17;ETCBE17;ETCFZ17;ETCGI17;ETCJZ17;ETCKZ17;ETCLZ17;ETCMN17;ETCOQ17;ETCRU17;ETCTOT16;ETCBE16;ETCFZ16;ETCGI16;ETCJZ16;ETCKZ16;ETCLZ16;ETCMN16;ETCOQ16;ETCRU16;ETCTOT15;ETCBE15;ETCFZ15;ETCGI15;ETCJZ15;ETCKZ15;ETCLZ15;ETCMN15;ETCOQ15;ETCRU15;ETCTOT14;ETCBE14;ETCFZ14;ETCGI14;ETCJZ14;ETCKZ14;ETCLZ14;ETCMN14;ETCOQ14;ETCRU14;ETCTOT13;ETCBE13;ETCFZ13;ETCGI13;ETCJZ13;ETCKZ13;ETCLZ13;ETCMN13;ETCOQ13;ETCRU13;ETCTOT12;ETCBE12;ETCFZ12;ETCGI12;ETCJZ12;ETCKZ12;ETCLZ12;ETCMN12;ETCOQ12;ETCRU12;ETCTOT11;ETCBE11;ETCFZ11;ETCGI11;ETCJZ11;ETCKZ11;ETCLZ11;ETCMN11;ETCOQ11;ETCRU11;HT21;HT021;HT121;HT221;HT321;HT421;HT521;HTCH21;HTCH021;HTCH121;HTCH221;HTCH321;HTCH421;HTCH521;CPG21;CPG021;CPG121;CPG221;CPG321;CPG421;CPG521;CPGE21;CPGE021;CPGE121;CPGE221;CPGE321;CPGE421;CPGE521;CPGEL21;CPGEL021;CPGEL121;CPGEL221;CPGEL321;CPGEL421;CPGEL521;CPGEO21;CPGEO021;CPGEO121;CPGEO221;CPGEO321;CPGEO421;CPGEO521;VV21;VVUH21;VVLIT21;RT21;RTUH21;RTLIT21;AJCS21;AJCSUH21;AJCSLIT21


def load_communes(meta_dossier_file: str = metaDossierFile, dossier_complet_file: str = dossierCompletFile):
    global metaDossier, dossierComplet
    if (metaDossier is None) or (dossierComplet is None):
        downloadFile(metaDossierSourceFile, dossierCompletFile, zip=True, zipped_file="dossier_complet.csv")
        print_blue("Lecture Meta Donnees Communes : " + metaDossierFile + " ...")
        metaDossier = pd.read_csv(meta_dossier_file, delimiter=';', index_col=0)
        print_blue("Lecture Donnees Communes : " + dossier_complet_file + " ...")
        dossierComplet = pd.read_csv(dossier_complet_file, delimiter=';', dtype={"CODGEO": "string"}, index_col=0)
    return metaDossier, dossierComplet

#####################
### Artificialisation
#####################

artificialisationSourcePage = "https://artificialisation.biodiversitetousvivants.fr/les-donnees-au-1er-janvier-2020"
artificialisationSourceFile = "https://cerema.app.box.com/v/pnb-action7-indicateurs-ff/file/862179205781"
artificialisationSourceMeta = "https://artificialisation.biodiversitetousvivants.fr/sites/artificialisation/files/fichiers/2021/08/description%20indicateurs%202009%202020.pdf"
dossierArtificialisationFile = data_dir + "obs_artif_conso_com_2009_2020_V2.csv"
dossierArtificialisation = None
global_context["URL_SOURCE_ARTIFICIALISATION"] = artificialisationSourcePage

# idcom,idcomtxt,idreg,idregtxt,iddep,iddeptxt,epci20,epci20txt,aav2020,libaav2020,cateaav2020,naf09art10,art09act10,art09hab10,art09mix10,art09inc10,naf10art11,art10act11,art10hab11,art10mix11,art10inc11,naf11art12,art11act12,art11hab12,art11mix12,art11inc12,naf12art13,art12act13,art12hab13,art12mix13,art12inc13,naf13art14,art13act14,art13hab14,art13mix14,art13inc14,naf14art15,art14act15,art14hab15,art14mix15,art14inc15,naf15art16,art15act16,art15hab16,art15mix16,art15inc16,naf16art17,art16act17,art16hab17,art16mix17,art16inc17,naf17art18,art17act18,art17hab18,art17mix18,art17inc18,naf18art19,art18act19,art18hab19,art18mix19,art18inc19,naf19art20,art19act20,art19hab20,art19mix20,art19inc20,nafart0920,artact0920,arthab0920,artmix0920,artinc0920,artcom0920,pop12,pop17,pop1217,men12,men17,men1217,emp17,emp12,emp1217,mepart1217,menhab1217,artpop1217,surfcom20


def load_artificialisation(dossier_artificialisation_file: str = dossierArtificialisationFile):
    global dossierArtificialisation
    downloadFile(artificialisationSourceFile, dossierArtificialisationFile)
    if (dossierArtificialisation is None):
        print_blue("Lecture Donnees Artificialisation : " + dossier_artificialisation_file + " ...")
        dossierArtificialisation = pd.read_csv(dossier_artificialisation_file, delimiter=',', index_col=0, dtype={"idcom": str, "iddep": str, "epci20": str, "aav2020" : str})
    return dossierArtificialisation


###
### Collect Data Description
###

collectDataFile    = configurationFile
collectDataMetrics = None
collectDiagnostics = None

# Key	Description	Source	Type	Data	Total
# Key	Description	Test    Message


def load_collectData(collect_file: str = collectDataFile):
    global collectDataMetrics, collectDiagnostics
    if (collectDataMetrics is None) :
        print_blue("Lecture Data Metrics : " + collect_file + " ...")
        xls = pd.ExcelFile(collect_file)
        collectDataMetrics = pd.read_excel(xls, 'Collect',    index_col=0, dtype=str)
        collectDiagnostics = pd.read_excel(xls, 'Diagnostic', index_col=0, dtype=str)
    return collectDataMetrics

###
### File Management
###

def delete_patten(dir = output_dir, pattern = "*.bck"):
    # Get a list of all the file paths that ends with .txt from in specified directory
    fileList = glob.glob(output_dir+ext)
    # Iterate over the list of filepaths & remove each file.
    for filePath in fileList:
        try:
            os.remove(filePath)
        except:
            print("Error while deleting file : ", filePath)

###
### Display in Browser
###

DISPLAY_HTML = True


def display_in_browser(html_file):
    if DISPLAY_HTML is False : return
    webbrowser.open_new_tab(html_file)


###
### Utils
###


def downloadFile(url: str, filename: str, zip=False, zipped_file: str = None) -> str:
    """ Download Files and Unzip"""
    if (os.path.isfile(filename)): return filename
    print_red("Downloading : "+filename)
    local_filename = filename
    with requests.get(url, stream=True) as r:
        r.raise_for_status()
        with open(local_filename, 'wb') as f:
            i = 1
            for chunk in r.iter_content(chunk_size=8192):
                i = i + 1
                print(".", end="")
                if i == 150:
                    print("")
                    i = 1
                f.write(chunk)
        f.close()
        print("")
    if (zip):
        print_red("Unzipping : " + filename)
        with zipfile.ZipFile(local_filename, 'r') as zip_ref:
            zip_ref.extractall("zip")
        shutil.move('zip' + os.sep + zipped_file, filename)
    print_red("Exctracted : " + local_filename)
    return local_filename


def round0(value, rounding=0) -> Union[float, int] :
    if (value != value) : value = 0  # NaN
    if (rounding == 0): return int(round(value, 0))
    return round(value, rounding)


def round0str(value, rounding=0) -> str :
    val = round0(value, rounding)
    if (rounding == 0) : return str(val)
    if (rounding == 1) : return f"{val:.1f}"
    if (rounding == 2) : return f"{val:.2f}"
    if (rounding == 3) : return f"{val:.3f}"
    if (rounding == 4) : return f"{val:.4f}"
    if (rounding == 5) : return f"{val:.5f}"
    return f"{val:.6}"


def perCent(value, rounding=0) -> float :
    return round0(value * 100, rounding)


def perCentStr(value, rounding=0) -> str :
    return round0str(value * 100, rounding)+"%"


def clean_name(name: str) -> str:
    return unidecode.unidecode(name).replace(" ", "_").replace("\\", "_").replace("'", "_")


### Print
def print_green(text):
    print(colored(text, "green"))


def print_red(text):
    print(colored(text, "red"))


def print_yellow(text):
    print(colored(text, "yellow"))


def print_grey(text):
    print(colored(text, "grey"))


def print_blue(text):
    print(colored(text, "blue"))


def print_data(p_data_dict: dict):
    for l_key in p_data_dict.keys():
        print(l_key + " : " + str(p_data_dict[l_key]))


def print_data_frame(p_data_frame: pd.DataFrame, code_insee: str):
    for column in p_data_frame:
        print(column + " - " + str(p_data_frame[column]["meta"]) + " : " + str(p_data_frame[column][code_insee]))


def print_commune(commune):
    if (isinstance(commune, int)):
        print(str(commune)+" : "+nom_commune(commune))
        return
    for comm in commune :
        print(str(comm)+" : "+nom_commune(comm))
    return


def print_epci(ecpi) -> dict :
    if (isinstance(ecpi, int)):
        print(str(ecpi)+" : "+nom_epci(ecpi))
        return
    for ep in ecpi :
        print(str(ep)+" : "+nom_epci(ep))
    return


def print_dept(dept) -> dict :
    if (isinstance(dept, int)):
        print(str(dept)+" : "+nom_dept(dept))
        return
    for dp in dept :
        print(str(dp)+" : "+nom_dept(dp))
    return


def to_json(obj,  indent=4):
    return(jsonc.dumps(obj,  indent=indent))


def to_yaml(obj,  indent=4):
    return(yaml.safe_dump(obj,  indent=indent, default_flow_style=False))


def save_file(data, file_name: str):
    try:
        with open(file_name, 'w') as outfile:
            outfile.write(str(data))
            outfile.close()
    except Exception as e:
        print_red("Error Writing File : " + file_name + "-" + str(e))
        raise


## Save figure for HTML Format
def fig_to_base64(figure):
    img = io.BytesIO()
    figure.savefig(img, format='png', bbox_inches='tight')
    img.seek(0)
    return base64.b64encode(img.getvalue())


## Calculate Population Evolution and Rate
def calc_after(annee_depart : int, pop_depart, annee_arrivee : int, taux_croissance, rounding=3) -> float :
    """ Retourne l'after )) : P1 = P0 x ( 1 + T/100) puissance N """
    annee = annee_arrivee - annee_depart
    pop_arrivee = pop_depart * (1 + taux_croissance / 100) ** annee
    return round0(pop_arrivee, rounding)


def calc_taux(annee_depart : int, pop_depart, annee_arrivee : int, pop_arrivee, rounding=3) -> float :
    """ Retourne le taux  : T/100 = [ P1/P0 ] puissance 1/N - 1 """
    annee = annee_arrivee - annee_depart
    taux_croissance = (pop_arrivee / pop_depart) ** (1 / annee)
    return round0(- (1 - taux_croissance) * 100, rounding)


def taux(part, total, rounding=3) -> float :
    """ Retourne le taux """
    return round0(part/total, rounding)


## Data Access
def get_code_insee_commune(code_postal) -> [int, str]:
    """ Retourne le code insee et le nom de la commune """
    load_codes()
    the_list = codesPostaux.index[codesPostaux['Code_postal'] == code_postal].tolist()
    if (not the_list):
        return "Pas de Code Postal pour code Postal "+str(code_postal), "Pas de Commune pour code Postal "+str(code_postal)
    code_insee = the_list[0]
    commune = codesPostaux["Nom_commune"][code_insee]
    if not isinstance(commune, str) : commune = commune[0]
    return code_insee, commune


def get_code_postal_commune(code_insee) -> [int, str]:
    """ Retourne le code postal et le nom de la commune """
    load_codes()
    try:
        code_postal = codesPostaux["Code_postal"][code_insee]
    except Exception as e:
        code_postal = "Pas de Code Postal pour Code INSEE "+str(code_insee)
        commune     = "Pas de Commune pour Code INSEE "+str(code_insee)
        return code_postal, commune
    if (not isinstance(code_postal, str)):
        code_postal = code_postal[0]
        commune     = codesPostaux["Nom_commune"][code_insee][0]
        return code_postal, commune
    commune     = codesPostaux["Nom_commune"][code_insee]
    return code_postal, commune


def get_code_insee(code_postal : Union[int, str]) -> int:
    """ Le Code INSEE du Code Postal """
    load_codes()
    if (isinstance(codesPostaux["Code_commune_INSEE"][code_postal], str)):
        code_insee = codesPostaux["Code_commune_INSEE"][code_postal]
    else:
        code_insee = codesPostaux["Code_commune_INSEE"][code_postal][0]
    return code_insee


def nom_epci(code_epci, clean=False) -> str:
    """ Le nom de l'EPCI """
    if (code_epci == 0) : return "Pas de Nom"
    load_interco()
    nom = intercoDossier[intercoDossier["Unnamed: 2"] == code_epci].head(1)["Unnamed: 3"][0]
    if (clean): return nom
    return clean_name(nom) + "_" + str(code_epci)


def nom_dept(code_dept, clean=False) -> str:
    """ Le nom du Departement """
    if (code_dept == 0) : return "Pas de Nom"
    load_departements()
    nom = departements["nom_departement"][code_dept]
    if (clean): return nom
    return clean_name(nom) + "_" + str(code_dept)


def nom_commune(code_insee=None, code_postal=None, clean=False) -> str:
    """ Le nom de la commune """
    load_codes()
    commune = "Pas de nom"
    if (code_insee)  : code_postal, commune = get_code_postal_commune(code_insee)
    if (code_postal) : code_insee,  commune = get_code_insee_commune(code_postal)
    nom = str(commune).title()
    if (clean): return nom
    return clean_name(nom) + "_" + str(code_insee)


def nom_region(code_region, clean=False) -> str:
    """ Le nom de Region """
    if (code_region == 0) : return "Pas de Nom"
    load_departements()
    nom     = departements[departements["code_region"] == code_region]['nom_region'].to_list()[0]
    if (clean): return nom
    return clean_name(nom) + "_" + str(code_region)


def communes_epci(code_epci) -> list[int]:
    """ Les Codes INSEE des Communes d'une EPCI """
    load_interco()
    index = intercoDossier.index
    condition = intercoDossier["Unnamed: 2"] == code_epci
    epci_indices = index[condition]
    epci_indices_list = epci_indices.tolist()
    return sorted(epci_indices_list)


def communes_dept(code_dept) -> list[int]:
    """ Les Codes INSEE des Communes d'un Departement """
    load_interco()
    index = intercoDossier.index
    condition = intercoDossier["Unnamed: 4"] == code_dept
    epci_indices = index[condition]
    epci_indices_list = epci_indices.tolist()
    return sorted(epci_indices_list)


def communes_region(code_reg) -> list[int]:
    """ Les Codes INSEE des Communes d'une Region """
    load_interco()
    index = intercoDossier.index
    condition    = intercoDossier["Unnamed: 5"] == code_reg
    epci_indices = index[condition]
    epci_indices_list = epci_indices.tolist()
    return sorted(epci_indices_list)


def epci_dept(code_dept) -> list[int]:
    """ Les Codes INSEE des EPCI d'un Departement """
    load_interco()
    epci_list    = intercoDossier[intercoDossier["Unnamed: 4"] == code_dept]["Unnamed: 2"]
    return sorted(list(set(epci_list)))


def dept_epci(code_epci) -> int :
    """ Le Code de Departement de l'EPCI """
    load_interco()
    epci_list    = intercoDossier[intercoDossier["Unnamed: 2"] == code_epci]["Unnamed: 4"]
    if epci_list.empty : return 0
    return epci_list[0]


def region_epci(code_epci) -> int :
    """ Le Code de Region de l'EPCI """
    load_interco()
    epci_list    = intercoDossier[intercoDossier["Unnamed: 2"] == code_epci]["Unnamed: 5"]
    if epci_list.empty : return 0
    return epci_list[0]


def region_dept(code_dept) -> int :
    """ Le Code de Region du Departement """
    load_interco()
    reg_list    = intercoDossier[intercoDossier["Unnamed: 4"] == code_dept]["Unnamed: 5"]
    if reg_list.empty : return 0
    return reg_list[0]


def list_dept(code_region = None) -> list[int]:
    """ La liste des Departements """
    load_departements()
    liste_dept = sorted(list(map(str, list(set(departements.index.values.tolist())))))
    if (code_region):
        liste_dept_region = []
        for dept in liste_dept :
            if (str(region_dept(dept)) == str(code_region)):
                liste_dept_region.append(dept)
        return liste_dept_region
    else:
        return liste_dept


def epci_region(code_reg) -> list[int]:
    """ Les EPCI d'une Region """
    load_interco()
    epci_list    = intercoDossier[intercoDossier["Unnamed: 5"] == code_reg]["Unnamed: 2"]
    return sorted(list(set(epci_list)))


def epci_commune(code_commune) -> int:
    """ L'EPCI d'une Commune """
    load_interco()
    epci_list    = intercoDossier[intercoDossier.index == str(code_commune)]["Unnamed: 2"]#
    if epci_list.size == 0 : return None
    return epci_list[0]


def list_region() -> list[int]:
    """ La liste des Regions """
    load_departements()
    return list(map(str, sorted(list(set(departements["code_region"])))))


def get_sru2017(key, code_insee, rounding=6):
    """ Retourne la valeur comsolidee de la cle SRU 17-19 pour la commune  """
    load_sru(sruFile)
    try:
        return round0(sru2017[key][int(code_insee)], rounding)
    except Exception as e:
        return 0


def get_sru2020(key, code_insee, rounding=6):
    """ Retourne la valeur comsolidee de la cle SRU 20-22 pour la commune  """
    load_sru(sruFile)
    try:
        return round0(sru2020[key][int(code_insee)], rounding)
    except Exception as e:
        return 0


def get_art(key, code_insee, rounding=6):
    """ Retourne la valeur comsolidee de la cle ART pour la commune  """
    load_artificialisation()
    try:
        return round0(dossierArtificialisation[key][code_insee], rounding)
    except Exception as e:
        return 0


###
### Data Collection and Consolidation
###

int_insee_datas = [
                    "P08_POP",     "P13_POP",      "P18_POP",
                    "P08_LOG",     "P13_LOG",      "P18_LOG",
                    "P08_RP",      "P13_RP",       "P18_RP",
                    "P08_RSECOCC", "P13_RSECOCC",  "P18_RSECOCC",
                    "P08_LOGVAC",  "P13_LOGVAC",  "P18_LOGVAC",
                    "P08_MAISON",  "P13_MAISON",  "P18_MAISON",
                    "P08_APPART",  "P13_APPART",  "P18_APPART",
                    "C08_MEN",     "C13_MEN",     "C18_MEN",
                    "C08_PMEN",    "C13_PMEN",    "C18_PMEN",
                    "P08_RP_PROP", "P13_RP_PROP", "P18_RP_PROP",
                    "P08_RP_LOC",  "P13_RP_LOC",  "P18_RP_LOC",
                    "NAIS0813",    "NAIS1318",
                    "DECE0813",    "DECE1318",
                  ]

source_data    = "DATA"
source_codes   = "CODE"
source_interco = "INTERCO"
source_insee   = "INSEE"
source_calc    = "CALC"
source_sru     = "SRU"
source_art     = "ART"
source_proj    = "PROJ"
source_evol    = "EVOL"
source_sit     = "SIT"

mode_sum       = "SUM"
mode_ignore    = "IGNORE"
mode_equal     = "EQUAL"
mode_count     = "COUNT"
mode_custom    = "CUSTOM"
mode_na        = "N/A"
mode_average   = "AVG"

type_int       = "INT"
type_str       = "STR"
type_taux      = "TAUX"
type_percent   = "PERCENT"
type_float     = "FLOAT"

entite_commune = "COMMUNE"
entite_epci    = "EPCI"
entite_dept    = "DEPT"
entite_region  = "REGION"
entite_scot    = "SCOT"

DataStoreCache = {}


class DataStore():

    def __init__(self, store_name : str, store_type : str, store_code : str):
        self.store_name  = store_name   # Name of Commune, EPCI, DEPT, REGION ...
        self.store_type  = store_type   # Type of Entity for Store :  "COMMUNE", "EPCI", "DEPT", "REGION"
        self.store_code  = store_code   # Code INSEE for "COMMUNE", "EPCI", for pour "DEPT", "REGION"
        self.store_index = store_code   # Working Index : Code INSEE for "COMMUNE", "total" pour tables multi-communes
        if (self.store_type != entite_commune) : self.store_index = "total"
        self.data_frame  = pd.DataFrame()
        self.key_datas   = []  # Metric Keys
        self.meta_dict   = {}  # Semantic of this indicator / metric
        self.type_dict   = {}  # { "INT", "STR",    "TAUX",  "PERCENT", "FLOAT" }
        self.source_dict = {}  # { "SRU", "INSEE",  "ART",   "SIT",     "DATA", "PROJ", "EVOL", "CALC" }
        self.mode_dict   = {}  # { "SUM", "IGNORE", "EQUAL", "COUNT",   "CUSTOM", "N/A", "AVG" }
        self.error_dict  = {}  # Error while processing this indicator / metric
        self.metric_list = []  # List of Metrics for Rendering
        self.diagnostics = []  # List of Diagnostic for Rendering
        self.html        = None

    def add_metric(self, key : str, meta : str, source: str, mode : str, type: str, index : str = None, data=None):
        """ Add a metric to the data store """
        self.key_datas.append(key)
        self.meta_dict[key]    = meta
        self.source_dict[key]  = source
        self.type_dict[key]    = type
        self.mode_dict[key]    = mode
        self.error_dict[key]   = "OK"
        self.metric_list.append({"key" : key , "meta" : meta , "source" : source , "type" : type, "mode" : mode})
        return self.add_data(key, index, data)

    def add_diagnostic(self, _key:str, _description:str, test:str, message:str, data : bool):
        """ Add a diagnostic to the data store """
        diagnostic = { "key" : _key , "description" : _description , "test" : test , "message" : message, "value" : data }
        self.diagnostics.append(diagnostic)
        return diagnostic

    def add_data(self, key : str, index : str, data):
        """ Add a data to the data store - with type checking """
        if (data  is None): return
        if (key   is None): return
        if (index is None): index = self.store_index
        if (index is None): return
        try:
            if (self.type_dict[key]   == "STR")     : return self.add_value(key, index, str(data))
            elif (self.type_dict[key] == "INT")     : return self.add_value(key, index, int(round(data, 0)))
            elif (self.type_dict[key] == "FLOAT")   : return self.add_value(key, index, float(data))
            elif (self.type_dict[key] == "TAUX")    : return self.add_value(key, index, float(data))
            elif (self.type_dict[key] == "PERCENT") : return self.add_value(key, index, float(data))
            else:
                self.error_dict[key] = "Invalid Type  [" + str(index) + "][" + str(key) + "] - Not a " + self.type_dict[key] + " :  " + str(data)
                print_red(self.error_dict[key])
                self.add_value(key, index, str(data))
                quit()
                return None
        except Exception as e:
            self.error_dict[key] = "Type Error [" + str(index) + "][" + str(key) + "] - Not a " + self.type_dict[key] + " :  " + str(data) + " : " + str(e)
            print_red(self.error_dict[key])
            self.add_value(key, index, str(data))
            quit()
            return None
        return None

    def add_value(self, key : str, index : str, data):
        """ Add a raw value to the data store.  """
        self.data_frame.at[index, key] = data
        return data

    def __getitem__(self, key):
        return self.get(key=key, index=None)

    def __setitem__(self, key, value):
        return self.add_data(key, self.store_index, value)

    def get(self, key : str, index : str = None):
        """ Return a value from data store.  """
        if (key   is None): return None
        if (index is None): index = self.store_index
        if (index is None): return None
        return self.data_frame.at[index, key]

    def get_row_as_dict(self, index : str = None):
        """ Return a raw as a dict with keys as keys.  """
        if (index is None): index = self.store_index
        if (index is None): return None
        dc = {}
        for key in self.key_datas:
            dc[key] = self.get(key, index)
        return dc

    def get_fullname(self):
        """ Datastore name for file name.  """
        fullname = str(self.store_type) + "_" + str(self.store_name) + "_" + str(self.store_code)
        return clean_name(fullname)

    def save_data(self):
        # DF TO EXCEL
        writer = pd.ExcelWriter(output_dir + self.get_fullname() + ".xlsx")
        self.data_frame.to_excel(writer, "Data")
        pivot = self.data_frame.transpose()
        pivot.to_excel(writer, "Pivot")
        diagdf = self.data_frame.from_dict(self.diagnostics)
        diagdf.to_excel(writer,"Diagnotics")
        writer.save()
        writer.close()
        # DF TO CSV
        self.data_frame.to_csv(output_dir + self.get_fullname() + ".csv", sep=',')
        # DF TO JSON
        with open(output_dir + self.get_fullname() + "_c.json", 'w') as f:
            global_context["JSON_DATA_SET_C"] = to_json(jsonc.loads(self.data_frame.to_json(orient='index')), indent=4)
            f.write(global_context["JSON_DATA_SET_C"])
        all = {}
        for name, values in self.data_frame.iteritems():
            all[name] = {}
            for name2, value2 in values.iteritems():
                all[name][name2] = value2
        with open(output_dir + self.get_fullname() + "_m.json", 'w') as f:
            global_context["JSON_DATA_SET_M"] = to_json(all, indent=4)
            f.write(global_context["JSON_DATA_SET_M"])

    def load_data(self):
        # EXCEL to DF
        filename = output_dir + self.get_fullname() + ".xlsx"
        if not os.path.isfile(filename) : return None
        print_green("Chargement Donnees : "+filename)
        xls = pd.ExcelFile(filename)
        self.data_frame  = pd.read_excel(xls, 'Data', index_col=0)
        self.key_datas   = list(self.data_frame.columns.values)
        self.meta_dict   = self.get_row_as_dict('meta')
        self.mode_dict   = self.get_row_as_dict('mode')
        self.type_dict   = self.get_row_as_dict('type')
        self.source_dict = self.get_row_as_dict('source')
        return self.data_frame

    def number(self, key, round=0, suffix="") -> str:
        return round0str(self.data_frame[key][self.store_index], round)+suffix

    def str(self, key) -> str:
        return str(self.data_frame[key][self.store_index])

    def taux(self, key, round=2, suffix="") -> str:
        val = self.data_frame[key][self.store_index]
        if (suffix == "%"): val = val * 100
        return round0str(val, round)+suffix

    def tauxp100(self, key, round=2) -> str:
        return round0str(self.data_frame[key][self.store_index] * 100, round)+"%"

    def percent(self, key, round=2, suffix="%") -> str:
        return round0str(self.data_frame[key][self.store_index], round) + suffix

    def getHTML(self) -> str:
        if (self.html) : return self.html
        self.render_report()
        return self.html

    def render_report(self, template=html_report_template):
        # Building Mako Template Context
        context = {**self.get_row_as_dict(), **global_context}
        metric_list = []
        for metric in self.metric_list :
            metric['value'] = self[metric['key']]
            metric_list.append(metric)
        context["METRICS"] = metric_list
        diag_list = []
        for diagnostic in self.diagnostics :
            diag_list.append(diagnostic)
        context["DIAGNOSTICS"] = diag_list
        context["COMMUNE"] = str(context["NOM_COMMUNE"]).title()
        save_file(to_yaml(context), context_file)
        # Rendering Template
        mako.runtime.UNDEFINED = 'MISSING_CONTEXT'
        temp = Template(filename=template)
        self.html = temp.render(**context)
        # Saving to File
        p_html_file = output_dir + self.get_fullname() + ".html"
        f = open(p_html_file, 'w')
        f.write(self.html)
        f.close()
        return p_html_file

    # Add Meta Data
    def add_meta_data(self):
        self.data_frame = self.data_frame.append(pd.Series(self.meta_dict,   name='meta'))
        self.data_frame = self.data_frame.sort_index(ascending=False)        # sorting by index
        self.data_frame = self.data_frame.append(pd.Series(self.mode_dict,   name='mode'))
        self.data_frame = self.data_frame.append(pd.Series(self.type_dict,   name='type'))
        self.data_frame = self.data_frame.append(pd.Series(self.source_dict, name='source'))
        return self

    # Get Data Frame without Meta Data - Clean Meta Data
    def clean_meta_data(self, inplace=True) :
        clean_data_frame = self.data_frame
        if 'meta'   in clean_data_frame.index : clean_data_frame.drop(labels="meta",   axis=0, inplace=inplace)
        if 'mode'   in clean_data_frame.index : clean_data_frame.drop(labels="mode",   axis=0, inplace=inplace)
        if 'type'   in clean_data_frame.index : clean_data_frame.drop(labels="type",   axis=0, inplace=inplace)
        if 'source' in clean_data_frame.index : clean_data_frame.drop(labels="source", axis=0, inplace=inplace)
        return clean_data_frame

    def collect_data(self, code_postal=None, code_insee=None):

        commune = "Pas de Nom"
        if (code_postal):
            code_insee, commune = get_code_insee_commune(code_postal)

        if (code_insee):
            code_postal, commune = get_code_postal_commune(code_insee)

        if (str(code_insee) in DataStoreCache) :
            print_green("Cached Donnees : " + str(code_postal) + " : " + commune + " (Code INSEE : " + code_insee + ")")
            return DataStoreCache[code_insee]

        save_index       = self.store_index
        self.store_index = code_insee

        print_green("Collecte Donnees : " + str(code_postal) + " : " + commune + " (Code INSEE : " + code_insee + ")")

        # Donnees Commune
        self.add_metric("CODE_INSEE",     "Code INSEE Commune",        source=source_codes,    mode=mode_count, data=code_insee,       type="STR")
        self.add_metric("CODE_POSTAL",    "Code Postal Commune",       source=source_codes,    mode=mode_count, data=code_postal,      type="STR")
        self.add_metric("NOM_COMMUNE",    "Nom de Commune",            source=source_codes,    mode=mode_count, data=commune,          type="STR")
        self.add_metric("LIBELLE",        "Libelle",                   source=source_codes,    mode=mode_count, data=commune.title(),  type="STR")

        # Donnees EPCI
        self.add_metric("EPCI",      "Code EPCI - Métropole",          source=source_interco,  mode=mode_count, data=intercoDossier["Unnamed: 2"][code_insee],       type="STR")
        self.add_metric("LIBEPCI",   "Libellé de l'EPCI / Métropole",  source=source_interco,  mode=mode_count, data=intercoDossier["Unnamed: 3"][code_insee],       type="STR")
        self.add_metric("TYPE_EPCI", "Nature d'EPCI",                  source=source_interco,  mode=mode_count, data=intercoEPCI["Unnamed: 2"][self.get("EPCI")],      type="STR")
        self.add_metric("EPCI_COMMUNES", "Nombre communes EPCI",       source=source_interco,  mode=mode_count, data=intercoEPCI["Unnamed: 3"][self.get("EPCI")],      type="INT")
        self.add_metric("DEP",       "Departement",                    source=source_interco,  mode=mode_count, data=intercoDossier["Unnamed: 4"][code_insee],       type="STR")
        self.add_metric("DEP_NOM",   "Nom Departement",                source=source_interco,  mode=mode_count, data=departements["nom_departement"][self.get("DEP")], type="STR")
        self.add_metric("REG",       "Region",                         source=source_interco,  mode=mode_count, data=intercoDossier["Unnamed: 5"][code_insee],       type="STR")
        self.add_metric("REG_NOM",   "Nom Région",                     source=source_interco,  mode=mode_count, data=departements["nom_region"][self.get("DEP")],      type="STR")
        url_dossier = "https://www.insee.fr/fr/statistiques/2011101?geo=COM-" + self.str("CODE_INSEE")
        self.add_metric("DOSSIER_INSEE", "Dossier Complet INSEE",      source=source_insee,    mode=mode_custom, data=url_dossier,      type="STR")
        global_context["URL_SOURCE_DOSSIER"] = url_dossier

        # Donnees INSEE Commune
        load_communes()
        for data in int_insee_datas:
            donnee = dossierComplet[data][code_insee]
            self.add_metric(data,  metaDossier["LIB_VAR_LONG"][data],  source=source_insee,  mode=mode_sum, data=int(round0(donnee)), type="INT")

        # Donnees Commune Calculees
        self.add_metric("TXPOP_0818", "Taux de Croissance Annuel de la population de 2008 a 2018",
                      source=source_insee,  mode=mode_custom, type="PERCENT",
                      data=calc_taux(2008, self.get("P08_POP"), 2018, self.get("P18_POP")))
        self.add_metric("TXPOP_0813", "Taux de Croissance Annuel de la population de 2008 a 2013",
                      source=source_insee,  mode=mode_custom, type="PERCENT",
                      data=calc_taux(2008, self.get("P08_POP"), 2013, self.get("P13_POP")))
        self.add_metric("TXPOP_1318", "Taux de Croissance Annuel de la population de 2013 a 2018",
                      source=source_insee,  mode=mode_custom, type="PERCENT",
                      data=calc_taux(2013, self.get("P13_POP"), 2018, self.get("P18_POP")))
        self.add_metric("TM_2008", "Taille des Menages en 2008",
                      source=source_insee,  mode=mode_custom, type="FLOAT",
                      data=round(self.get("C08_PMEN") / self.get("C08_MEN"), 3))
        self.add_metric("TM_2013", "Taille des Menages en 2013",
                      source=source_insee,  mode=mode_custom, type="FLOAT",
                      data=round(self.get("C13_PMEN") / self.get("C13_MEN"), 3))
        self.add_metric("TM_2018", "Taille des Menages en 2018",
                      source=source_insee,  mode=mode_custom, type="FLOAT",
                      data=round(self.get("C18_PMEN") / self.get("C18_MEN"), 3))
        self.add_metric("TXTM_0813", "Taux de Croissance Annuel de la taille des menages de 2008 a 2013",
                      source=source_insee,  mode=mode_custom, type="PERCENT",
                      data=calc_taux(2008, self.get("TM_2008"), 2013, self.get("TM_2013")))
        self.add_metric("TXTM_1318", "Taux de Croissance Annuel de la taille des menages de 2013 a 2018",
                      source=source_insee,  mode=mode_custom, type="PERCENT",
                      data=calc_taux(2013, self.get("TM_2013"), 2018, self.get("TM_2018")))
        self.add_metric("TXTM_0818", "Taux de Croissance Annuel de la taille des menages de 2008 a 2018",
                      source=source_insee,  mode=mode_custom, type="PERCENT",
                      data=calc_taux(2008, self.get("TM_2008"), 2018, self.get("TM_2018")))

        # Donnees SRU
        load_sru()
        self.add_metric(key="SRU_OBJ_2017_2019", meta="Objectifs 2017-2019",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=get_sru2017("Objectifs SRU 2017-2019", code_insee, rounding=0))
        self.add_metric(key="SRU_LLS_2017", meta="NB de LLS au 01/01/2017",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=get_sru2017("NB de LLS au 01/01/2017", code_insee, rounding=0))
        self.add_metric(key="SRU_TX_LLS_2017", meta="TX de LLS au 01/01/2017",
                      source=source_sru,  mode=mode_custom, type="TAUX",
                      data=get_sru2017("TX de LLS au 01/01/2017", code_insee, rounding=4))
        self.add_metric(key="SRU_RP_2017", meta="NBR RP au 01/01/2017",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=get_sru2017("NBR RP au 01/01/2017", code_insee, rounding=0))
        self.add_metric(key="SRU_OBJ_TX", meta="Taux de LLS à atteindre",
                      source=source_sru,  mode=mode_ignore, type="PERCENT",
                      data=get_sru2017("Taux de LLS à atteindre", code_insee, rounding=2))

        self.add_metric(key="SRU_OBJ_2020_2022", meta="Objectifs 2020-2022",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=get_sru2020("Objectifs SRU 2020-2022", code_insee, rounding=0))
        self.add_metric(key="SRU_LLS_2020", meta="NB de LLS au 01/01/2020",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=get_sru2020("NB de LLS au 01/01/2020", code_insee, rounding=0))
        self.add_metric(key="SRU_TX_LLS_2020", meta="TX de LLS au 01/01/2020",
                      source=source_sru,  mode=mode_custom, type="TAUX",
                      data=get_sru2020("TX de LLS au 01/01/2020", code_insee, rounding=4))
        self.add_metric(key="SRU_RP_2020", meta="NBR RP au 01/01/2020",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=get_sru2020("NBR RP au 01/01/2020", code_insee, rounding=0))
        self.add_metric(key="SRU_OBJ_TX", meta="Taux de LLS à atteindre",
                      source=source_sru,  mode=mode_ignore, type="TAUX",
                      data=get_sru2020("Taux de LLS à atteindre", code_insee, rounding=2))

        # Donnees SRU Calculees
        self.add_metric(key="SRU_CARENCE_2017", meta="Carence en 2017",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=round0(self.get("SRU_RP_2017") * (0.25 - self.get("SRU_TX_LLS_2017")), 4))

        self.add_metric(key="SRU_CARENCE_2020", meta="Carence en 2020",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=round0(self.get("SRU_RP_2020") * (0.25 - self.get("SRU_TX_LLS_2020")), 4))

        self.add_metric(key="SRU_LOG3565_2017", meta="Logements Totaux a Construire en Modele 35/65 sur Objectif 2017",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=round0(self.get("SRU_OBJ_2017_2019")/35*65, 0))

        self.add_metric(key="SRU_LOG3565_2020", meta="Logements Totaux a Construire en Modele 35/65 sur Objectif 2020",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=round0(self.get("SRU_OBJ_2020_2022")/35*65, 0))

        self.add_metric(key="SRU_LOG3565_TOTAL", meta="Logements Totaux a Construire en Modele 35/65 sur Carence Totale 2020",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=round0(self.get("SRU_CARENCE_2020")/35*65, 0))

        self.add_metric(key="SRU_EVOL_RP", meta="Evolution du nombre de Residences Principales",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=round0(self.get("SRU_RP_2020")-self.get("SRU_RP_2017"), 0))

        self.add_metric(key="SRU_EVOL_CARENCE", meta="Evolution de la Carence du aux Residences Principales",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=round0((self.get("SRU_RP_2020") - self.get("SRU_RP_2017")) * 0.25, 0))

        self.add_metric(key="SRU_LOG_CONSTRUITS", meta="Logements Sociaux Construits entre 2017 et 2020",
                      source=source_sru,  mode=mode_sum, type="INT",
                      data=round0(self.get("SRU_CARENCE_2017")  + self.get("SRU_EVOL_CARENCE")  - self.get("SRU_CARENCE_2020") , 0))

        # Donnee Artificialisation
        load_artificialisation()
        self.add_metric(key="ART_TOTAL", meta="Total des flux entre NAF et artificialisé sur la période 2009 2020",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("nafart0920", code_insee))
        self.add_metric(key="ART_HABITAT", meta="Flux NAF vers artificialisé destiné à l’habitat sur la période 2009 2020",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("arthab0920", code_insee))
        self.add_metric(key="ART_ACTIVITE", meta="Flux NAF vers artificialisé destiné à l’activité sur la période 2009 2020",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("artact0920", code_insee))
        self.add_metric(key="ART_MIXTE", meta="Flux NAF vers artificialisé destiné au mixte sur la période 2009 2020",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("artmix0920", code_insee))
        self.add_metric(key="ART_INCONNUE", meta="Flux NAF vers artificialisé inconnu sur la période 2009 2020",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("artinc0920", code_insee))
        self.add_metric(key="SURFACE_COMMUNE", meta="Surface communale en m²",
                      source=source_art,  mode=mode_sum, type="FLOAT",
                      data=get_art("surfcom20", code_insee))
        self.add_metric(key="ART_POURCENT", meta="Part de surface communale artificialisée (en %)",
                      source=source_art,  mode=mode_custom, type="PERCENT",
                      data=get_art("artcom0920", code_insee))
        self.add_metric(key="ART_POPULATION", meta="M² artificialisé par habitant supplémentaire",
                      source=source_art,  mode=mode_ignore, type="INT",
                      data=get_art("artpop1217", code_insee))
        self.add_metric(key="ART_MENAGE", meta="M² artificialisé par menage supplémentaire",
                      source=source_art,  mode=mode_ignore, type="INT",
                      data=get_art("menhab1217", code_insee))
        self.add_metric(key="ART_EMPLOI_MENAGE", meta="Nombre de ménages + emplois supplémentaire par ha artificialisé",
                      source=source_art,  mode=mode_ignore, type="INT",
                      data=get_art("mepart1217", code_insee))
        self.add_metric(key="ART_EMPLOIS_2012", meta="Nombre d’emplois 2012",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("emp12", code_insee))
        self.add_metric(key="ART_EMPLOIS_2017", meta="Nombre d’emplois 2017",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("emp17", code_insee))
        self.add_metric(key="ART_EMPLOIS_1217", meta="Variation des Emplois entre 2012 et 2017",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("emp1217", code_insee))
        self.add_metric(key="ART_MENAGES_2012", meta="Nombre de menages 2012",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("men12", code_insee))
        self.add_metric(key="ART_MENAGES_2017", meta="Nombre de menages 2017",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("men17", code_insee))
        self.add_metric(key="ART_MENAGES_1217", meta="Variation des Menages entre 2012 et 2017",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("men1217", code_insee))
        self.add_metric(key="ART_POPULATION_2012", meta="Population en 2012",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("pop12", code_insee))
        self.add_metric(key="ART_POPULATION_2017", meta="Population en 2017",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("pop17", code_insee))
        self.add_metric(key="ART_POPULATION_1217", meta="Variation Population entre 2012 et 2017",
                      source=source_art,  mode=mode_sum, type="INT",
                      data=get_art("pop1217", code_insee))

        # Donnees Projections EPCI
        load_projections_paca()
        p_epci = projectionsPaca.loc[projectionsPaca["Unnamed: 1"] == int(self.get("EPCI"))]
        p_epci = p_epci.head(1)
        self.add_metric(key="PROJ_EPCI_NOM", meta="Nom EPCI",
                      source=source_proj,  mode=mode_equal, type="STR",
                      data=p_epci["Unnamed: 2"].iloc[0]  if (p_epci.shape[0] == 1) else self.get("EPCI"))
        self.add_metric(key="PROJ_EPCI_2013", meta="Projection Population EPCI 2013",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=p_epci["Unnamed: 4"].iloc[0]  if (p_epci.shape[0] == 1) else 0)
        self.add_metric(key="PROJ_EPCI_2030", meta="Projection Population EPCI 2030",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=p_epci["Unnamed: 8"].iloc[0]  if (p_epci.shape[0] == 1) else 0)
        self.add_metric(key="PROJ_EPCI_2050", meta="Projection Population EPCI 2050",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=p_epci["Unnamed: 12"].iloc[0]  if (p_epci.shape[0] == 1) else 0)
        self.add_metric(key="PROJ_EPCI_2040", meta="Projection Population EPCI 2040",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=(self.get("PROJ_EPCI_2030") + self.get("PROJ_EPCI_2050")) / 2  if (p_epci.shape[0] == 1) else 0)
        self.add_metric(key="PROJ_EPCI_2020", meta="Projection Population EPCI 2020",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=(self.get("PROJ_EPCI_2013") + self.get("PROJ_EPCI_2030")) / 2  if (p_epci.shape[0] == 1) else 0)

        # Donnees Projections SCOT
        load_projections_paca()
        p_scot = projectionsPaca.loc[projectionsPaca["Projection selon quatre scénarios à l'horizon 2030 et 2050  "] == "SCOT_50_000_ou_plus"]
        p_scot = p_scot.loc[p_scot["Unnamed: 1"].astype(str).str.contains(self.get("EPCI"))]
        p_scot = p_scot.head(1)
        self.add_metric(key="PROJ_SCOT_NOM", meta="Nom SCOT",
                      source=source_proj,  mode=mode_equal, type="STR",
                      data=p_scot["Unnamed: 2"].iloc[0]  if (p_epci.shape[0] == 1) else self.get("EPCI"))
        self.add_metric(key="PROJ_SCOT_2013", meta="Projection Population SCOT 2013",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=p_scot["Unnamed: 4"].iloc[0]  if (p_epci.shape[0] == 1) else 0)
        self.add_metric(key="PROJ_SCOT_2030", meta="Projection Population SCOT 2030",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=p_scot["Unnamed: 8"].iloc[0]  if (p_epci.shape[0] == 1) else 0)
        self.add_metric(key="PROJ_SCOT_2050", meta="Projection Population SCOT 2050",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=p_scot["Unnamed: 12"].iloc[0]  if (p_epci.shape[0] == 1) else 0)
        self.add_metric(key="PROJ_SCOT_2040", meta="Projection Population SCOT 2040",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=(self.get("PROJ_SCOT_2030") + self.get("PROJ_SCOT_2050") / 2  if (p_epci.shape[0] == 1) else 0))
        self.add_metric(key="PROJ_SCOT_2020", meta="Projection Population SCOT 2020",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=(self.get("PROJ_SCOT_2013") + self.get("PROJ_SCOT_2030") / 2  if (p_epci.shape[0] == 1) else 0))

        # Donnees Projections Departement 2013-2050
        load_projections()
        self.add_metric(key="PROJ_DPT_2013", meta="Projection Dept 2013",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=projectionsDPT["Unnamed: 2"][self.get("DEP")] * 1000)
        self.add_metric(key="PROJ_DPT_2018", meta="Projection Dept 2018", type="INT",
                      source=source_proj,  mode=mode_equal,
                      data=projectionsDPT["Unnamed: 7"][self.get("DEP")] * 1000)
        self.add_metric(key="PROJ_DPT_TXPOP_1318", meta="Taux de Croissance Annuel de la population de 2013 a 2018",
                      source=source_proj,  mode=mode_equal, type="PERCENT",
                      data=calc_taux(2013, self.get("PROJ_DPT_2013"), 2018, self.get("PROJ_DPT_2018")))
        self.add_metric(key="PROJ_DPT_2020", meta="Projection Dept 2020",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=projectionsDPT["Unnamed: 9"][self.get("DEP")] * 1000)
        self.add_metric(key="PROJ_DPT_TXPOP_1820", meta="Taux de Croissance Annuel de la population de 2018 a 2020",
                      source=source_proj,  mode=mode_equal, type="PERCENT",
                      data=calc_taux(2018, self.get("PROJ_DPT_2018"), 2020, self.get("PROJ_DPT_2020")))
        self.add_metric(key="PROJ_DPT_TXPOP_1320", meta="Taux de Croissance Annuel de la population de 2013 a 2020",
                      source=source_proj,  mode=mode_equal, type="PERCENT",
                      data=calc_taux(2013, self.get("PROJ_DPT_2013"), 2020, self.get("PROJ_DPT_2020")))
        self.add_metric(key="PROJ_DPT_2030", meta="Projection Dept 2030",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=projectionsDPT["Unnamed: 19"][self.get("DEP")] * 1000)
        self.add_metric(key="PROJ_DPT_TXPOP_2030", meta="Taux de Croissance Annuel de la population de 2020 a 2030",
                      source=source_proj,  mode=mode_equal, type="PERCENT",
                      data=calc_taux(2020, self.get("PROJ_DPT_2020"), 2030, self.get("PROJ_DPT_2030")))
        self.add_metric(key="PROJ_DPT_2040", meta="Projection Dept 2040",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=projectionsDPT["Unnamed: 29"][self.get("DEP")] * 1000)
        self.add_metric(key="PROJ_DPT_TXPOP_3040", meta="Taux de Croissance Annuel de la population de 2030 a 2040",
                      source=source_proj,  mode=mode_equal, type="PERCENT",
                      data=calc_taux(2030, self.get("PROJ_DPT_2030"), 2040, self.get("PROJ_DPT_2040")))
        self.add_metric(key="PROJ_DPT_2050", meta="Projection Dept 2050",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=projectionsDPT["Unnamed: 39"][self.get("DEP")] * 1000)
        self.add_metric(key="PROJ_DPT_TXPOP_4050", meta="Taux de Croissance Annuel de la population de 2040 a 2050",
                      source=source_proj,  mode=mode_equal, type="PERCENT",
                      data=calc_taux(2040, self.get("PROJ_DPT_2040"), 2050, self.get("PROJ_DPT_2050")))

        # Donnees Projections Region 2013-2050
        load_projections()
        self.add_metric(key="PROJ_REG_2013", meta="Projection Region 2013",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=projectionsREG["Unnamed: 2"][self.get("REG")] * 1000)
        self.add_metric(key="PROJ_REG_2018", meta="Projection Region 2018",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=projectionsREG["Unnamed: 7"][self.get("REG")] * 1000)
        self.add_metric(key="PROJ_REG_2020", meta="Projection Region 2020",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=projectionsREG["Unnamed: 9"][self.get("REG")] * 1000)
        self.add_metric(key="PROJ_REG_2030", meta="Projection Region 2030",
                      source=source_proj,  mode=mode_equal, type="INT",
                      data=projectionsREG["Unnamed: 19"][self.get("REG")] * 1000)
        self.add_metric(key="PROJ_REG_2040", meta="Projection Region 2040", type="INT",
                      source=source_proj,  mode=mode_equal,
                      data=projectionsREG["Unnamed: 29"][self.get("REG")] * 1000)
        self.add_metric(key="PROJ_REG_2050", meta="Projection Region 2050", type="INT",
                      source=source_proj,  mode=mode_equal,
                      data=projectionsREG["Unnamed: 39"][self.get("REG")] * 1000)

        # Donnees Evolution 2008-2021
        load_evolution()
        self.add_metric(key="EVOL_DPT_POP08", meta="Population Dept en 2008",
                        source=source_proj,  mode=mode_equal, type="INT",
                        data=round(evolution0813["Unnamed: 1"][self.get("DEP_NOM")]))
        self.add_metric(key="EVOL_DPT_POP13", meta="Population Dept en 2013", type="INT",
                        source=source_proj,  mode=mode_equal,
                        data=round(evolution1318["Unnamed: 1"][self.get("DEP_NOM")]))
        self.add_metric(key="EVOL_DPT_POP18", meta="Population Dept en 2018", type="INT",
                        source=source_proj,  mode=mode_equal,
                        data=round(evolution1821["Unnamed: 1"][self.get("DEP_NOM")]))
        self.add_metric(key="EVOL_DPT_0813", meta="Taux Evolution Annuel Population Dept entre 2008 et 2013",
                        source=source_proj,  mode=mode_equal, type="TAUX",
                        data=round(evolution0813["Unnamed: 2"][self.get("DEP_NOM")], 3))
        self.add_metric(key="EVOL_DPT_1318", meta="Taux Evolution Annuel Population Dept entre 2013 et 2018",
                        source=source_proj,  mode=mode_equal, type="TAUX",
                        data=round(evolution1318["Unnamed: 2"][self.get("DEP_NOM")], 3))
        self.add_metric(key="EVOL_DPT_1821", meta="Taux Evolution Annuel Population Dept entre 2018 et 2021",
                        source=source_proj,  mode=mode_equal, type="TAUX",
                        data=round(evolution1821["Unnamed: 2"][self.get("DEP_NOM")], 3))
        self.add_metric(key="EVOL_DPT_POP21", meta="Population Dept en 2021",
                        source=source_proj,  mode=mode_equal, type="INT",
                        data=round(calc_after(2018, self.get("EVOL_DPT_POP18"), 2021, self.get("EVOL_DPT_1821"))))

        # Donnees Sitadel Logements
        load_sitadel()
        com_sitadel1 = sitadel1316.loc[sitadel1316['COMM'] == str(code_insee)]
        com_sitadel2 = sitadel1721.loc[sitadel1721['COMM'] == str(code_insee)]
        com_sitadel  = pd.concat([com_sitadel1, com_sitadel2])
        self.add_metric(key="NB_LGT_TOT_CREES", meta="Logements Autorises",
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=com_sitadel['NB_LGT_TOT_CREES'].sum())
        log_commences = com_sitadel.loc[com_sitadel['Etat_DAU'] == 5]
        log_termines  = com_sitadel.loc[com_sitadel['Etat_DAU'] == 6]
        self.add_metric(key="NB_LGT_TOT_COMMENCES", meta="Logements Commences",
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=log_commences['NB_LGT_TOT_CREES'].sum() + log_termines['NB_LGT_TOT_CREES'].sum())
        log_commences1316 = com_sitadel1.loc[com_sitadel1['Etat_DAU'] == 5]
        log_termines1316  = com_sitadel1.loc[com_sitadel1['Etat_DAU'] == 6]
        self.add_metric(key="NB_LGT_TOT_COMMENCES_1316", meta="Logements Commences entre 2013 et 2016",
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=log_commences1316['NB_LGT_TOT_CREES'].sum() + log_termines1316['NB_LGT_TOT_CREES'].sum())
        log_commences1721 = com_sitadel2.loc[com_sitadel2['Etat_DAU'] == 5]
        log_termines1721  = com_sitadel2.loc[com_sitadel2['Etat_DAU'] == 6]
        self.add_metric(key="NB_LGT_TOT_COMMENCES_1721", meta="Logements Commences entre 2017 et 2021",
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=log_commences1721['NB_LGT_TOT_CREES'].sum() + log_termines1721['NB_LGT_TOT_CREES'].sum())
        self.add_metric(key="NB_LGT_TX_REALISATION", meta="Taux de Logements Commences",
                        source=source_proj,  mode=mode_custom,  type="TAUX",
                        data=0 if self.get("NB_LGT_TOT_CREES") == 0 else self.get("NB_LGT_TOT_COMMENCES") / self.get("NB_LGT_TOT_CREES"))
        log_renouv = com_sitadel.loc[com_sitadel['NATURE_PROJET'] == 2]
        self.add_metric(key="NB_LGT_RENOUVELLEMENT", meta="Logements en Renouvellement",
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=log_renouv['NB_LGT_TOT_CREES'].sum())
        log_nouveau = com_sitadel.loc[com_sitadel['NATURE_PROJET'] == 1]
        self.add_metric(key="NB_LGT_NOUVEAU", meta="Logements Nouveau",
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=log_nouveau['NB_LGT_TOT_CREES'].sum())
        log_principal = com_sitadel.loc[com_sitadel['RES_PRINCIP_OU_SECOND'] == 1]
        self.add_metric(key="NB_LGT_PRINCIPAL", meta="Logements Principal", type="INT",
                        source=source_proj,  mode=mode_sum,
                        data=log_principal['NB_LGT_TOT_CREES'].sum())
        log_secondaire = com_sitadel.loc[com_sitadel['NATURE_PROJET'] == 2]
        self.add_metric(key="NB_LGT_SECONDAIRE", meta="Logements Secondaire",
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=log_secondaire['NB_LGT_TOT_CREES'].sum())
        self.add_metric(key="NB_LGT_IND_CREES", meta=sitadelMeta['Description de la variable']['NB_LGT_IND_CREES'],
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=com_sitadel['NB_LGT_IND_CREES'].sum())
        self.add_metric(key="NB_LGT_COL_CREES", meta=sitadelMeta['Description de la variable']['NB_LGT_COL_CREES'],
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=com_sitadel['NB_LGT_COL_CREES'].sum())
        self.add_metric(key="NB_LGT_DEMOLIS", meta=sitadelMeta['Description de la variable']['NB_LGT_DEMOLIS'],
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=com_sitadel['NB_LGT_DEMOLIS'].sum())
        self.add_metric(key="NB_LGT_PRET_LOC_SOCIAL", meta=sitadelMeta['Description de la variable']['NB_LGT_PRET_LOC_SOCIAL'],
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=com_sitadel['NB_LGT_PRET_LOC_SOCIAL'].sum())
        self.add_metric(key="NB_LGT_PRET_LOC_SOCIAL_1316", meta="Logements Sociaux entre 2013 et 2016",
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=com_sitadel1['NB_LGT_PRET_LOC_SOCIAL'].sum())
        self.add_metric(key="NB_LGT_PRET_LOC_SOCIAL_1721", meta="Logements Sociaux entre 2017 et 2021",
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=com_sitadel2['NB_LGT_PRET_LOC_SOCIAL'].sum())
        self.add_metric(key="SITADEL_SUPERFICIE_TERRAIN", meta=sitadelMeta['Description de la variable']['SUPERFICIE_TERRAIN'],
                        source=source_proj,  mode=mode_sum, type="INT",
                        data=com_sitadel['SUPERFICIE_TERRAIN'].sum())

        # Donnees Sitadel Locaux
        load_sitadel_locaux()
        com_sitadelLocaux1 = sitadel_locaux_1316.loc[sitadel_locaux_1316['COMM'] == str(code_insee)]
        com_sitadelLocaux2 = sitadel_locaux_1721.loc[sitadel_locaux_1721['COMM'] == str(code_insee)]
        com_sitadelLocaux  = pd.concat([com_sitadelLocaux1, com_sitadelLocaux2])
        loc_commences      = com_sitadelLocaux.loc[com_sitadelLocaux['Etat_DAU'] == 5]
        loc_termines       = com_sitadelLocaux.loc[com_sitadelLocaux['Etat_DAU'] == 6]
        loc_commences1316  = com_sitadelLocaux1.loc[com_sitadelLocaux1['Etat_DAU'] == 5]
        loc_termines1316   = com_sitadelLocaux1.loc[com_sitadelLocaux1['Etat_DAU'] == 6]
        loc_commences1721  = com_sitadelLocaux2.loc[com_sitadelLocaux2['Etat_DAU'] == 5]
        loc_termines1721   = com_sitadelLocaux2.loc[com_sitadelLocaux2['Etat_DAU'] == 6]
        loc_nouveau        = com_sitadelLocaux.loc[com_sitadelLocaux['NATURE_PROJET'] == 1]
        # These will be loaded from Collect Excel


        # Projections Calculees
        self.add_metric(key="TX_POP_2030", meta="Taux Evolution de la Population entre 2020 et 2030",
                      source=source_proj,  mode=mode_custom, type="PERCENT",
                      data=self.get("PROJ_DPT_TXPOP_2030"))
        self.add_metric(key="TX_POP_3040", meta="Taux Evolution de la Population entre 2030 et 2040",
                      source=source_proj,  mode=mode_custom, type="PERCENT",
                      data=self.get("PROJ_DPT_TXPOP_2030"))
        self.add_metric(key="TX_POP_4050", meta="Taux Evolution de la Population entre 2040 et 2050",
                      source=source_proj,  mode=mode_custom, type="PERCENT",
                      data=self.get("PROJ_DPT_TXPOP_4050"))
        self.add_metric(key="POP_2020", meta="Population en 2020",
                      source=source_proj,  mode=mode_sum, type="INT",
                      data=round(calc_after(2018, self.get("P18_POP"), 2020, self.get("TXTM_1318"))))
        self.add_metric(key="POP_2030", meta="Population en 2030",
                      source=source_proj,  mode=mode_sum, type="INT",
                      data=round(calc_after(2020, self.get("POP_2020"), 2030, self.get("TX_POP_2030"))))
        self.add_metric(key="POP_2040", meta="Population en 2040",
                      source=source_proj,  mode=mode_sum, type="INT",
                      data=round(calc_after(2030, self.get("POP_2030"), 2040, self.get("TX_POP_3040"))))
        self.add_metric(key="POP_2050", meta="Population en 2050",
                      source=source_proj,  mode=mode_sum, type="INT",
                      data=round(calc_after(2040, self.get("POP_2040"), 2050, self.get("TX_POP_4050"))))
        self.add_metric(key="TM_2020", meta="Taille des Menages en 2020",
                      source=source_proj,  mode=mode_custom, type="FLOAT",
                      data=calc_after(2018, self.get("TM_2018"), 2020, self.get("TXTM_1318")))
        self.add_metric(key="TM_2030", meta="Taille des Menages en 2030",
                      source=source_proj,  mode=mode_custom, type="FLOAT",
                      data=calc_after(2020, self.get("TM_2020"), 2030, self.get("TXTM_1318") / 2))
        self.add_metric(key="TM_2040", meta="Taille des Menages en 2040",
                      source=source_proj,  mode=mode_custom, type="FLOAT",
                      data=calc_after(2020, self.get("TM_2030"), 2030, self.get("TXTM_1318") / 3))
        self.add_metric(key="TM_2050", meta="Taille des Menages en 2050",
                      source=source_proj,  mode=mode_custom, type="FLOAT",
                      data=calc_after(2040, self.get("TM_2040"), 2050, self.get("TXTM_1318") / 4))
        self.add_metric(key="LOG_2020", meta="Besoins en Logements en 2020",
                      source=source_proj,  mode=mode_sum, type="INT",
                      data=round(self.get("POP_2020") / self.get("TM_2020")))
        self.add_metric(key="LOG_2030", meta="Besoins en Logements en 2030",
                      source=source_proj,  mode=mode_sum, type="INT",
                      data=round(self.get("POP_2030") / self.get("TM_2030")))
        self.add_metric(key="LOG_2040", meta="Besoins en Logements en 2040",
                      source=source_proj,  mode=mode_sum, type="INT",
                      data=round(self.get("POP_2040") / self.get("TM_2040")))
        self.add_metric(key="LOG_2050", meta="Besoins en Logements en 2050",
                      source=source_proj,  mode=mode_sum, type="INT",
                      data=round(self.get("POP_2050") / self.get("TM_2050")))

        self.add_metric(key="P20_RP", meta="Logements en 2020",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=round(self.get("LOG_2020")))
        self.add_metric(key="TX_RES_SEC_18", meta="Taux de Residences Secondaires en 2018",
                      source=source_calc,  mode=mode_custom, type="TAUX",
                      data=round((self.get("P18_RSECOCC")) / (self.get("P18_RP") + self.get("P18_RSECOCC") + self.get("P18_LOGVAC")), 4))
        self.add_metric(key="TX_RES_VAC_18", meta="Taux de Residences Vacantes en 2018",
                      source=source_calc,  mode=mode_custom, type="TAUX",
                      data=round((self["P18_LOGVAC"])  / (self["P18_RP"] + self["P18_RSECOCC"] + self["P18_LOGVAC"]), 4))
        self.add_metric(key="P20_RSECOCC", meta="Residences Secondaires en 2020",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=round((self["P18_RSECOCC"]  / self["P18_RP"]) * self["LOG_2020"], 0))
        self.add_metric(key="P20_LOGVAC", meta="Residences Vacantes en 2020",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=round((self["P18_LOGVAC"]  / self["P18_RP"]) * self["LOG_2020"], 0))
        self.add_metric(key="P30_RSECOCC", meta="Residences Secondaires en 2030",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=round((self["P18_RSECOCC"]  / self["P18_RP"]) * self["LOG_2020"], 0))
        self.add_metric(key="P30_LOGVAC", meta="Residences Vacantes en 2030",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=round((self["P18_LOGVAC"]  / self["P18_RP"]) * self["LOG_2020"], 0))

        self.add_metric(key="NOUV_LOG_0813", meta="Nouveaux Logements (RP+RS+VAC) entre 2008 et 2013 (5 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["P13_RP"] - self["P08_RP"] + self["P13_RSECOCC"] - self["P08_RSECOCC"]  + self["P13_LOGVAC"] - self["P08_LOGVAC"]))
        self.add_metric(key="NOUV_LOG_1318", meta="Nouveaux Logements (RP+RS+VAC) entre 2013 et 2018 (5 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["P18_RP"] - self["P13_RP"] + self["P18_RSECOCC"] - self["P13_RSECOCC"]  + self["P18_LOGVAC"] - self["P13_LOGVAC"]))
        self.add_metric(key="NOUV_LOG_1820", meta="Nouveaux Logements (RP+RS+VAC) entre 2018 et 2020 (2 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["P20_RP"] - self["P18_RP"] + self["P20_RSECOCC"] - self["P18_RSECOCC"]  + self["P20_LOGVAC"] - self["P18_LOGVAC"]))
        self.add_metric(key="NOUV_LOG_1320", meta="Nouveaux Logements (RP+RS+VAC) entre 2013 et 2020 (7 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["P20_RP"] - self["P13_RP"] + self["P20_RSECOCC"] - self["P13_RSECOCC"]  + self["P20_LOGVAC"] - self["P13_LOGVAC"]))
        self.add_metric(key="NOUV_LOG_0820", meta="Nouveaux Logements (RP+RS+VAC) entre 2008 et 2020 (12 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["P20_RP"] - self["P08_RP"] + self["P20_RSECOCC"] - self["P08_RSECOCC"]  + self["P20_LOGVAC"] - self["P08_LOGVAC"]))
        self.add_metric(key="EXCES_BESOINS_0820", meta="Exces en Logements Construits par rapport aux besoins entre 2008 et 2020 (12 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["NOUV_LOG_0813"] + self["NB_LGT_TOT_COMMENCES_1316"] + self["NB_LGT_TOT_COMMENCES_1721"])    - (self["LOG_2020"] - self["P08_RP"]))
        self.add_metric(key="EXCES_BESOINS_1320", meta="Exces en Logements Construits par rapport aux besoins entre 2013 et 2020 (7 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["NB_LGT_TOT_COMMENCES_1316"] + self["NB_LGT_TOT_COMMENCES_1721"])    - (self["LOG_2020"] - self["P13_RP"]))
        self.add_metric(key="BESOINS_0813", meta="Besoins en Logements entre 2013 et 2020 (7 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["P13_RP"] - self["P08_RP"]))
        self.add_metric(key="BESOINS_1320", meta="Besoins en Logements entre 2013 et 2020 (7 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["LOG_2020"] - self["P13_RP"]))
        self.add_metric(key="BESOINS_0820", meta="Besoins en Logements entre 2008 et 2020 (12 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["LOG_2020"] - self["P08_RP"]))
        self.add_metric(key="NOUV_RESSEC_1320", meta="Nouvelles Residences Secondaires entre 2013 et 2020  (8 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["P20_RSECOCC"] - self["P13_RSECOCC"]))
        self.add_metric(key="NOUV_LOGVAC_1320", meta="Nouvelles Residences Vacantes entre 2013 et 2020  (8 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["P18_LOGVAC"] - self["P13_LOGVAC"]))
        self.add_metric(key="NOUV_RESSEC_1318", meta="Nouvelles Residences Secondaires entre 2013 et 2018  (8 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["P18_RSECOCC"] - self["P13_RSECOCC"]))
        self.add_metric(key="NOUV_LOGVAC_1318", meta="Nouvelles Residences Vacantes entre 2013 et 2018  (8 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["P18_LOGVAC"] - self["P13_LOGVAC"]))
        self.add_metric(key="NB_LGT_TOT_COMMENCES_1321", meta="Logements Construits entre 2013 et 2021  (8 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(round(self["NB_LGT_TOT_COMMENCES_1316"]   + self["NB_LGT_TOT_COMMENCES_1721"])))
        self.add_metric(key="NB_LGT_PRET_LOC_SOCIAL_1321", meta="Logements Sociaux Construits entre 2013 et 2020  (8 ans)",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(round(self["NB_LGT_PRET_LOC_SOCIAL_1316"]   + self["NB_LGT_PRET_LOC_SOCIAL_1721"])))
        self.add_metric(key="TX_LGT_PRET_LOC_SOCIAL_1321", meta="Taux de Construction de LS entre 2013 et 2020  (8 ans)",
                      source=source_calc,  mode=mode_custom, type="TAUX",
                      data=self["NB_LGT_PRET_LOC_SOCIAL_1321"] / self["NB_LGT_TOT_COMMENCES_1321"])
        self.add_metric(key="TX_LGT_PRET_LOC_SOCIAL_1316", meta="Taux de Construction de LS entre 2013 et 2016  (8 ans)",
                      source=source_calc,  mode=mode_custom, type="TAUX",
                      data=(round(self["NB_LGT_PRET_LOC_SOCIAL_1316"] / self["NB_LGT_TOT_COMMENCES_1316"], 4)))
        self.add_metric(key="TX_LGT_PRET_LOC_SOCIAL_1721", meta="Taux de Construction de LS  entre 2017 et 2021  (8 ans)",
                      source=source_calc,  mode=mode_custom, type="TAUX",
                      data=(round(self["NB_LGT_PRET_LOC_SOCIAL_1721"] / self["NB_LGT_TOT_COMMENCES_1721"], 4)))
        self.add_metric(key="LOG_NON_VENDUS_1320", meta="Logements Construits non encore vendus en 2020",
                      source=source_calc,  mode=mode_sum, type="INT",
                      data=(self["NB_LGT_TOT_COMMENCES_1321"] - self["NOUV_LOG_1320"]))

        # Collected Data
        _line = 0
        for index, metric in collectDataMetrics.iterrows():
            _line = _line + 1
            _key         = index
            _description = metric["Description"]
            _source      = metric["Source"]
            _type        = metric["Type"]
            _data        = str(metric["Data"])
            _total       = metric["Total"]
            if (str(_key) == "nan") : continue          # Empty Line
            if (str(_key).startswith("#")) : continue   # Ignore key starting with #
            # print_grey("Evaluating Metric " + str(_line) + ": " + str(_key) + " : " + str(_data))
            _data = re.sub("\${([A-Z0-9a-z-_]*)}", '\\1', _data)    # Replace ${VAR} by VAR
            try:
                value = eval(_data, self.get_row_as_dict(), {**globals(), **locals()} )
                self.add_metric(_key, _description, source=_source, mode=_total, data=value, type=_type)
            except Exception as e :
                error = "Error evaluating metrique : " + _key + " + eval : " + _data + " - Error : " + str(e)
                print_red(error)
                self.add_metric(_key, _description, source=_source, mode=_total, data=error, type=_type)

        self.store_index = save_index
        return self

    def total_data(self, meta=True):

        data_clean = self.clean_meta_data()
        if 'total'   in data_clean.index : data_clean.drop(labels="total",   axis=0, inplace=True)

        print_green("> Total Donnees : " + str(self.store_code) + " : " + self.store_name )

        total_dict = {}
        for key in self.key_datas:
            total_dict[key] = "ERROR Invalid Mode"
            mode = self.mode_dict[key]
            try:
                if (key == "CODE_INSEE"): total_dict[key] = self.store_index
                elif (mode == "SUM"):     total_dict[key] = data_clean[key].sum()
                elif (mode == "EQUAL"):   total_dict[key] = data_clean[key][0]
                elif (mode == "COUNT"):   total_dict[key] = data_clean.shape[0]
                elif (mode == "IGNORE"):  total_dict[key] = "IGNORE"
                elif (mode == "N/A"):     total_dict[key] = "N/A"
                elif (mode == "AVG"):     total_dict[key] = data_clean[key].average()
                elif (mode == "CUSTOM"):  total_dict[key] = "CUSTOM not Implemented"
                else:                     total_dict[key] = "CUSTOM not evaluated"
            except Exception as e:
                print(key)
                print("Exception : [" + str(mode) + " ] for key : [" + str(key) + "] : " + str(e))
                print(data_clean[key])
                quit()

        if (self.store_type == "COMMUNE"):
            total_dict["TYPE_EPCI"]     = "COMMUNE"
            url_dossier = "https://www.insee.fr/fr/statistiques/2011101?geo=COM-" + str(self.store_code)
            total_dict["DOSSIER_INSEE"]          = url_dossier
            global_context["URL_SOURCE_DOSSIER"] = url_dossier

        if (self.store_type == "EPCI"):
            total_dict["LIBELLE"]       = self.store_name
            total_dict["CODE_INSEE"]    = self.store_code
            total_dict["CODE_POSTAL"]   = "EPCI"
            total_dict["NOM_COMMUNE"]   = "EPCI"
            total_dict["EPCI"]          = self.store_code
            total_dict["LIBEPCI"]       = self.store_name
            total_dict["TYPE_EPCI"]     = "EPCI"
            total_dict["EPCI_COMMUNES"] = len(communes_epci(self.store_code))
            total_dict["DEP"]           = dept_epci(self.store_code)
            total_dict["DEP_NOM"]       = nom_dept(dept_epci(self.store_code), clean=True)
            total_dict["REG"]           = region_epci(self.store_code)
            total_dict["REG_NOM"]       = nom_region(region_epci(self.store_code), clean=True)
            url_dossier = "https://www.insee.fr/fr/statistiques/2011101?geo=EPCI-" + str(self.store_code)
            total_dict["DOSSIER_INSEE"]          = url_dossier
            global_context["URL_SOURCE_DOSSIER"] = url_dossier

        if (self.store_type == "DEPT"):
            total_dict["LIBELLE"]       = self.store_name
            total_dict["CODE_INSEE"]    = self.store_code
            total_dict["CODE_POSTAL"]   = "DEPT"
            total_dict["NOM_COMMUNE"]   = nom_dept(self.store_code, clean=True)
            total_dict["EPCI"]          = "DEPT"
            total_dict["LIBEPCI"]       = "DEPT"
            total_dict["TYPE_EPCI"]     = "DEPT"
            total_dict["EPCI_COMMUNES"] = len(communes_dept(self.store_code))
            total_dict["DEP"]           = self.store_code
            total_dict["DEP_NOM"]       = nom_dept(self.store_code, clean=True)
            total_dict["REG"]           = region_dept(self.store_code)
            total_dict["REG_NOM"]       = nom_region(region_dept(self.store_code), clean=True)
            url_dossier = "https://www.insee.fr/fr/statistiques/2011101?geo=DEP-" + str(self.store_code)
            total_dict["DOSSIER_INSEE"]          = url_dossier
            global_context["URL_SOURCE_DOSSIER"] = url_dossier

        if (self.store_type == "REGION"):
            total_dict["LIBELLE"]       = self.store_name
            total_dict["CODE_INSEE"]    = self.store_code
            total_dict["CODE_POSTAL"]   = "REGION"
            total_dict["NOM_COMMUNE"]   = nom_region(region_dept(self.store_code), clean=True)
            total_dict["EPCI"]          = "REGION"
            total_dict["LIBEPCI"]       = "REGION"
            total_dict["TYPE_EPCI"]     = "REGION"
            total_dict["EPCI_COMMUNES"] = len(communes_region(self.store_code))
            total_dict["DEP"]           = "REGION"
            total_dict["DEP_NOM"]       = "REGION"
            total_dict["REG"]           = self.store_code
            total_dict["REG_NOM"]       = nom_region(region_dept(self.store_code), clean=True)
            url_dossier = "https://www.insee.fr/fr/statistiques/2011101?geo=REG-" + str(self.store_code)
            total_dict["DOSSIER_INSEE"]          = url_dossier
            global_context["URL_SOURCE_DOSSIER"] = url_dossier

        # Custom
        total_dict["SRU_TX_LLS_2017"] = 0 if total_dict["SRU_RP_2017"] == 0 else round(total_dict["SRU_LLS_2017"] / total_dict["SRU_RP_2017"] if "SRU_RP_2017" in total_dict else 0, 3)
        total_dict["SRU_TX_LLS_2020"] = 0 if total_dict["SRU_RP_2020"] == 0 else round(total_dict["SRU_LLS_2020"] / total_dict["SRU_RP_2020"] if "SRU_RP_2020" in total_dict else 0, 3)
        total_dict["TXPOP_0818"]  = calc_taux(2008, total_dict["P08_POP"], 2018, total_dict["P18_POP"], rounding=3)
        total_dict["TXPOP_0813"]  = calc_taux(2008, total_dict["P08_POP"], 2013, total_dict["P13_POP"], rounding=3)
        total_dict["TXPOP_1318"]  = calc_taux(2013, total_dict["P13_POP"], 2018, total_dict["P18_POP"], rounding=3)
        total_dict["TM_2008"]     = round(total_dict["C08_PMEN"] / total_dict["C08_MEN"], 3)
        total_dict["TM_2013"]     = round(total_dict["C13_PMEN"] / total_dict["C13_MEN"], 3)
        total_dict["TM_2018"]     = round(total_dict["C18_PMEN"] / total_dict["C18_MEN"], 3)
        total_dict["TXTM_0818"]   = calc_taux(2008, total_dict["TM_2008"], 2018, total_dict["TM_2018"], rounding=3)
        total_dict["TXTM_0813"]   = calc_taux(2008, total_dict["TM_2008"], 2013, total_dict["TM_2013"], rounding=3)
        total_dict["TXTM_1318"]   = calc_taux(2013, total_dict["TM_2013"], 2018, total_dict["TM_2018"], rounding=3)
        total_dict["TM_2020"]     = round(total_dict["POP_2020"] / total_dict["LOG_2020"], 3)
        total_dict["TM_2030"]     = round(total_dict["POP_2030"] / total_dict["LOG_2030"], 3)
        total_dict["TM_2040"]     = round(total_dict["POP_2040"] / total_dict["LOG_2040"], 3)
        total_dict["TM_2050"]     = round(total_dict["POP_2050"] / total_dict["LOG_2050"], 3)
        total_dict["TX_POP_2030"] = calc_taux(2020, total_dict["POP_2020"], 2030, total_dict["POP_2030"], rounding=3)
        total_dict["TX_POP_3040"] = calc_taux(2030, total_dict["POP_2030"], 2040, total_dict["POP_2040"], rounding=3)
        total_dict["TX_POP_4050"] = calc_taux(2040, total_dict["POP_2040"], 2050, total_dict["POP_2050"], rounding=3)

        total_dict["TX_RES_SEC_18"] = round((total_dict["P18_RSECOCC"]) / (total_dict["P18_RP"] + total_dict["P18_RSECOCC"] + total_dict["P18_LOGVAC"]), 4)
        total_dict["TX_RES_VAC_18"] = round((total_dict["P18_LOGVAC"])  / (total_dict["P18_RP"] + total_dict["P18_RSECOCC"] + total_dict["P18_LOGVAC"]), 4)

        total_dict["TX_LGT_PRET_LOC_SOCIAL_1321"] = round((total_dict["NB_LGT_PRET_LOC_SOCIAL_1321"]) / (total_dict["NB_LGT_TOT_COMMENCES_1321"]), 4)
        total_dict["TX_LGT_PRET_LOC_SOCIAL_1316"] = round((total_dict["NB_LGT_PRET_LOC_SOCIAL_1316"]) / (total_dict["NB_LGT_TOT_COMMENCES_1316"]), 4)

        total_dict["NB_LGT_TX_REALISATION"] = 0 if total_dict["NB_LGT_TOT_CREES"] == 0 else round(total_dict["NB_LGT_TOT_COMMENCES"] / total_dict["NB_LGT_TOT_CREES"], 3)

        total_dict["ART_POURCENT"]          = 0 if total_dict["SURFACE_COMMUNE"]  == 0 else round(100 * total_dict["ART_TOTAL"] / total_dict["SURFACE_COMMUNE"], 3)

        for key in self.key_datas:
            mode = self.mode_dict[key]
            if (key == "CODE_INSEE"): continue
            elif (mode == "SUM"):     continue
            elif (mode == "EQUAL"):   continue
            elif (mode == "COUNT"):   continue
            elif (mode == "IGNORE"):  continue
            elif (mode == "N/A"):     continue
            elif (mode == "AVG"):     continue
            elif (mode == "CUSTOM"):  continue
            else:
                try:
                    mode = re.sub("\${([A-Z0-9a-z-_]*)}", '\\1', mode)    # Replace ${VAR} by VAR
                    total_dict[key] = eval(mode, self.get_row_as_dict(), globals())
                except Exception as e:
                    error = "Error evaluating metrique total mode : " + key + " + eval : " + mode + " - Error : " + str(e)
                    print_red(error)
                    total_dict[key] = error

        # Store in Data Frame
        if (meta):
            # Add Meta Data
            self.data_frame = self.data_frame.append(pd.Series(self.meta_dict,   name='meta'))
            self.data_frame = self.data_frame.sort_index(ascending=False)        # sorting by index
            self.data_frame = self.data_frame.append(pd.Series(total_dict,       name="total"))
            self.data_frame = self.data_frame.append(pd.Series(self.mode_dict,   name='mode'))
            self.data_frame = self.data_frame.append(pd.Series(self.type_dict,   name='type'))
            self.data_frame = self.data_frame.append(pd.Series(self.source_dict, name='source'))
        else:
            # Store in Data Frame
            self.data_frame = self.data_frame.append(pd.Series(total_dict, name="total"))

        update_DataStoreCache(self)
        return self

    def run_diagnostic(self):

        load_min_data()
        _line = 0
        for index, metric in collectDiagnostics.iterrows():
            _line = _line + 1
            _key         = index  # Key
            _description = metric["Description"]
            _test        = str(metric["Test"])
            _message     = metric["Message"]
            if (str(_key) == "nan") : continue          # Ignore empty lines
            if (str(_key).startswith("#")) : continue   # Ignore key starting with #
            # print_grey("Evaluating Diagnostic " + str(_line) + ": " + str(_key) + " : " + str(_test))
            _data = re.sub("\${([A-Z0-9a-z-_]*)}", '\\1', _test)    # Replace ${VAR} by VAR
            try:
                value = bool(eval(_test, self.get_row_as_dict(), {**globals(), **locals()}))
                self.add_diagnostic(_key, _description, test=_test, message=_message, data=value)
            except Exception as e :
                error = "Error evaluating Diagnostic : " + _key + " + eval : " + _test + " - Error : " + str(e)
                print_red(error)
                self.add_diagnostic(_key, _description, test=_test, message=error, data=value)
        return self

    def report(self, force=True):

        load_min_data()
        print_yellow("Preparation Rapport "+self.store_type + " " + self.store_name + " (Code INSEE : "+self.store_code+")")
        loaded = None
        if (force is False) :
            loaded = self.load_data()
        if (force is True) or (loaded is None):
            if (self.store_type == entite_commune):
                self.collect_data(code_insee=self.store_code)
                self.total_data(meta=True)
                self.store_index = self.store_code
            if (self.store_type == entite_epci):
                for commune in communes_epci(self.store_code):
                    self.collect_data(code_insee=commune)
                self.total_data(meta=True)
                self.store_index = 'total'
            if (self.store_type == entite_dept):
                for commune in communes_dept(self.store_code):
                    self.collect_data(code_insee=commune)
                self.total_data(meta=True)
                self.store_index = 'total'
            if (self.store_type == entite_region):
                for commune in communes_region(self.store_code):
                    self.collect_data(code_insee=commune)
                self.total_data(meta=True)
                self.store_index = 'total'

        self.run_diagnostic()
        html_report_file = gen_report(ds=self)
        html_index_file  = gen_index()
        display_in_browser(html_index_file)
        return self


def update_DataStoreCache(ds : DataStore, code_insee=None):
    if code_insee and ((isinstance(code_insee, int)) or (isinstance(code_insee, str))):
        DataStoreCache[str(code_insee)] = ds
        print_green("Added in Cache : DataStore with code INSEE " + str(ds.store_code) + " : "  + ds.store_name)
    elif (isinstance(ds["CODE_INSEE"], int)) or (isinstance(ds["CODE_INSEE"], str)):
        DataStoreCache[str(ds.data_frame["CODE_INSEE"])] = ds
        print_green("Added in Cache : DataStore with code INSEE " + str(ds["CODE_INSEE"]) + " : "  + ds.store_name)
    else:
        print_red("Not Added in Cache : DataStore without code INSEE : " + ds.store_name)

def render_index(template=html_index_template):
    # Building Mako Template Context
    context = {**report_region_dict(region="93", filename=regions_file), **global_context}
    # Rendering Template
    mako.runtime.UNDEFINED = 'MISSING_CONTEXT'
    temp = Template(filename=template)
    index_html = temp.render(**context)
    # Saving to File
    p_html_file = output_dir + "index.html"
    f = open(p_html_file, 'w')
    f.write(index_html)
    f.close()
    return p_html_file


'''
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.image import MIMEImage
from email.mime.base import MIMEBase
from email import encoders
import glob

def email_html_report(self, ka: KPI_Analysis, kc: KPI_Configuration, p_to_address=""):

        if (p_to_address != ""):
            to_address = p_to_address
        else:
            to_address = kc.get_Parameter("to_address", "bheuse@gmail.com")

        from_address = kc.get_Parameter("from_address", "bheuse@gmail.com")
        subject = kc.get_Parameter("Subject", "KPI Report")
        subject = subject + " : " + kc.account + " " + kc.system
        if (ka.has_exceptions()):
            subject = "Exceptions - " + subject

        # Create message container - the correct MIME type is multipart/alternative.
        msg = MIMEMultipart('alternative')
        msg['Subject'] = subject
        msg['From'] = from_address
        msg['To'] = to_address

        # Record the MIME types of both parts - text/plain and text/html.
        part1 = MIMEText(ka.get_report_text(), 'plain')
        part2 = MIMEText(self.generate_html_report("", "1"), 'html')

        # Attach parts into message container (HTML & Text Versions).
        msg.attach(part1)
        msg.attach(part2)

        html_report = kc.get_Parameter("html_report")
        xlsx_report = kc.get_Parameter("xlsx_report")
        # Attach Images (Graphs).
        for file in glob.glob(ku.change_basename(html_report, "*.png")):
            # Open the files in binary mode - MIMEImage understand image type.
            fp = open(file, 'rb')
            img = MIMEImage(fp.read())
            fp.close()
            cid = "<" + os.path.basename(file).replace(".png", "") + ">"
            img.add_header("Content-ID", cid)
            msg.attach(img)

        # Attach XLSX Report.
        if (self.report_excel):
            fp = open(xlsx_report, 'rb')
            xls = MIMEBase('application', 'vnd.ms-excel')
            xls.set_payload(fp.read())
            fp.close()
            encoders.encode_base64(xls)
            xls.add_header('Content-Disposition', 'attachment', filename=xlsx_report)
            msg.attach(xls)

        # Serveur SMTP : smtp.gmail.com
        # Utilisateur SMTP: Votre nom d’utilisateur complet dans Gmail (adresse e-mail), par exemple votremail@gmail.com
        # Mot de passe SMTP : votre mot de passe Gmail.
        # Port SMTP : 465
        # TLS / SSL : Obligatoire.
        SMTP_Address = kc.get_Parameter("SMTP_Address", 'smtp.gmail.com')
        SMTP_Port = kc.get_Parameter("SMTP_Port", 465)
        SMTP_User = kc.get_Parameter("SMTP_User", "bheuse@gmail.com")
        SMTP_Password = kc.get_Parameter("SMTP_Password", kc.deobfuscate("ccKjwpnCmMKgwpbCqXBp"))

        print("Sending Email to : " + to_address)
        try:
            # Send the message via local SMTP server.
            email_server = smtplib.SMTP_SSL(SMTP_Address, SMTP_Port)
            email_server.login(SMTP_User, SMTP_Password)
            # sendmail function takes 3 arguments: sender's address, recipient's address
            # and message to send - here it is sent as one string.
            email_server.sendmail(from_address, to_address, msg.as_string())
            email_server.quit()
            print("Sent Email")
        except:
            print(colored("Sending Email Failed", "red"))
            raise
'''


###
### HTML Reports & Plotting
###


def report_diagnostic(ds: DataStore):
    # Diagnostic Report
    data_html = "<h3>" + "Diagnostic des Donnees" + "</h3>"
    for diagnostic in ds.diagnostics:
        if (diagnostic["value"]==True):
            data_html = data_html + "<p style=color:green;>" + " OK  : "      + str(diagnostic["message"]) + "</p>"
        else:
            data_html = data_html + "<p style=color:red;>"   + " Problem  : " + str(diagnostic["message"]) + "</p>"
    return data_html


def report_source(ds: DataStore):
    # Summary Table
    data_html = "<h3>" + "Sources de Donnees" + "</h3>"
    data_html = data_html + "<p>" + "Artificialisation :    <a target=\"_blank\" href=\"" + artificialisationSourcePage + "\">Dossier Cerema  </a>" + "</p>"
    data_html = data_html + "<p>" + "Logements Sociaux :    <a target=\"_blank\" href=\"" + sru2020SourcePage           + "\">Dossier Dreal   </a>" + "</p>"
    data_html = data_html + "<p>" + "Logements Construits : <a target=\"_blank\" href=\"" + sitadelSourcePage           + "\">Dossier Sitadel </a>" + "</p>"
    data_html = data_html + "<p>" + "Donnees Communes :     <a target=\"_blank\" href=\"" + metaDossierSourcePage       + "\">Dossier Insee   </a>" + "</p>"
    data_html = data_html + "<p>" + "Projections 2050 :     <a target=\"_blank\" href=\"" + projectionsSourcePage       + "\">Dossier Insee   </a>" + "</p>"
    data_html = data_html + "<p>" + "Projections Paca :     <a target=\"_blank\" href=\"" + projectionsPacaSourcePage   + "\">Dossier Omphale </a>" + "</p>"
    data_html = data_html + "<p>" + "Dossier " + ds.str("NOM_COMMUNE").title() + "  :  <a target=\"_blank\" href=\"" + ds["DOSSIER_INSEE"] + "\">Dossier Insee   </a>" + "</p>"
    global_context["HTML_SOURCES"] = data_html
    return data_html


def report_sru(ds: DataStore):
    data_dict = ds.get_row_as_dict(ds.store_index)
    # Summary Table
    df = pd.DataFrame(columns=['Item', '2017', '2020'])
    row = {'Item': "Residences Principales",     '2017': ds.number("SRU_RP_2017"),    '2020': ds.number("SRU_RP_2020")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Logements Sociaux",          '2017': ds.number("SRU_LLS_2017"),   '2020': ds.number("SRU_LLS_2020")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Taux Logements Sociaux",     '2017': ds.tauxp100("SRU_TX_LLS_2017"), '2020': ds.tauxp100("SRU_TX_LLS_2020")}
    df = df.append(row, ignore_index=True)

    carence2017 = round0(data_dict["SRU_RP_2017"] * (0.25 - data_dict["SRU_TX_LLS_2017"]), 0)
    carence2020 = round0(data_dict["SRU_RP_2020"] * (0.25 - data_dict["SRU_TX_LLS_2020"]), 0)
    row = {'Item': "Carence",                    '2017': round0str(carence2017), '2020' : round0str(carence2020)}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Objectifs Trienaux",         '2017': ds.number("SRU_OBJ_2017_2019"), '2020': ds.number("SRU_OBJ_2020_2022")}
    df = df.append(row, ignore_index=True)

    mod3565_2017 = round(data_dict["SRU_OBJ_2017_2019"]/35*100, 0)
    mod3565_2020 = round(data_dict["SRU_OBJ_2020_2022"]/35*100, 0)
    mod3565_carence = round(carence2020/35*100, 0)
    row = {'Item': "Log 35/65 Trienaux",                  '2017': round0str(mod3565_2017), '2020': round0str(mod3565_2020)}
    df = df.append(row, ignore_index=True)

    evol_res_pr  = round(data_dict["SRU_RP_2020"]-data_dict["SRU_RP_2017"], 0)
    evol_carence = round((data_dict["SRU_RP_2020"] - data_dict["SRU_RP_2017"]) * 0.25, 0)
    log_sociaux  = round(carence2017 + evol_carence - carence2020, 0)
    html = "<h2>" + "Logements Sociaux " + ds.store_name + "</h2>"
    html = html   + "<p>" + df.to_html() + "</p>"
    html = html   + "<p>" + "Evolution 2017-2020 des RP : "       + round0str(evol_res_pr, 0)     + "</p>"
    html = html   + "<p>" + "Evolution 2017-2020 Carence : "      + round0str(evol_carence, 0)    + "</p>"
    html = html   + "<p>" + "LS Realises en 2017-2020 : "            + round0str(log_sociaux, 0)     + "</p>"
    html = html   + "<p>" + "Total de logements a construire en 36/65 : "  + round0str(mod3565_carence, 0) + "</p>"
    global_context["HTML_TABLE_SRU"] = html
    return html


def report_artificialisation(ds: DataStore):
    data_dict = ds.get_row_as_dict(ds.store_index)
    html = "<h2>" + "Artificialisation sur 10 ans (2009-2020)" + "</h2>"
    html = html   + "<p>" + "Surface du Territoire       = " + round0str(data_dict["SURFACE_COMMUNE"] / 10000, 1) + " ha"+"</p>"
    html = html   + "<p>" + "Artificialisation 2009-2020 = " + round0str(data_dict["ART_TOTAL"] / 10000, 1)  + " ha"+"</p>"
    html = html   + "<p>" + "Supplement                  = " + round0str(data_dict["ART_POURCENT"] , 1) + "%"+"</p>"
    global_context["HTML_TABLE_ARTIFICIALISATION"] = html
    return html


def report_historique(ds: DataStore):
    data_dict = ds.get_row_as_dict(ds.store_index)
    # Summary Table
    df = pd.DataFrame(columns=['Item', '2008', '2013', '2018'])
    row = {'Item': "Population",             '2008': ds.number("P08_POP"),    '2013': ds.number("P13_POP"),    '2018': ds.number("P18_POP")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "- Evolution #",          '2008': "-",                     '2013': round0str(data_dict["P13_POP"]-data_dict["P08_POP"]), '2018': round0str(data_dict["P18_POP"]-data_dict["P13_POP"])}
    df = df.append(row, ignore_index=True)
    row = {'Item': "- Evolution %",          '2008': "-",                     '2013': ds.percent("TXPOP_0813"), '2018': ds.percent("TXPOP_1318")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Population Menages ",    '2008': ds.number("C08_PMEN"),   '2013': ds.number("C13_PMEN"),   '2018': ds.number("C18_PMEN")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Population Hors Menages ", '2008': round0str(data_dict["P08_POP"]-data_dict["C08_PMEN"]),   '2013': round0str(data_dict["P13_POP"]-data_dict["C13_PMEN"]),   '2018': round0str(data_dict["P18_POP"]-data_dict["C18_PMEN"])}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Menages ",               '2008': ds.number("C08_MEN"),    '2013': ds.number("C13_MEN"),    '2018': ds.number("C18_MEN")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Taille des Menages",     '2008': ds.number("TM_2008", 2), '2013': ds.number("TM_2013", 2), '2018': ds.number("TM_2018", 2)}
    df = df.append(row, ignore_index=True)
    row = {'Item': "- Evolution TM %",       '2008': "-",                     '2013': ds.percent("TXTM_0813", 2), '2018': ds.percent("TXTM_1318", 2)}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Logements",              '2008': ds.number("P08_LOG"),    '2013': ds.number("P13_LOG"),    '2018': ds.number("P18_LOG")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "- Residences Principales", '2008': ds.number("P08_RP"),   '2013': ds.number("P13_RP"),     '2018': ds.number("P18_RP")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "- Residences Secondaires", '2008': ds.number("P08_RSECOCC"), '2013': ds.number("P13_RSECOCC"), '2018': ds.number("P18_RSECOCC")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "- Logements Vacants",    '2008': ds.number("P08_LOGVAC"), '2013': ds.number("P13_LOGVAC"),  '2018': ds.number("P18_LOGVAC")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "- Maisons",              '2008': ds.number("P08_MAISON"), '2013': ds.number("P13_MAISON"),  '2018': ds.number("P18_MAISON")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "- Appartements ",        '2008': ds.number("P08_APPART"), '2013': ds.number("P13_APPART"),  '2018': ds.number("P18_APPART")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Proprietaires en RP",    '2008': ds.number("P08_RP_PROP"), '2013': ds.number("P13_RP_PROP"), '2018': ds.number("P18_RP_PROP")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Locataires en RP",       '2008': ds.number("P08_RP_LOC"),  '2013': ds.number("P13_RP_LOC"),  '2018': ds.number("P18_RP_LOC")}
    df = df.append(row, ignore_index=True)

    html = "<h2>" + "Historique " + ds.store_name + "</h2>"
    html = html   + "<p>" + df.to_html() + "</p>"
    global_context["HTML_TABLE_HISTORIQUE"] = html
    return html


def report_projection(ds: DataStore):
    data_dict = ds.get_row_as_dict(ds.store_index)
    # Summary Table
    df = pd.DataFrame(columns=['Item', '2020', '2030', '2040', '2050'])
    row = {'Item': "Population",             '2020': ds.number("POP_2020"),   '2030': ds.number("POP_2030"),    '2040': ds.number("POP_2040"),     '2050': ds.number("POP_2050")}
    df = df.append(row, ignore_index=True)
    row = {'Item': "- Evolution %",          '2020': ds.percent("TXPOP_1318", 2), '2030': ds.percent("TX_POP_2030", 2), '2040': ds.percent("TX_POP_3040", 2),  '2050': ds.percent("TX_POP_4050", 2)}
    df = df.append(row, ignore_index=True)
    df = df.append(row, ignore_index=True)
    row = {'Item': "Taille des Menages",     '2020': ds.number("TM_2020", 2), '2030': ds.number("TM_2030", 2),  '2040': ds.number("TM_2040", 2),   '2050': ds.number("TM_2050", 2)}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Besoins en Logements = ",  '2020': data_dict["LOG_2020"], '2030': data_dict["LOG_2030"],    '2040': data_dict["LOG_2040"],     '2050': data_dict["LOG_2050"]}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Besoins en Logements # 10 ans",  '2020': "-",             '2030': round0str(data_dict["LOG_2030"]-data_dict["LOG_2020"]),      '2040': round0str(data_dict["LOG_2040"]-data_dict["LOG_2030"]),      '2050': round0str(data_dict["LOG_2050"]-data_dict["LOG_2040"])}
    df = df.append(row, ignore_index=True)
    row = {'Item': "Besoins en Logements # / an ", '2020': "-",               '2030': round0str((data_dict["LOG_2030"]-data_dict["LOG_2020"])/10), '2040': round0str((data_dict["LOG_2040"]-data_dict["LOG_2030"])/10), '2050': round0str((data_dict["LOG_2050"]-data_dict["LOG_2040"])/10)}
    df = df.append(row, ignore_index=True)

    html = "<h2>" + "Projections " + ds.store_name + "</h2>"
    html = html   + "<p>" + df.to_html() + "</p>"
    global_context["HTML_TABLE_PROJECTIONS"] = html
    return html


def report_summary_data(ds: DataStore):
    # Summary Table
    data_dict = {}
    df = pd.DataFrame(columns=['Key', 'Value', 'Meta'])
    for column in ds.data_frame:
        data_dict[column] = ds.data_frame[column][ds.store_index]
        row = {'Key': column, 'Value': str(ds.data_frame[column][ds.store_index]), 'Meta': ds.data_frame[column]["meta"]}
        df = df.append(row, ignore_index=True)
    data_html = "<h3>" + "Donnees Brutes Consolidees pour : " + ds.store_name  + "</h3>"
    data_html = data_html + df.to_html(index=True)
    global_context["HTML_TABLE_SUMMARY"] = data_html
    return data_html


def report_full_data(ds: DataStore):
    data_html = "<h3>" + "Toutes les Donnees - Details : " + ds.store_name + "</h3>"
    data_html = data_html + ds.data_frame.to_html(index=True)
    global_context["HTML_FULL_DATA"] = data_html
    return data_html


index_figure = 0


def new_figure():
    global index_figure
    index_figure += 1
    plt.close('all')
    plt.figure(index_figure)
    return plt


def plot_logements(ds: DataStore):
    data_dict = ds.get_row_as_dict(ds.store_index)
    label = "Logements"

    df1 = pd.DataFrame({'x_values': (2008, 2013, 2018, 2020),  # Residences Principales - Historique
                        'y_values': (data_dict["P08_RP"]   - data_dict["P08_RP"],
                                     data_dict["P13_RP"]   - data_dict["P08_RP"],
                                     data_dict["P18_RP"]   - data_dict["P08_RP"],
                                     data_dict["LOG_2020"] - data_dict["P08_RP"])})
    df11 = pd.DataFrame({'x_values': (2020, 2030),            # Residences Principales - Projection
                         'y_values': (data_dict["LOG_2020"] - data_dict["P08_RP"],
                                      data_dict["LOG_2030"] - data_dict["P08_RP"])})
    df2 = pd.DataFrame({'x_values': (2008, 2013, 2018),  # Residences Principales + Secondaires
                        'y_values': (data_dict["P08_RP"] - data_dict["P08_RP"] + data_dict["P08_RSECOCC"] - data_dict["P08_RSECOCC"] + data_dict["P08_LOGVAC"] - data_dict["P08_LOGVAC"],
                                     data_dict["P13_RP"] - data_dict["P08_RP"] + data_dict["P13_RSECOCC"] - data_dict["P08_RSECOCC"] + data_dict["P13_LOGVAC"] - data_dict["P08_LOGVAC"],
                                     data_dict["P18_RP"] - data_dict["P08_RP"] + data_dict["P18_RSECOCC"] - data_dict["P08_RSECOCC"] + data_dict["P18_LOGVAC"] - data_dict["P08_LOGVAC"])})
    df21 = pd.DataFrame({'x_values': (2018, 2020),  # Residences Principales + Secondaires - Projection
                         'y_values': (data_dict["P18_RP"] - data_dict["P08_RP"] + data_dict["P18_RSECOCC"] - data_dict["P08_RSECOCC"] + data_dict["P18_LOGVAC"] - data_dict["P08_LOGVAC"],
                                      data_dict["NOUV_LOG_0813"] + data_dict["NB_LGT_TOT_COMMENCES_1316"] + data_dict["NB_LGT_TOT_COMMENCES_1721"])})
    df3 = pd.DataFrame({'x_values': (2013, 2016, 2020),
                        'y_values': (data_dict["NOUV_LOG_0813"],
                                     data_dict["NOUV_LOG_0813"] + data_dict["NB_LGT_TOT_COMMENCES_1316"],  # Logements Construits
                                     data_dict["NOUV_LOG_0813"] + data_dict["NB_LGT_TOT_COMMENCES_1316"] + data_dict["NB_LGT_TOT_COMMENCES_1721"])})
    df4 = pd.DataFrame({'x_values': (2013, 2016, 2020),
                        'y_values': (data_dict["NOUV_LOG_0813"],
                                     data_dict["NOUV_LOG_0813"] + data_dict["NB_LGT_PRET_LOC_SOCIAL_1316"],  # Logements Sociaux Construits
                                     data_dict["NOUV_LOG_0813"] + data_dict["NB_LGT_PRET_LOC_SOCIAL_1316"] + data_dict["NB_LGT_PRET_LOC_SOCIAL_1721"])})

    # Draw plot
    plt = new_figure()
    plt.plot('x_values', 'y_values', data=df1, color='blue',
             linestyle='-',  linewidth=3, label="Residences Principales des menages - Historique")
    plt.plot('x_values', 'y_values', data=df11, color='blue',
             linestyle='--', linewidth=2, label="Residences Principales des menages - Projection des Besoins")
    plt.plot('x_values', 'y_values', data=df2, color='purple',
             linestyle='-', linewidth=3, label="Residences Principales + Secondaires + Vacants")
    plt.plot('x_values', 'y_values', data=df21, color='purple',
             linestyle='dotted', linewidth=3, label="Indeterminees (Principales / Secondaires / Non-Vendues)")
    plt.plot('x_values', 'y_values', data=df3, color='black',
             linestyle='-', linewidth=3, label="Logements Construits")
    plt.plot('x_values', 'y_values', data=df4, color='grey',
             linestyle='--', linewidth=3, label="Logements Sociaux Construits")

    # Naming the axis
    plt.xlabel('Annees')
    plt.ylabel('Logements')

    # Title & Legend
    plt.title(label + " sur " + ds.store_name)
    plt.legend(bbox_to_anchor=(1.0, 1.0))

    ## Save Locally
    image_file_name = output_dir + ds.get_fullname() + "_" + label.replace(" ", "_") + ".png"
    plt.savefig(image_file_name)

    ## Save for HTML Format
    encoded_fig = fig_to_base64(plt)
    browser_html = '<h2>'+label+'</h2><p><img src="data:image/png;base64, {}"></p>'.format(encoded_fig.decode('utf-8'))
    browser_html = browser_html + "<p> Taux de Residences Secondaires : " + round0str(100 * round(data_dict["TX_RES_SEC_18"], 4), 1) + "%</p>"
    browser_html = browser_html + "<p> Taux de Residences Vacantes : " + round0str(100 * round(data_dict["TX_RES_VAC_18"],    4), 1) + "%</p>"

    browser_html = browser_html + "<p> Periode 2013 - 2020 : " + str(round(ds["EXCES_BESOINS_1320"])) + "</p>"
    browser_html = browser_html + "<p> - Besoins en logements : " + str(round(ds["BESOINS_1320"])) + "</p>"
    browser_html = browser_html + "<p> - Logements Construits : " + str(round(ds["NB_LGT_TOT_COMMENCES_1321"])) + "</p>"
    browser_html = browser_html + "<p> - Exces de Logements Construits par rapport aux besoins : " + str(round(ds["EXCES_BESOINS_1320"])) + "</p>"
    browser_html = browser_html + "<p> -> Nouvelles Residences Secondaires : "  + str(round(ds["NOUV_RESSEC_1318"])) + "</p>"
    browser_html = browser_html + "<p> -> Nouvelles Residences Vacantes : "     + str(round(ds["NOUV_LOGVAC_1318"])) + "</p>"
    browser_html = browser_html + "<p> -> Indetermines / Non-Vendus : "     + str(round(ds["EXCES_BESOINS_1320"]-ds["NOUV_LOGVAC_1318"]-ds["NOUV_RESSEC_1318"])) + "</p>"
    browser_html = browser_html + "<p> Periode 2013 - 2021 : " + str(round(ds["EXCES_BESOINS_1320"])) + "</p>"
    browser_html = browser_html + "<p> - Logements Construits : " + str(ds["NB_LGT_TOT_COMMENCES_1321"])     + "</p>"
    browser_html = browser_html + "<p> - Logements Sociaux  : "   + str(ds["NB_LGT_PRET_LOC_SOCIAL_1321"]) + "</p>"
    browser_html = browser_html + "<p> - Taux LS Construits : " + str(round(100 * ds["TX_LGT_PRET_LOC_SOCIAL_1321"], 2)) + "% </p>"
    # email_html   = "<img alt=" + str(lKpi.get_data(c_name)) + " src=\"cid:" + image_file_name + "\" >"
    global_context["HTML_PLOT_LOGEMENTS"] = browser_html
    return browser_html


def plot_taille_menages(ds: DataStore):
    data_dict = ds.get_row_as_dict(ds.store_index)
    label = "Taille des Menages"
    df1 = pd.DataFrame({'x_values': (2008, 2013, 2018, 2020),
                        'y_values': (data_dict["TM_2008"],
                                     data_dict["TM_2013"],
                                     data_dict["TM_2018"],
                                     data_dict["TM_2020"]
                                     )})
    df2 = pd.DataFrame({'x_values': (2020, 2030, 2040, 2050),
                        'y_values': (data_dict["TM_2020"],
                                     data_dict["TM_2030"],
                                     data_dict["TM_2040"],
                                     data_dict["TM_2050"]
                                     )})

    # Draw plot
    plt = new_figure()
    plt.plot('x_values', 'y_values', data=df1,
             color='blue',   linestyle='-',  linewidth=3, label=label + " Historique")
    plt.plot('x_values', 'y_values', data=df2,
             color='yellow', linestyle='--', linewidth=3, label=label + " Projetee")

    # Naming the axis
    plt.xlabel('Annees')
    plt.ylabel('Taille des Menages')

    # Title & Legend
    plt.title(label + " sur " + ds.store_name)
    plt.legend()

    ## Save Locally
    image_file_name = output_dir + ds.get_fullname() + "_" + label.replace(" ", "_") + ".png"
    plt.savefig(image_file_name)

    ## Save for HTML Format
    encoded_fig = fig_to_base64(plt)
    browser_html = '<h2>'+label+'</h2><p><img src="data:image/png;base64, {}"></p>'.format(encoded_fig.decode('utf-8'))
    # email_html   = "<img alt=" + str(lKpi.get_data(c_name)) + " src=\"cid:" + image_file_name + "\" >"
    global_context["HTML_PLOT_TAILLE_DES_MENAGES"] = browser_html
    return browser_html


def plot_population(ds: DataStore):
    data_dict = ds.get_row_as_dict(ds.store_index)
    label = "Population"
    df1 = pd.DataFrame({'x_values': (2008, 2013, 2018, 2020),
                        'y_values': (data_dict["P08_POP"],
                                     data_dict["P13_POP"],
                                     data_dict["P18_POP"],
                                     data_dict["POP_2020"]
                                     )})
    df2 = pd.DataFrame({'x_values': (2020, 2030, 2040, 2050),
                        'y_values': (data_dict["POP_2020"],
                                     data_dict["POP_2030"],
                                     data_dict["POP_2040"],
                                     data_dict["POP_2050"]
                                     )})

    # Draw plot
    plt = new_figure()
    plt.plot('x_values', 'y_values', data=df1,
             color='blue',   linestyle='-',  linewidth=3, label=label + " Historique")
    plt.plot('x_values', 'y_values', data=df2,
             color='yellow', linestyle='--', linewidth=3, label=label + " Projetee")

    # Naming the axis
    plt.xlabel('Annees')
    plt.ylabel('Population')

    # Title & Legend
    plt.title(label + " sur " + ds.store_name)
    plt.legend()

    ## Save Locally
    image_file_name = output_dir + ds.get_fullname() + "_" + label.replace(" ", "_") + ".png"
    plt.savefig(image_file_name)

    ## Save for HTML Format
    encoded_fig = fig_to_base64(plt)
    browser_html = '<h2>'+label+'</h2><p><img src="data:image/png;base64, {}"></p>'.format(encoded_fig.decode('utf-8'))
    # email_html   = "<img alt=" + str(lKpi.get_data(c_name)) + " src=\"cid:" + image_file_name + "\" >"
    global_context["HTML_PLOT_POPULATION"] = browser_html
    return browser_html

###
### Reports
###

def gen_index():
    report_region_dict("93", filename=regions_file)
    return render_index()


def gen_report(ds : DataStore):
    ds.save_data()
    global_context["HTML_SOURCES"]                 = report_source(ds)
    global_context["HTML_DIAGNOSTIC"]              = report_diagnostic(ds)
    global_context["HTML_PLOT_LOGEMENTS"]          = plot_logements(ds)
    global_context["HTML_PLOT_POPULATION"]         = plot_population(ds)
    global_context["HTML_PLOT_TAILLE_DES_MENAGES"] = plot_taille_menages(ds)
    global_context["HTML_TABLE_HISTORIQUE"]        = report_historique(ds)
    global_context["HTML_TABLE_PROJECTIONS"]       = report_projection(ds)
    global_context["HTML_TABLE_ARTIFICIALISATION"] = report_artificialisation(ds)
    global_context["HTML_TABLE_SRU"]               = report_sru(ds)
    global_context["HTML_TABLE_SUMMARY"]           = report_summary_data(ds)
    global_context["HTML_FULL_DATA"]               = report_full_data(ds)
    return ds.render_report()


def report_commune(code_postal: str = "06250", force=True, with_communes=False):
    code_insee, commune = get_code_insee_commune(code_postal)
    if (str(commune).startswith("Pas")):
        code_insee, commune = get_code_postal_commune(code_postal)
        if (not str(commune).startswith("Pas")): code_insee = code_postal
    entite = entite_commune
    name   = commune
    code   = code_insee
    return DataStore(store_name=name, store_type=entite, store_code=code).report(force=force)


def report_epci(epci_id: str = "200039915", force=True, with_communes=False):
    entite = entite_epci
    name   = nom_epci(epci_id, clean=True)
    code   = epci_id
    if (with_communes):
        for commune in communes_epci(epci_id):
            report_commune(commune, force, with_communes)
    return DataStore(store_name=name, store_type=entite, store_code=code).report(force=force)


def report_dept(dept_id: str = "06", force=True, with_communes=False):
    entite = entite_dept
    name   = nom_dept(dept_id, clean=True)
    code   = dept_id
    if (with_communes):
        for commune in communes_dept(dept_id):
            report_commune(commune, force, with_communes)
        for epci in epci_dept(dept_id):
            report_epci(epci, force, with_communes)
    return DataStore(store_name=name, store_type=entite, store_code=code).report(force=force)


def report_region(reg_id: str = "93", force=True, with_communes=False):
    entite = "REGION"
    name   = nom_region(reg_id, clean=True)
    code   = reg_id
    if (with_communes):
        for dept in list_dept(reg_id):
            report_dept(dept, force, with_communes=True)
        for commune in communes_region(reg_id):
            report_commune(commune, force, with_communes)
    return DataStore(store_name=name, store_type=entite, store_code=code).report(force=force)


def report_paca(force=True):
    print_yellow("DEPT 06 - Alpes-Maritimes : ")
    for epci in epci_dept("06"):
        report_epci(str(epci), force=force)
    report_dept("06", force=force)

    print_yellow("DEPT 04 - Alpes-de-Haute-Provence : ")
    for epci in epci_dept("04"):
        report_epci(str(epci), force=force)
    report_dept("04", force=force)

    print_yellow("DEPT 05 - Hautes-Alpes : ")
    for epci in epci_dept("05"):
        report_epci(str(epci), force=force)
    report_dept("05", force=force)

    print_yellow("DEPT 13 - Bouches-du-Rhone : ")
    for epci in epci_dept("13"):
        report_epci(str(epci), force=force)
    report_dept("13", force=force)

    print_yellow("DEPT 83 - Var : ")
    for epci in epci_dept("83"):
        report_epci(str(epci), force=force)
    report_dept("83", force=force)

    print_yellow("DEPT 84 - Vaucluse : ")
    for epci in epci_dept("84"):
        report_epci(str(epci), force=force)
    report_dept("84", force=force)

    print_yellow("REGION 93 - Region PACA : ")
    report_region("93", force=force)


report_france = {}

def report_region_dict(region=None, filename=None) -> dict:
    global report_france
    if str(region) in report_france : return report_france[str(region)]

    if (os.path.isfile(filename)):
        with open(filename, "r") as read_file:
            print("Converting JSON encoded data into Python dictionary")
            france = jsonc.load(read_file)
            report_france[str(region)] = france
            return france
    france = {}
    france["REGIONS"] = []
    if (not region):
        lr = list_region()
    else:
        lr = [str(region)]
    for r in lr:
        rd = {}
        rd["TYPE"] =  "REGION"
        rd["INSEE"]  = str(r)
        rd["Nom"]    = nom_region(r, clean=True)
        rd["Clean"]  = nom_region(r, clean=False)
        rd["HTML"] = "REGION_" + rd["Clean"] + ".html"
        rd["Region"] = str(r)
        rd["DEPARTEMENTS"] = []
        france["REGIONS"].append(rd)
        # all[str(r)] = rd
        for d in list_dept(r):
            dd = {}
            dd["TYPE"] = "DEPT"
            dd["INSEE"] = str(d)
            dd["Nom"]   = nom_dept(d, clean=True)
            dd["Clean"] = nom_dept(d, clean=False)
            dd["HTML"] = "DEPT_" + dd["Clean"] + ".html"
            dd["Departement"] = str(d)
            dd["Region"] = str(r)
            dd["Nom_Region"] = nom_region(r, clean=True)
            dd["EPCI"] = []
            dd["COMMUNES"] = []
            rd["DEPARTEMENTS"].append(dd)
            # rd[str(d)] = dd
            for e in epci_dept(d):
                de = {}
                de["TYPE"]  = "EPCI"
                de["INSEE"] = str(e)
                de["Nom"] = nom_epci(e,   clean=True)
                de["Clean"] = nom_epci(e, clean=False)
                de["HTML"] = "EPCI_" + de["Clean"] + ".html"
                de["Departement"]     = str(d)
                de["Nom_Departement"] = nom_dept(d, clean=True)
                de["Region"]          = str(r)
                de["Nom_Region"]      = nom_region(r, clean=True)
                de["COMMUNES"] = []
                dd["EPCI"].append(de)
                # dd[str(e)] = de
                for c in communes_epci(e):
                    cd = {}
                    cd["TYPE"]  = "COMMUNE"
                    cd["INSEE"] = str(c)
                    pos, lib = get_code_postal_commune(c)
                    cd["Postal"] = pos
                    cd["Libelle"] = lib
                    cd["Nom"] = nom_commune(c,   clean=True)
                    cd["Clean"] = nom_commune(c, clean=False)
                    cd["HTML"] = "COMMUNE_" + cd["Clean"] + ".html"
                    cd["Departement"]     = str(d)
                    cd["Nom_Departement"] = nom_dept(d, clean=True)
                    cd["Region"]          = str(r)
                    cd["Nom_Region"]      = nom_region(r, clean=True)
                    cd["EPCI"]            = epci_commune(c)
                    cd["Nom_EPCI"]        = nom_epci(epci_commune(c))
                    de["COMMUNES"].append(cd)
                    # de[str(c)] = cd
            for c in communes_dept(d):
                cd = {}
                cd["TYPE"]  = "COMMUNE"
                cd["INSEE"] = str(c)
                pos, lib = get_code_postal_commune(c)
                cd["Postal"] = pos
                cd["Libelle"] = lib
                cd["Nom"] = nom_commune(c,   clean=True)
                cd["Clean"] = nom_commune(c, clean=False)
                cd["HTML"] = "COMMUNE_" + cd["Clean"] + ".html"
                cd["Departement"]     = str(d)
                cd["Nom_Departement"] = nom_dept(d, clean=True)
                cd["Region"]          = str(r)
                cd["Nom_Region"]      = nom_region(r, clean=True)
                cd["EPCI"]            = epci_commune(c)
                cd["Nom_EPCI"]        = nom_epci(epci_commune(c))
                dd["COMMUNES"].append(cd)
                # d[str(c)] = cd
    if (filename):
        save_file(to_json(france, indent=4),  filename)
    report_france[str(region)] = france
    return france


def load_min_data():
    load_codes()
    load_departements()
    load_interco()
    load_collectData()


def load_all_data():
    load_min_data()
    load_sru(sruFile)
    load_communes()
    load_projections()
    load_projections_paca()
    load_sitadel()
    load_sitadel_locaux()
    load_evolution()
    load_artificialisation()


class TestConsommation(unittest.TestCase):

    def setUp(self) -> None:
        global DISPLAY_HTML
        DISPLAY_HTML = False
        print_red("> Setup")
        load_min_data()
        print_red("< Setup")

    def testSaintTropez(self):
        print_yellow("> Saint-Tropez")
        ds = report_commune("83990", force=False)
        self.assertEqual(ds.get("NOM_COMMUNE"), "ST TROPEZ")
        print_yellow("< Saint-Tropez")

    def testMougins(self):
        print_yellow("> Mougins")
        ds = report_commune("06250", force=False)
        self.assertEqual(ds.get("NOM_COMMUNE"), "MOUGINS")
        print_yellow("< Mougins")

    def testMouginsReport(self):
        global DISPLAY_HTML
        DISPLAY_HTML = True
        self.testMougins()

    def testCannesReport(self):
        global DISPLAY_HTML
        DISPLAY_HTML = True
        print_yellow("> Cannes")
        ds = report_commune("06400", force=False)
        self.assertEqual(ds.get("NOM_COMMUNE"), "CANNES")
        print_yellow("< Cannes")

    def testCAPL(self):
        print_yellow("> CA Cannes Pays de Lerins")
        ds = report_epci(epci_id="200039915", force=False)
        self.assertEqual(str(ds.get("EPCI")), "200039915")
        self.assertEqual(str(ds.get("NOM_COMMUNE")), "EPCI")
        print_yellow("< CA Cannes Pays de Lerins")

    def testCAPLReport(self):
        global DISPLAY_HTML
        DISPLAY_HTML = True
        self.testCAPL()

    def testAlpesMaritimes(self):
        print_yellow("> Departement Alpes Maritimes")
        ds = report_dept(dept_id="06", force=False)
        self.assertEqual(str(ds.get("NOM_COMMUNE")), "163")
        print_yellow("< Departement Alpes Maritimes")

    def testAlpesMaritimesReport(self):
        global DISPLAY_HTML
        DISPLAY_HTML = True
        self.testAlpesMaritimes()

    def testPaca(self):
        print_yellow("> Region Provence Alpes Cote d'Azur")
        ds = report_region(reg_id="93", force=False)
        self.assertEqual(str(ds.get("NOM_COMMUNE")), "946")
        print_yellow("< Region Provence Alpes Cote d'Azur")

    def test_report_region_dict(self):
        all = report_region_dict("93", filename=regions_file)
        print_blue(to_json(all, indent=4))

    def test_render_index(self):
        global DISPLAY_HTML
        DISPLAY_HTML = True
        html_index = gen_index()
        display_in_browser(html_index)

    def testPacaReport(self):
        global DISPLAY_HTML
        DISPLAY_HTML = True
        self.testPaca()

    def testReportPaca(self):
        load_all_data()
        report_paca()

    def testData(self):
        load_min_data()
        print_yellow("> Liste des Departements")
        the_list = list_dept()
        print(the_list)
        self.assertIn("06", the_list)
        self.assertNotIn("200004802", the_list)

        print_yellow("> Liste des Regions")
        the_list = list_region()
        print(the_list)
        self.assertIn("93", the_list)

        print_yellow("> Liste EPCI Region 93")
        the_list = epci_region("93")
        print(the_list)
        self.assertIn("200004802", the_list)

        print_yellow("> Liste EPCI Departement 06")
        the_list = epci_dept("06")
        print(the_list)
        self.assertIn("200039915", the_list)
        self.assertNotIn("200035723", the_list)

        print_yellow("> Liste Communes EPCI  200039915")
        the_list = communes_epci("200039915")
        print(the_list)
        self.assertIn("06030",    the_list)
        self.assertNotIn("04022", the_list)
        dept = dept_epci("200039915")
        self.assertEqual("06",    dept)

        print_yellow("> Liste Communes Departement  06")
        print(communes_dept("06"))
        self.assertIn("06030", communes_dept("06"))
        self.assertNotIn("04022", communes_epci("200039915"))

        print_yellow("> Liste Communes Region  93")
        print(communes_region("93"))
        self.assertIn("06030", communes_region("93"))
        self.assertIn("04022", communes_region("93"))

        print_yellow("> Nom Region 93")
        nom = nom_region("93", clean=False)
        print(nom)
        self.assertEqual("Provence-Alpes-Cote_d_Azur_93", nom)
        nom = nom_region("93", clean=True)
        print(nom)
        self.assertEqual("Provence-Alpes-Côte d'Azur", nom)

        print_yellow("> Nom EPCI 200039915")
        nom = nom_epci("200039915", clean=False)
        print(nom)
        self.assertEqual("CA_Cannes_Pays_de_Lerins_200039915", nom)
        nom = nom_epci("200039915", clean=True)
        print(nom)
        self.assertEqual("CA Cannes Pays de Lérins", nom)

        print_yellow("> Nom Departement 06")
        nom = nom_dept("06", clean=False)
        print(nom)
        self.assertEqual("Alpes-Maritimes_06", nom)
        nom = nom_dept("06", clean=True)
        print(nom)
        self.assertEqual("Alpes-Maritimes", nom)

        print_yellow("> Nom Commune 06250")
        nom = nom_commune(code_postal="06250", clean=False)
        print(nom)
        self.assertEqual("Mougins_06085", nom)
        nom = nom_commune(code_postal="06250", clean=True)
        print(nom)
        self.assertEqual("Mougins", nom)
        nom = nom_commune(code_insee="06085", clean=False)
        print(nom)
        self.assertEqual("Mougins_06085", nom)
        nom = nom_commune(code_insee="06085", clean=True)
        print(nom)
        self.assertEqual("Mougins", nom)
        ecpi = epci_commune("06085")
        print(str(ecpi))
        self.assertEqual("200039915", ecpi)


    def testCalc(self):
        self.assertEqual("0",    round0str(0,   rounding=0))
        self.assertEqual("1",    round0str(1,   rounding=0))
        self.assertEqual("1",    round0str(1.1, rounding=0))
        self.assertEqual("0",    round0str(0.2, rounding=0))
        self.assertEqual("0.0",  round0str(0,   rounding=1))
        self.assertEqual("1.0",  round0str(1,   rounding=1))
        self.assertEqual("1.1",  round0str(1.1, rounding=1))
        self.assertEqual("0.2",  round0str(0.2, rounding=1))
        self.assertEqual("1.11", round0str(1.1123, rounding=2))
        self.assertEqual("0.30", round0str(0.2993, rounding=2))
        self.assertEqual("20%",   perCentStr(0.2,    rounding=0))
        self.assertEqual("1.6%",  perCentStr(0.0156, rounding=1))
        self.assertEqual("1.56%", perCentStr(0.0156, rounding=2))
        self.assertEqual(0,      taux(24, 100, rounding=0))
        self.assertEqual(0.2,    taux(24, 100, rounding=1))
        self.assertEqual(0.24,   taux(24, 100, rounding=2))
        self.assertEqual(0.12,   taux(24, 200, rounding=2))

        self.assertEqual(100.1,   calc_after(2000, 100, 2001, 0.1,  rounding=3))
        self.assertEqual(100.2,   calc_after(2000, 100, 2002, 0.1,  rounding=3))
        self.assertEqual(100.3,   calc_after(2000, 100, 2003, 0.1,  rounding=3))
        self.assertEqual(100.2,   calc_after(2000, 100, 2020, 0.01, rounding=3))

        self.assertEqual(0.01,    calc_taux(2000, 100, 2020, 100.2, rounding=3))

    def testSRUData(self):
        self.assertEqual(25,      get_sru2017("Taux de LLS à atteindre", "06085", rounding=2))
        self.assertEqual(8909,    get_sru2020("NBR RP au 01/01/2020",    "06085", rounding=0))

    def testSRUArtificialisation(self):
        self.assertEqual(1589,    get_art("pop1217", "06085", rounding=0))


###
### Command Line Arguments
###

# Arg Options
DISPLAY_HTML       = False
FORCE              = False
CONFIGURATION_FILE = None
TEMPLATE_FILE      = None
CODE_COMMUNE       = None
CODE_EPCI          = None
CODE_DEPT          = None
CODE_REGION        = None
DEBUG              = False
WITH_COMMUNES      = False
LIST_COMMUNE       = False


def read_command_line_args(argv):
    global DISPLAY_HTML, FORCE, DEBUG, WITH_COMMUNES, LIST_COMMUNE
    global CONFIGURATION_FILE, TEMPLATE_FILE
    global CODE_COMMUNE, CODE_EPCI, CODE_DEPT, CODE_REGION
    # print_yellow("Command Line Arguments : " + str(argv))

    usage = """
    Usage: -f -a -b -l -c <commune_code> -e <epci_code> -d <dept_code> -r <region_code>   
           --list    : List for all communes/epci/dept in Territory       
           --commune : Report for Code INSEE / Postal                 
           --ecpi    : Report for ECPI                                
           --dept    : Report for Departement                         
           --region  : Report for Region                              
           --all     : Report for all communes in Territory           
           --force   : Report reading source data (cache ignored)     
           --browse  : Start Browser on generated report            
           --cxlsx     <ConfigurationFile.xlsx> : Use Configuration File  
           --rhtml     <ReportTemplate.html>    : Use ReportTemplate      
           --clean   : Delete Report files      
    """

    try:
        opts, args = getopt.getopt(argv, "halbfc:e:d:r:", [ "help", "list", "commune=", "epci=", "dep=", "reg=", "no_debug" ])
    except getopt.GetoptError:
        print(usage)
        raise
        sys.exit(2)
    for opt, arg in opts:
        if opt in ("-h", "--help"):
            print(usage)
            quit()
        elif (opt == "--debug"):
            DEBUG = True
            continue
        elif opt in ("-b", "-B"):
            DISPLAY_HTML = True
            continue
        elif opt in ("-f", "-F"):
            FORCE = True
            continue
        elif opt in ("-a", "-A", "-all", "-All", "-ALL"):
            WITH_COMMUNES = True
            continue
        elif opt in ("-b", "--browse"):
            DISPLAY_HTML = True
            continue
        elif (opt == "--cxlsx"):
            if (not os.path.isfile(arg)):
                print_red("Configuration File not found : "+arg)
                quit()
            CONFIGURATION_FILE = arg
            continue
        elif (opt == "--clean"):
            delete_patten(output_dir, "*.png")
            delete_patten(output_dir, "*.csv")
            delete_patten(output_dir, "*.json")
            delete_patten(output_dir, "*.xlsx")
            delete_patten(output_dir, "*.html")
            quit()
        elif (opt == "--rhtml"):
            if (not os.path.isfile(arg)):
                print_red("Template File not found : "+arg)
                quit()
            TEMPLATE_FILE = arg
            continue
        elif opt in ("-l", "--list"):
            LIST_COMMUNE = True
            continue
        elif opt in ("-c", "--commune"):
            CODE_COMMUNE = arg
            print_yellow("> Commune "+str(CODE_COMMUNE))
            report_commune(CODE_COMMUNE, force=FORCE, with_communes=WITH_COMMUNES)
            print_yellow("< Commune "+str(CODE_COMMUNE))
            quit()
        elif opt in ("-e", "--epci"):
            CODE_EPCI = arg
            if (LIST_COMMUNE):
                print_commune(communes_epci(CODE_EPCI))
            else:
                print_yellow("> EPCI " + str(CODE_EPCI))
                report_epci(CODE_EPCI, force=FORCE, with_communes=WITH_COMMUNES)
                print_yellow("< EPCI " + str(CODE_EPCI))
                quit()
        elif opt in ("-d", "--dept"):
            CODE_DEPT = arg
            if (LIST_COMMUNE):
                print_commune(communes_dept(CODE_DEPT))
                print_epci(epci_dept(CODE_DEPT))
                quit()
            else:
                print_yellow("> Departement " + str(CODE_DEPT))
                report_dept(CODE_DEPT, force=FORCE, with_communes=WITH_COMMUNES)
                print_yellow("< Departement " + str(CODE_DEPT))
                quit()
        elif opt in ("-r", "--reg"):
            CODE_REGION = arg
            if (LIST_COMMUNE):
                print_commune(communes_region(CODE_REGION))
                print_epci(epci_region(CODE_REGION))
                print_dept(list_dept(CODE_REGION))
                quit()
            else:
                print_yellow("> Region " + str(CODE_REGION))
                report_region(CODE_REGION, force=FORCE, with_communes=WITH_COMMUNES)
                print_yellow("< Region " + str(CODE_REGION))
                quit()


###
### Main
###

read_command_line_args(argv=sys.argv[1:])

if __name__ == '__main__':
    print_yellow("Consommation Fonciere - Test Suite > " + __name__)
    load_min_data()
    unittest.main()

